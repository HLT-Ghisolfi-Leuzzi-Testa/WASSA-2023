{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>empathy</th>\n",
       "      <th>distress</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Hope</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Disgust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>It breaks my heart to see people living in tho...</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>6.625</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hope/Sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>I wonder why there aren't more people trying t...</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>6.000</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>After reading the article, you can't help but ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.375</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>213</td>\n",
       "      <td>It is so sad that someone who had such an amaz...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>6.625</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>213</td>\n",
       "      <td>From reading the article, it looks like the wo...</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>213</td>\n",
       "      <td>That's sad.  Regardless of what they find out ...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.125</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>78</td>\n",
       "      <td>After reading the article, my reaction is that...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>78</td>\n",
       "      <td>It sounds like these boys had a really rough l...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>78</td>\n",
       "      <td>This is a tragic and sad story about how some ...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>336</td>\n",
       "      <td>Hello. I feel really terrible about the curren...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>31</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>Disgust/Sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id  article_id  \\\n",
       "0                2          35   \n",
       "1                3          35   \n",
       "2                5          35   \n",
       "3                6         213   \n",
       "4                8         213   \n",
       "5               10         213   \n",
       "6               11          78   \n",
       "7               13          78   \n",
       "8               14          78   \n",
       "9               17         336   \n",
       "\n",
       "                                               essay   empathy  distress  \\\n",
       "0  It breaks my heart to see people living in tho...  6.833333     6.625   \n",
       "1  I wonder why there aren't more people trying t...  5.833333     6.000   \n",
       "2  After reading the article, you can't help but ...  1.000000     1.375   \n",
       "3  It is so sad that someone who had such an amaz...  6.166667     6.625   \n",
       "4  From reading the article, it looks like the wo...  6.833333     1.000   \n",
       "5  That's sad.  Regardless of what they find out ...  1.666667     1.125   \n",
       "6  After reading the article, my reaction is that...  1.500000     1.000   \n",
       "7  It sounds like these boys had a really rough l...  2.000000     1.000   \n",
       "8  This is a tragic and sad story about how some ...  6.000000     3.000   \n",
       "9  Hello. I feel really terrible about the curren...  7.000000     1.000   \n",
       "\n",
       "   speaker_id   gender education     race      age  ... essay_id  \\\n",
       "0          30        1         6        3       37  ...        1   \n",
       "1          19        1         6        2       32  ...        2   \n",
       "2          17        1         6        1       29  ...        4   \n",
       "3          16        2         5        1       28  ...        5   \n",
       "4          30        1         6        3       37  ...        7   \n",
       "5          49        1         5        1       31  ...        9   \n",
       "6          17        1         6        1       29  ...       10   \n",
       "7          24        2         7        1       38  ...       12   \n",
       "8          43        2         6        1       33  ...       13   \n",
       "9          31  unknown   unknown  unknown  unknown  ...       16   \n",
       "\n",
       "           emotion Surprise Hope Neutral Sadness Joy Fear Anger Disgust  \n",
       "0     Hope/Sadness        0    1       0       1   0    0     0       0  \n",
       "1            Anger        0    0       0       0   0    0     1       0  \n",
       "2          Sadness        0    0       0       1   0    0     0       0  \n",
       "3          Sadness        0    0       0       1   0    0     0       0  \n",
       "4          Neutral        0    0       1       0   0    0     0       0  \n",
       "5          Sadness        0    0       0       1   0    0     0       0  \n",
       "6          Sadness        0    0       0       1   0    0     0       0  \n",
       "7          Sadness        0    0       0       1   0    0     0       0  \n",
       "8          Sadness        0    0       0       1   0    0     0       0  \n",
       "9  Disgust/Sadness        0    0       0       1   0    0     0       1  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH_TRAIN = \"https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/WASSA23_essay_level_train_preproc.tsv\"\n",
    "df_train = pd.read_csv(DATA_PATH_TRAIN, sep='\\t')\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>speaker_number</th>\n",
       "      <th>...</th>\n",
       "      <th>iri_fantasy</th>\n",
       "      <th>iri_empathatic_concern</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Hope</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>How sad is it that this kind of pain and suffe...</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>The article is kind of tragic and hits close t...</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>64000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.429</td>\n",
       "      <td>1.429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>213</td>\n",
       "      <td>I think that these kinds of stories, are sad, ...</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>213</td>\n",
       "      <td>It's crazy that random accidents like this hap...</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>55000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.571</td>\n",
       "      <td>3.143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>78</td>\n",
       "      <td>This story makes me so so sad.... As someone w...</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.143</td>\n",
       "      <td>3.286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>78</td>\n",
       "      <td>After reading the article, my first reaction a...</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>85000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.143</td>\n",
       "      <td>4.643</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>336</td>\n",
       "      <td>I didn't know coal mining had such adverse eff...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>27000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.571</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>336</td>\n",
       "      <td>This is very sad.  I can't imagine having elep...</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>42000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.571</td>\n",
       "      <td>3.857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>281</td>\n",
       "      <td>Guys, reading this article really hits home fo...</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>29000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.571</td>\n",
       "      <td>4.857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>171</td>\n",
       "      <td>Hey guys. So I just read this article about Ir...</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>29000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.571</td>\n",
       "      <td>4.857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id  article_id  \\\n",
       "0                1          35   \n",
       "1                4          35   \n",
       "2                7         213   \n",
       "3                9         213   \n",
       "4               12          78   \n",
       "5               15          78   \n",
       "6               16         336   \n",
       "7               20         336   \n",
       "8               23         281   \n",
       "9               26         171   \n",
       "\n",
       "                                               essay  speaker_id  gender  \\\n",
       "0  How sad is it that this kind of pain and suffe...          68       2   \n",
       "1  The article is kind of tragic and hits close t...          79       1   \n",
       "2  I think that these kinds of stories, are sad, ...          68       2   \n",
       "3  It's crazy that random accidents like this hap...          84       2   \n",
       "4  This story makes me so so sad.... As someone w...          68       2   \n",
       "5  After reading the article, my first reaction a...          70       1   \n",
       "6  I didn't know coal mining had such adverse eff...          81       1   \n",
       "7  This is very sad.  I can't imagine having elep...          73       2   \n",
       "8  Guys, reading this article really hits home fo...          63       1   \n",
       "9  Hey guys. So I just read this article about Ir...          63       1   \n",
       "\n",
       "   education  race  age  income  speaker_number  ... iri_fantasy  \\\n",
       "0          2     1   21   20000               1  ...       3.143   \n",
       "1          6     3   33   64000               1  ...       2.429   \n",
       "2          2     1   21   20000               1  ...       3.143   \n",
       "3          4     1   25   55000               1  ...       3.571   \n",
       "4          2     1   21   20000               1  ...       3.143   \n",
       "5          6     1   29   85000               1  ...       4.143   \n",
       "6          4     1   30   27000               1  ...       4.571   \n",
       "7          7     1   38   42000               1  ...       2.571   \n",
       "8          4     1   25   29000               1  ...       2.571   \n",
       "9          4     1   25   29000               1  ...       2.571   \n",
       "\n",
       "   iri_empathatic_concern  Sadness  Anger Surprise  Neutral  Joy  Hope  \\\n",
       "0                   3.286        1      0        0        0    0     0   \n",
       "1                   1.429        1      0        0        0    0     0   \n",
       "2                   3.286        1      0        0        0    0     0   \n",
       "3                   3.143        0      0        0        1    0     0   \n",
       "4                   3.286        1      0        0        0    0     0   \n",
       "5                   4.643        1      0        0        0    0     0   \n",
       "6                   4.000        0      0        0        1    0     0   \n",
       "7                   3.857        1      0        0        0    0     0   \n",
       "8                   4.857        1      0        0        0    0     0   \n",
       "9                   4.857        0      0        0        1    0     0   \n",
       "\n",
       "   Disgust  Fear  \n",
       "0        0     0  \n",
       "1        0     0  \n",
       "2        0     0  \n",
       "3        0     0  \n",
       "4        0     0  \n",
       "5        0     0  \n",
       "6        0     0  \n",
       "7        0     0  \n",
       "8        0     0  \n",
       "9        0     0  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH_DEV = \"https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/WASSA23_essay_level_dev_preproc.tsv\"\n",
    "df_dev = pd.read_csv(DATA_PATH_DEV, sep='\\t')\n",
    "df_dev.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_list = [\"Sadness\", \"Anger\", \"Surprise\", \"Neutral\",\t\"Joy\", \"Hope\", \"Disgust\", \"Fear\"]\n",
    "\n",
    "essays_train = df_train['essay'].to_list()\n",
    "essays_dev = df_train['essay'].to_list()\n",
    "\n",
    "labels_train = []\n",
    "labels_dev = []\n",
    "for emo in emotions_list:\n",
    "  labels_train.append(df_train[emo].to_list())\n",
    "  labels_dev.append(df_dev[emo].to_list())\n",
    "#labels_train = df_train[emotions_list].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 570/570 [00:00<00:00, 225kB/s]\n",
      "Downloading model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440M/440M [00:33<00:00, 13.0MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     69\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 70\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     72\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     74\u001b[0m scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/optimization.py:466\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    462\u001b[0m state[\u001b[39m\"\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    464\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[39m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m exp_avg\u001b[39m.\u001b[39;49mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m(\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta1))\n\u001b[1;32m    467\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[1;32m    468\u001b[0m denom \u001b[39m=\u001b[39m exp_avg_sq\u001b[39m.\u001b[39msqrt()\u001b[39m.\u001b[39madd_(group[\u001b[39m\"\u001b[39m\u001b[39meps\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define your dataset class\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len, target_labels):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.essay = dataframe.essay\n",
    "        self.targets = self.data[target_labels].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.essay)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        essay = str(self.essay[index])\n",
    "        essay = \" \".join(essay.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            essay,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': torch.FloatTensor(self.targets[index])\n",
    "        }\n",
    "\n",
    "# Prepare your data\n",
    "#texts =   # List of essay texts\n",
    "#labels = data_emo_labels  # List of corresponding emotion labels\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', truncation=True)\n",
    "emotions_list = [\"Sadness\", \"Anger\", \"Surprise\", \"Neutral\",\t\"Joy\", \"Hope\", \"Disgust\", \"Fear\"]\n",
    "dataset = CustomDataset(df_train, tokenizer, 200, emotions_list)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Load pretrained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8)\n",
    "\n",
    "# Set up optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "# Fine-tune the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(2):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['targets'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}: Average Loss = {total_loss / len(dataloader)}')\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained('fine_tuned_bert_emotion_classifier')\n",
    "tokenizer.save_pretrained('fine_tuned_bert_emotion_classifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
