{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EMO task"
      ],
      "metadata": {
        "id": "9_B-_QwdhWLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"from google.colab import drive\n",
        "drive.mount('/content/drive')\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9sDeMksltGSk",
        "outputId": "f8d70000-db30-407a-ddf9-381be4f7084f",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:22:48.416426Z",
          "iopub.execute_input": "2023-07-11T14:22:48.417279Z",
          "iopub.status.idle": "2023-07-11T14:22:48.430966Z",
          "shell.execute_reply.started": "2023-07-11T14:22:48.417245Z",
          "shell.execute_reply": "2023-07-11T14:22:48.429651Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from google.colab import drive\\ndrive.mount('/content/drive')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "15KoBLrVhbI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q\n",
        "!pip install accelerate -U -q\n",
        "!pip install datasets -q\n",
        "!pip install torch-summary -q\n",
        "!pip install graphviz -q\n",
        "!pip install torchview -q\n",
        "!pip install bertviz -q\n",
        "!pip install NRCLex -q\n",
        "!pip install textblob -q\n",
        "!python -m textblob.download_corpora -q\n",
        "\n",
        "repo_path = \"https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/\"\n",
        "branch = \"main\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gnWTVNYDMx2",
        "outputId": "19d5175b-36ae-4019-be94-8974308ad86f",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:22:48.434968Z",
          "iopub.execute_input": "2023-07-11T14:22:48.435257Z",
          "iopub.status.idle": "2023-07-11T14:24:42.917716Z",
          "shell.execute_reply.started": "2023-07-11T14:22:48.435233Z",
          "shell.execute_reply": "2023-07-11T14:24:42.916541Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "utils_url = f\"{repo_path}{branch}/utils.py\"\n",
        "evaluation_url = f\"{repo_path}{branch}/evaluation.py\"\n",
        "\n",
        "import os\n",
        "if os.path.exists(\"utils.py\"):\n",
        "  !rm \"utils.py\"\n",
        "if os.path.exists(\"evaluation.py\"):\n",
        "  !rm \"evaluation.py\"\n",
        "\n",
        "!wget {utils_url}\n",
        "!wget {evaluation_url}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xbo-Ei3IAYB",
        "outputId": "89bddcdc-014b-4c21-96f8-5d5ad5433737",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:24:42.920188Z",
          "iopub.execute_input": "2023-07-11T14:24:42.920778Z",
          "iopub.status.idle": "2023-07-11T14:24:45.436361Z",
          "shell.execute_reply.started": "2023-07-11T14:24:42.920737Z",
          "shell.execute_reply": "2023-07-11T14:24:45.435167Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-11 18:29:24--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27695 (27K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]  27.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-11 18:29:24 (98.4 MB/s) - ‘utils.py’ saved [27695/27695]\n",
            "\n",
            "--2023-07-11 18:29:24--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/evaluation.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10675 (10K) [text/plain]\n",
            "Saving to: ‘evaluation.py’\n",
            "\n",
            "evaluation.py       100%[===================>]  10.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-11 18:29:25 (58.6 MB/s) - ‘evaluation.py’ saved [10675/10675]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMO_json_path_train = f\"{repo_path}{branch}/datasets/EMO23_lexicon_per_word_train.json\"\n",
        "EMP_json_path_train = f\"{repo_path}{branch}/datasets/EMP23_lexicon_per_word_train.json\"\n",
        "EMO_json_path_dev = f\"{repo_path}{branch}/datasets/EMO23_lexicon_per_word_dev.json\"\n",
        "EMP_json_path_dev = f\"{repo_path}{branch}/datasets/EMP23_lexicon_per_word_dev.json\"\n",
        "EMO_json_path_test = f\"{repo_path}{branch}/datasets/EMO23_lexicon_per_word_test.json\"\n",
        "EMP_json_path_test = f\"{repo_path}{branch}/datasets/EMP23_lexicon_per_word_test.json\"\n",
        "\n",
        "!wget {EMO_json_path_train}\n",
        "!wget {EMP_json_path_train}\n",
        "!wget {EMO_json_path_dev}\n",
        "!wget {EMP_json_path_dev}\n",
        "!wget {EMO_json_path_test}\n",
        "!wget {EMP_json_path_test}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEVk5afqZjf1",
        "outputId": "6094f6b6-9d18-415a-b14b-2f05da868bf7",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:24:45.439712Z",
          "iopub.execute_input": "2023-07-11T14:24:45.440032Z",
          "iopub.status.idle": "2023-07-11T14:24:53.864606Z",
          "shell.execute_reply.started": "2023-07-11T14:24:45.440003Z",
          "shell.execute_reply": "2023-07-11T14:24:53.863484Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-11 18:29:25--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMO23_lexicon_per_word_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13477977 (13M) [text/plain]\n",
            "Saving to: ‘EMO23_lexicon_per_word_train.json.1’\n",
            "\n",
            "EMO23_lexicon_per_w 100%[===================>]  12.85M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-07-11 18:29:26 (252 MB/s) - ‘EMO23_lexicon_per_word_train.json.1’ saved [13477977/13477977]\n",
            "\n",
            "--2023-07-11 18:29:26--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMP23_lexicon_per_word_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7607723 (7.3M) [text/plain]\n",
            "Saving to: ‘EMP23_lexicon_per_word_train.json.1’\n",
            "\n",
            "EMP23_lexicon_per_w 100%[===================>]   7.25M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-07-11 18:29:27 (324 MB/s) - ‘EMP23_lexicon_per_word_train.json.1’ saved [7607723/7607723]\n",
            "\n",
            "--2023-07-11 18:29:27--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMO23_lexicon_per_word_dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1058526 (1.0M) [text/plain]\n",
            "Saving to: ‘EMO23_lexicon_per_word_dev.json.1’\n",
            "\n",
            "EMO23_lexicon_per_w 100%[===================>]   1.01M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-07-11 18:29:28 (83.7 MB/s) - ‘EMO23_lexicon_per_word_dev.json.1’ saved [1058526/1058526]\n",
            "\n",
            "--2023-07-11 18:29:28--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMP23_lexicon_per_word_dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 595839 (582K) [text/plain]\n",
            "Saving to: ‘EMP23_lexicon_per_word_dev.json.1’\n",
            "\n",
            "EMP23_lexicon_per_w 100%[===================>] 581.87K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2023-07-11 18:29:28 (61.0 MB/s) - ‘EMP23_lexicon_per_word_dev.json.1’ saved [595839/595839]\n",
            "\n",
            "--2023-07-11 18:29:28--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMO23_lexicon_per_word_test.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 651198 (636K) [text/plain]\n",
            "Saving to: ‘EMO23_lexicon_per_word_test.json.1’\n",
            "\n",
            "EMO23_lexicon_per_w 100%[===================>] 635.94K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-07-11 18:29:29 (59.4 MB/s) - ‘EMO23_lexicon_per_word_test.json.1’ saved [651198/651198]\n",
            "\n",
            "--2023-07-11 18:29:29--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMP23_lexicon_per_word_test.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 362281 (354K) [text/plain]\n",
            "Saving to: ‘EMP23_lexicon_per_word_test.json.1’\n",
            "\n",
            "EMP23_lexicon_per_w 100%[===================>] 353.79K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-07-11 18:29:29 (47.0 MB/s) - ‘EMP23_lexicon_per_word_test.json.1’ saved [362281/362281]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import string\n",
        "from torch import nn\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
        "from transformers import TrainingArguments, Trainer, TrainerCallback, EarlyStoppingCallback\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import AutoConfig, BertForSequenceClassification\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from typing import Optional, Union, Tuple\n",
        "from nrclex import NRCLex\n",
        "import importlib\n",
        "import sys\n",
        "from torch.utils.data import Dataset\n",
        "from utils import *\n",
        "importlib.reload(sys.modules['utils'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDmQslVxDhy1",
        "outputId": "812565f4-ed51-4ed0-c750-199fbf7aa09d",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:24:53.868082Z",
          "iopub.execute_input": "2023-07-11T14:24:53.868917Z",
          "iopub.status.idle": "2023-07-11T14:25:05.357879Z",
          "shell.execute_reply.started": "2023-07-11T14:24:53.868876Z",
          "shell.execute_reply": "2023-07-11T14:25:05.356986Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'utils' from '/content/utils.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set CUDA if available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"======= CUDA Available =======\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"======= CUDA NOT Available, run on CPU =======\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quom7lWCDiiI",
        "outputId": "9f5adf60-2221-47fb-eef5-f3ce744e029d",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.359325Z",
          "iopub.execute_input": "2023-07-11T14:25:05.360142Z",
          "iopub.status.idle": "2023-07-11T14:25:05.392331Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.360106Z",
          "shell.execute_reply": "2023-07-11T14:25:05.391378Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= CUDA Available =======\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "4gsXzUtCBv-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WASSA dataset"
      ],
      "metadata": {
        "id": "dIUOnGp-_6lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_names = [\n",
        "    'fear',\n",
        "    'anger',\n",
        "    'anticipation',\n",
        "    'trust',\n",
        "    'surprise',\n",
        "    'positive',\n",
        "    'negative',\n",
        "    'sadness',\n",
        "    'disgust',\n",
        "    'joy',\n",
        "    'hope'\n",
        "]"
      ],
      "metadata": {
        "id": "S2o5IfHdgXXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WASSADataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer,\n",
        "        essay,\n",
        "        essay_id,\n",
        "        targets,\n",
        "        sep=False,\n",
        "        prompt=None,\n",
        "        EMP_lexicon = None,\n",
        "        EMO_lexicon = None,\n",
        "        global_features = None,\n",
        "        local_emotions = False,\n",
        "        local_empathy = False,\n",
        "        local_distress = False,\n",
        "        max_len=None\n",
        "        ):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.essay = essay\n",
        "        self.essay_id = essay_id\n",
        "        self.targets = targets\n",
        "        self.EMP_lexicon = EMP_lexicon\n",
        "        self.EMO_lexicon = EMO_lexicon\n",
        "        self.sep = sep\n",
        "        self.prompt = prompt\n",
        "\n",
        "        self.global_features = global_features\n",
        "        self.local_emotions = local_emotions\n",
        "        self.local_empathy = local_empathy\n",
        "        self.local_distress = local_distress\n",
        "\n",
        "    def __len__(self):\n",
        "        print(\"dentro len\")\n",
        "        return len(self.essay)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        essay = str(self.essay[index])\n",
        "\n",
        "        essay_id = self.essay_id[index]\n",
        "\n",
        "\n",
        "        if self.prompt is not None:\n",
        "          prompt = str(self.prompt[index])\n",
        "\n",
        "        text = essay\n",
        "        text_pair = None\n",
        "        if self.sep:\n",
        "          text_pair = prompt\n",
        "        else:\n",
        "          if self.prompt is not None:\n",
        "            text += \" \" + prompt\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text=essay,\n",
        "            text_pair=text_pair,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "          'input_ids': inputs['input_ids'].flatten(),\n",
        "          'attention_mask': inputs['attention_mask'].flatten(),\n",
        "          'token_type_ids': inputs[\"token_type_ids\"].flatten()\n",
        "        }\n",
        "\n",
        "        if self.targets is not None:\n",
        "          item['labels'] = torch.FloatTensor(self.targets[index])\n",
        "\n",
        "        if self.global_features is not None:\n",
        "          item['global_features'] = self.global_features[index]\n",
        "\n",
        "        n_local_features = 0\n",
        "        features_tokens_row = []\n",
        "        if self.local_emotions:\n",
        "            n_local_features += len(emotions_names)\n",
        "            for i in range(len(emotions_names)):\n",
        "                features_tokens_row.append(0)\n",
        "        if self.local_empathy:\n",
        "            n_local_features += 1\n",
        "            features_tokens_row.append(4)\n",
        "        if self.local_distress:\n",
        "            n_local_features += 1\n",
        "            features_tokens_row.append(0)\n",
        "\n",
        "        if n_local_features > 0:\n",
        "            features_tokens = np.full((self.tokenizer.model_max_length, n_local_features), features_tokens_row)\n",
        "        else:\n",
        "          features_tokens = None\n",
        "\n",
        "        word_count=0\n",
        "        first_char=True\n",
        "        last_char_is_space=False\n",
        "        for char_idx, char in enumerate(essay):\n",
        "          token_idx = inputs.char_to_token(char_idx)\n",
        "          if token_idx is None:\n",
        "            if first_char: last_char_is_space=True\n",
        "            if not last_char_is_space and not first_char:\n",
        "              word_count+=1\n",
        "              last_char_is_space=True\n",
        "            continue\n",
        "          elif last_char_is_space:\n",
        "            last_char_is_space=False\n",
        "          first_char=False\n",
        "\n",
        "          j = 0\n",
        "          if char not in string.punctuation:\n",
        "            if self.local_emotions:\n",
        "              for i, emo in enumerate(emotions_names):\n",
        "                features_tokens[token_idx][i] = self.EMO_lexicon[str(essay_id)][emo][word_count]\n",
        "              j += len(emotions_names)\n",
        "\n",
        "            if self.local_empathy:\n",
        "              features_tokens[token_idx][j] = self.EMP_lexicon[str(essay_id)]['empathy'][word_count]\n",
        "              j += 1\n",
        "\n",
        "\n",
        "            if self.local_distress:\n",
        "              features_tokens[token_idx][j] = self.EMP_lexicon[str(essay_id)]['distress'][word_count]\n",
        "\n",
        "        if features_tokens is not None:\n",
        "            item['local_features'] = torch.FloatTensor(features_tokens)\n",
        "\n",
        "        return item"
      ],
      "metadata": {
        "id": "WOuBgl-TmlM-",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.395151Z",
          "iopub.execute_input": "2023-07-11T14:25:05.395849Z",
          "iopub.status.idle": "2023-07-11T14:25:05.431024Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.395802Z",
          "shell.execute_reply": "2023-07-11T14:25:05.425351Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset paths"
      ],
      "metadata": {
        "id": "VUd7BQjSsVMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DATA = f\"{repo_path}{branch}/datasets/WASSA23_essay_level_original_internal_train_preproc.tsv\"\n",
        "VAL_DATA = f\"{repo_path}{branch}/datasets/WASSA23_essay_level_internal_original_val_preproc.tsv\"\n",
        "DEV_DATA = f\"{repo_path}{branch}/datasets/WASSA23_essay_level_dev_preproc.tsv\""
      ],
      "metadata": {
        "id": "BjM03TscDwcz",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.432142Z",
          "iopub.status.idle": "2023-07-11T14:25:05.432935Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.432631Z",
          "shell.execute_reply": "2023-07-11T14:25:05.432655Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read dataframes"
      ],
      "metadata": {
        "id": "EFI6AulQsYci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(TRAIN_DATA, sep='\\t')\n",
        "val_df = pd.read_csv(VAL_DATA, sep='\\t')\n",
        "dev_df = pd.read_csv(DEV_DATA, sep='\\t')"
      ],
      "metadata": {
        "id": "Sppn6sPYsBqA",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.434804Z",
          "iopub.status.idle": "2023-07-11T14:25:05.435465Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.435227Z",
          "shell.execute_reply": "2023-07-11T14:25:05.435249Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = EmotionsLabelEncoder()\n",
        "label_encoder.fit(train_df.emotion)"
      ],
      "metadata": {
        "id": "hygjdzlasIEL",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.439309Z",
          "iopub.status.idle": "2023-07-11T14:25:05.440020Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.439779Z",
          "shell.execute_reply": "2023-07-11T14:25:05.439801Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional subsample"
      ],
      "metadata": {
        "id": "yn_tGpeFsNqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"train_df = train_df[:10]\n",
        "val_df = val_df[:10]\n",
        "dev_df = dev_df[:10]\"\"\""
      ],
      "metadata": {
        "id": "wkCC492RsNSU",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.441263Z",
          "iopub.status.idle": "2023-07-11T14:25:05.442060Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.441821Z",
          "shell.execute_reply": "2023-07-11T14:25:05.441845Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "70a1c098-fb16-45c1-a0af-848eb9872d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_df = train_df[:10]\\nval_df = val_df[:10]\\ndev_df = dev_df[:10]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode targets"
      ],
      "metadata": {
        "id": "mDJWlHhwsfwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = label_encoder.encode(train_df.emotion)\n",
        "y_val = label_encoder.encode(val_df.emotion)\n",
        "y_dev = label_encoder.encode(dev_df.emotion)"
      ],
      "metadata": {
        "id": "6LKqRnKdsJdu",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.443319Z",
          "iopub.status.idle": "2023-07-11T14:25:05.444031Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.443788Z",
          "shell.execute_reply": "2023-07-11T14:25:05.443811Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Global Features\n",
        "emo_count_global = True #@param {type:\"boolean\"}\n",
        "empathy_count_global = True #@param {type:\"boolean\"}\n",
        "distress_count_global = True #@param {type:\"boolean\"}\n",
        "bio_global = True #@param {type:\"boolean\"}\n",
        "global_features_names = []\n",
        "emotions_count = ['fear_count',\t'anger_count','anticipation_count',\t'trust_count',\n",
        "                 'positive_count',\t'negative_count', 'surprise_count',\n",
        "                 'sadness_count',\t'disgust_count',\t'joy_count',\t'hope_count']\n",
        "bio = ['gender', 'age', 'income', 'race', 'education']\n",
        "if emo_count_global:\n",
        "  for emo in emotions_count: global_features_names.append(emo)\n",
        "if empathy_count_global: global_features_names.append('empathy')\n",
        "if distress_count_global: global_features_names.append('distress')\n",
        "if bio_global:\n",
        "  for b in bio: global_features_names.append(b)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "j6y4HnEP6gcI",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.445308Z",
          "iopub.status.idle": "2023-07-11T14:25:05.446049Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.445777Z",
          "shell.execute_reply": "2023-07-11T14:25:05.445801Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Local Features\n",
        "emo_count_local = True #@param {type:\"boolean\"}\n",
        "empathy_count_local = True #@param {type:\"boolean\"}\n",
        "distress_count_local = True #@param {type:\"boolean\"}\n",
        "\n",
        "local_features_names = []\n",
        "if emo_count_local: local_features_names.append('emotions')\n",
        "if empathy_count_local: local_features_names.append('empathy')\n",
        "if distress_count_local: local_features_names.append('distress')\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n3snAqfK6728",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.447304Z",
          "iopub.status.idle": "2023-07-11T14:25:05.448055Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.447785Z",
          "shell.execute_reply": "2023-07-11T14:25:05.447832Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Number of labels\n",
        "num_labels = 8 #@param {type:\"number\"}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7JyTdDiw9TWP",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.449348Z",
          "iopub.status.idle": "2023-07-11T14:25:05.450050Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.449812Z",
          "shell.execute_reply": "2023-07-11T14:25:05.449835Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_LABELS = num_labels\n",
        "GLOBAL_FEATURES_NAMES = global_features_names\n",
        "LOCAL_FEATURES_NAMES = local_features_names\n",
        "DIM_EXTRA_FEATURES_GLOBAL = len(GLOBAL_FEATURES_NAMES)"
      ],
      "metadata": {
        "id": "dA224FxADpqd",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.451323Z",
          "iopub.status.idle": "2023-07-11T14:25:05.452081Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.451840Z",
          "shell.execute_reply": "2023-07-11T14:25:05.451866Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extra global features"
      ],
      "metadata": {
        "id": "FbCKVWh7-gpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_train =  np.array(train_df[GLOBAL_FEATURES_NAMES])\n",
        "features_val =  np.array(val_df[GLOBAL_FEATURES_NAMES])\n",
        "features_dev =  np.array(dev_df[GLOBAL_FEATURES_NAMES])"
      ],
      "metadata": {
        "id": "RDqlrqx6-gDt",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.453312Z",
          "iopub.status.idle": "2023-07-11T14:25:05.454050Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.453812Z",
          "shell.execute_reply": "2023-07-11T14:25:05.453836Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lexicons"
      ],
      "metadata": {
        "id": "qwYXJId_-Sb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/EMO23_lexicon_per_word_train.json\") as json_file:\n",
        "  EMO_lexicon_train_dict = json.load(json_file)\n",
        "with open(\"/content/EMP23_lexicon_per_word_train.json\") as json_file:\n",
        "  EMP_lexicon_train_dict = json.load(json_file)\n",
        "\n",
        "with open(\"/content/EMO23_lexicon_per_word_dev.json\") as json_file:\n",
        "  EMO_lexicon_dev_dict = json.load(json_file)\n",
        "with open(\"/content/EMP23_lexicon_per_word_dev.json\") as json_file:\n",
        "  EMP_lexicon_dev_dict = json.load(json_file)\n",
        "with open(\"/content/EMO23_lexicon_per_word_test.json\") as json_file:\n",
        "  EMO_lexicon_test_dict = json.load(json_file)\n",
        "with open(\"/content/EMP23_lexicon_per_word_test.json\") as json_file:\n",
        "  EMP_lexicon_test_dict = json.load(json_file)"
      ],
      "metadata": {
        "id": "Qg0D38kk-Rrv",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.455320Z",
          "iopub.status.idle": "2023-07-11T14:25:05.456052Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.455816Z",
          "shell.execute_reply": "2023-07-11T14:25:05.455839Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "oXIimY5ABmlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_type ={\n",
        "  'distilroberta-emotion':'j-hartmann/emotion-english-distilroberta-base',\n",
        "  'roberta-emotion':'j-hartmann/emotion-english-roberta-large',\n",
        "  'bert-base':'bert-base-cased',\n",
        "  'roberta-base' : 'bert-base'\n",
        "}"
      ],
      "metadata": {
        "id": "wtbV4tekujaC",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.457327Z",
          "iopub.status.idle": "2023-07-11T14:25:05.458047Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.457798Z",
          "shell.execute_reply": "2023-07-11T14:25:05.457835Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {\n",
        "    'model_id': 'roberta_lexicon',\n",
        "    'tokenizer_name': model_type.get('bert-base'),\n",
        "    'model_name': model_type.get('bert-base'),\n",
        "    'train_batch_size': 4,\n",
        "    'val_batch_size': 4,\n",
        "    'learning_rate': 5e-5,\n",
        "    'weight_decay': 0,\n",
        "    'epochs': 10,\n",
        "    'seed': 42,\n",
        "    'patience': 10,\n",
        "    'early_stopping_threshold': 0,\n",
        "    'weighted_loss': True\n",
        "}"
      ],
      "metadata": {
        "id": "Cxq0isZT6KQW",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.459326Z",
          "iopub.status.idle": "2023-07-11T14:25:05.460074Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.459813Z",
          "shell.execute_reply": "2023-07-11T14:25:05.459861Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_weights(y):\n",
        "  inverse_n_samples = 1 / np.sum(y, axis=0)\n",
        "  sum_inverses = sum(inverse_n_samples)\n",
        "  weights_train = inverse_n_samples / sum_inverses\n",
        "  return torch.cuda.FloatTensor(weights_train)"
      ],
      "metadata": {
        "id": "hfwVaaj-0qDq",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.461371Z",
          "iopub.status.idle": "2023-07-11T14:25:05.462108Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.461860Z",
          "shell.execute_reply": "2023-07-11T14:25:05.461887Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model_config.get('weighted_loss'):\n",
        "  loss_weights_train = get_loss_weights(y_train)\n"
      ],
      "metadata": {
        "id": "wVh3_jCFzmK7",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.463382Z",
          "iopub.status.idle": "2023-07-11T14:25:05.464083Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.463838Z",
          "shell.execute_reply": "2023-07-11T14:25:05.463862Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_config['tokenizer_name'], truncation=True)"
      ],
      "metadata": {
        "id": "wd7W2HhYsbai",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.465379Z",
          "iopub.status.idle": "2023-07-11T14:25:05.466080Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.465833Z",
          "shell.execute_reply": "2023-07-11T14:25:05.465856Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom \"lexicon\" model"
      ],
      "metadata": {
        "id": "w6aAhPift1UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
        "\n",
        "    def __init__(self, config, num_extra_dims, hidden_layers_to_concat, classifier_dropout):\n",
        "        super().__init__()\n",
        "        total_dims = (config.hidden_size*hidden_layers_to_concat)+num_extra_dims\n",
        "        self.dense = nn.Linear(total_dims, total_dims)\n",
        "        self.dropout = nn.Dropout(classifier_dropout)\n",
        "        self.out_proj = nn.Linear(total_dims, config.num_labels)\n",
        "\n",
        "    def forward(self, features, **kwargs):\n",
        "        x = self.dense(features)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.out_proj(x)\n",
        "        return x\n",
        "\n",
        "class CustomSequenceClassification(BertForSequenceClassification):\n",
        "\n",
        "    def __init__(self, config, num_extra_dims, local_features_name, loss_weights, last_cls = 1, mean_last_cls = False):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.config = config\n",
        "        self.local_features_name = local_features_name\n",
        "        self.loss_weights = loss_weights\n",
        "        self.last_cls = last_cls\n",
        "        self.mean_last_cls = mean_last_cls\n",
        "\n",
        "        # might need to rename this depending on the model\n",
        "        self.bert =  BertModel(config)\n",
        "        classifier_dropout = (\n",
        "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
        "        )\n",
        "        self.dropout = nn.Dropout(classifier_dropout)\n",
        "        self.classifier = ClassificationHead(config, num_extra_dims, last_cls, classifier_dropout)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.LongTensor] = None,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "\n",
        "\n",
        "        local_features = None,\n",
        "        global_features = None,\n",
        "\n",
        "        token_type_ids: Optional[torch.LongTensor] = None,\n",
        "        position_ids: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = True,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
        "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
        "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        cls_tokens = []\n",
        "        for i in range(1, self.last_cls + 1):\n",
        "            cls_tokens.append(outputs.hidden_states[-1 * i][:, 0, :])\n",
        "        if self.mean_last_cls:\n",
        "          # average cls tokens\n",
        "          output = torch.mean(torch.stack(cls_tokens), dim=0)\n",
        "        else:\n",
        "          # concat cls tokens\n",
        "          output = torch.cat(cls_tokens, dim=1)\n",
        "\n",
        "        #sequence_output = outputs[0]\n",
        "        #output = sequence_output[:, 0, :]\n",
        "\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        if local_features is not None:\n",
        "          output = outputs.last_hidden_state\n",
        "          output = self.dropout(output)\n",
        "\n",
        "          output = torch.cat((\n",
        "                  output,\n",
        "                  local_features.reshape(outputs.last_hidden_state.shape[0], outputs.last_hidden_state.shape[1], -1)),\n",
        "                             dim=2)\n",
        "\n",
        "          mask = torch.zeros_like(attention_mask)\n",
        "          # unmask cls token\n",
        "          mask[:,0] = 1.0\n",
        "          # unmask tokens with high or low empathy, high distress levels, or expressing at least one emotion\n",
        "          j = 0\n",
        "          if 'emotions' in self.local_features_name:\n",
        "            emotion_values = local_features[:,:,:11]\n",
        "            mask[emotion_values.sum(dim=-1)>=1] = 1.0\n",
        "            j += 11\n",
        "\n",
        "          if 'empathy' in self.local_features_name:\n",
        "            empathy_values = local_features[:,:,j]\n",
        "            mask[(empathy_values>5) | ((empathy_values<3) & (empathy_values>=1))] = 1.0\n",
        "            j += 1\n",
        "\n",
        "          if 'distress' in self.local_features_name:\n",
        "            distress_values = local_features[:,:,j]\n",
        "            mask[distress_values>4] = 1.0\n",
        "\n",
        "\n",
        "\n",
        "          # mean pooling of unmasked tokens\n",
        "          output = outputs.last_hidden_state\n",
        "          input_mask_expanded = mask.unsqueeze(-1).expand(output.size()).float()\n",
        "          sum_embeddings = torch.sum(output * input_mask_expanded, 1)\n",
        "          sum_mask = input_mask_expanded.sum(1)\n",
        "          sum_mask = torch.clamp(sum_mask, min = 1e-9)\n",
        "          output = sum_embeddings/sum_mask\n",
        "\n",
        "\n",
        "        if global_features is not None: #global\n",
        "          output = torch.cat((output, global_features), dim=-1)\n",
        "\n",
        "        logits = self.classifier(output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.config.problem_type is None:\n",
        "                if self.num_labels == 1:\n",
        "                    self.config.problem_type = \"regression\"\n",
        "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
        "                    self.config.problem_type = \"single_label_classification\"\n",
        "                else:\n",
        "                    self.config.problem_type = \"multi_label_classification\"\n",
        "\n",
        "            if self.config.problem_type == \"regression\":\n",
        "                loss_fct = nn.MSELoss()\n",
        "                if self.num_labels == 1:\n",
        "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
        "                else:\n",
        "                    loss = loss_fct(logits, labels)\n",
        "            elif self.config.problem_type == \"single_label_classification\":\n",
        "                loss_fct = nn.CrossEntropyLoss(weight = self.loss_weights)\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            elif self.config.problem_type == \"multi_label_classification\":\n",
        "                loss_fct = nn.BCEWithLogitsLoss(weight = self.loss_weights)\n",
        "                loss = loss_fct(logits, labels)\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )"
      ],
      "metadata": {
        "id": "2Vj3W-oUhBMZ",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.467469Z",
          "iopub.status.idle": "2023-07-11T14:25:05.468173Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.467928Z",
          "shell.execute_reply": "2023-07-11T14:25:05.467950Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomSequenceClassification.from_pretrained(model_config.get(\"model_name\"),\n",
        "                                                     num_labels=NUM_LABELS,\n",
        "                                                     classifier_dropout=0.1,\n",
        "                                                     num_extra_dims = DIM_EXTRA_FEATURES_GLOBAL,\n",
        "                                                     local_features_name = LOCAL_FEATURES_NAMES,\n",
        "                                                     loss_weights = loss_weights_train\n",
        "                                                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvJbF80XhSDE",
        "outputId": "8ae100a8-eb7e-4e58-fc4a-13d6ca8d2725",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.469469Z",
          "iopub.status.idle": "2023-07-11T14:25:05.470174Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.469927Z",
          "shell.execute_reply": "2023-07-11T14:25:05.469950Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing CustomSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing CustomSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "9xvHbhOhhttG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare datasets"
      ],
      "metadata": {
        "id": "bY0SLN6usjYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = WASSADataset(tokenizer=tokenizer,\n",
        "                       EMO_lexicon=EMO_lexicon_train_dict,\n",
        "                       EMP_lexicon=EMP_lexicon_train_dict,\n",
        "                       essay=train_df.essay,\n",
        "                       essay_id = train_df.essay_id,\n",
        "                       targets=y_train,\n",
        "                       global_features = features_train,\n",
        "                       local_emotions = True,\n",
        "                       local_empathy = True,\n",
        "                       local_distress = True)\n",
        "\n",
        "val_set = WASSADataset(tokenizer=tokenizer,\n",
        "                     EMO_lexicon=EMO_lexicon_train_dict,\n",
        "                     EMP_lexicon=EMP_lexicon_train_dict,\n",
        "                     essay=val_df.essay,\n",
        "                     essay_id = val_df.essay_id,\n",
        "                     targets=y_val,\n",
        "                     global_features = features_val,\n",
        "                     local_emotions = True,\n",
        "                     local_empathy = True,\n",
        "                     local_distress = True)"
      ],
      "metadata": {
        "id": "DUIqO6AiZ8al",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.471460Z",
          "iopub.status.idle": "2023-07-11T14:25:05.472164Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.471920Z",
          "shell.execute_reply": "2023-07-11T14:25:05.471943Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up training"
      ],
      "metadata": {
        "id": "rvduRx8HsteS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_arguments = TrainingArguments(\n",
        "    output_dir=f\"./{model_config['model_name']}\",\n",
        "    per_device_train_batch_size=model_config['train_batch_size'],\n",
        "    per_device_eval_batch_size=model_config['val_batch_size'],\n",
        "    num_train_epochs=model_config['epochs'],\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    eval_steps = 300,\n",
        "    save_steps = 300,\n",
        "    learning_rate=model_config['learning_rate'],\n",
        "    weight_decay=model_config['weight_decay'],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        "    seed=model_config['seed'],\n",
        "    logging_strategy = \"epoch\"\n",
        ") # TODO: custom other params"
      ],
      "metadata": {
        "id": "Z1DbZxhkD1R7",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.473478Z",
          "iopub.status.idle": "2023-07-11T14:25:05.474174Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.473938Z",
          "shell.execute_reply": "2023-07-11T14:25:05.473960Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=train_arguments,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=val_set,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_EMO_metrics_trainer\n",
        ")"
      ],
      "metadata": {
        "id": "hrI2rj4U3K2Q",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.475628Z",
          "iopub.status.idle": "2023-07-11T14:25:05.476352Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.476073Z",
          "shell.execute_reply": "2023-07-11T14:25:05.476097Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c986f492-1942-4664-a762-8ad11a541140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dentro len\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks"
      ],
      "metadata": {
        "id": "A-sruHQdsraI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainerLoggingCallback(TrainerCallback):\n",
        "    def __init__(self, log_path):\n",
        "        self.log_path = log_path\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        _ = logs.pop(\"total_flos\", None)\n",
        "        if state.is_local_process_zero: # whether this process is the main one in a distributed setting\n",
        "            with open(self.log_path, \"a\") as f:\n",
        "                f.write(json.dumps(logs) + \"\\n\")\n",
        "\n",
        "trainer.add_callback(EarlyStoppingCallback(\n",
        "    early_stopping_patience=model_config['patience'],\n",
        "    early_stopping_threshold=model_config['early_stopping_threshold']))\n",
        "\n",
        "trainer.add_callback(TrainerLoggingCallback(model_config['model_id']+\"_log.json\"))"
      ],
      "metadata": {
        "id": "4kUY7tU3sqr3",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.477624Z",
          "iopub.status.idle": "2023-07-11T14:25:05.478365Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.478091Z",
          "shell.execute_reply": "2023-07-11T14:25:05.478114Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start training"
      ],
      "metadata": {
        "id": "dcCqSooFsw0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L8xAPa81D5tu",
        "outputId": "db2fcdf1-1c3f-4c6d-843f-41302850b5ac",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.479651Z",
          "iopub.status.idle": "2023-07-11T14:25:05.480348Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.480097Z",
          "shell.execute_reply": "2023-07-11T14:25:05.480120Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1550' max='1550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1550/1550 12:21, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Sklearn Accuracy</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Micro F</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "      <th>Macro F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.028200</td>\n",
              "      <td>0.020074</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.018100</td>\n",
              "      <td>0.020010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>0.020017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.018000</td>\n",
              "      <td>0.019968</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>0.019977</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n",
            "dentro len\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dentro len\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1550, training_loss=0.019029162006993446, metrics={'train_runtime': 742.8613, 'train_samples_per_second': 8.319, 'train_steps_per_second': 2.087, 'train_loss': 0.019029162006993446, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(EMO_lexicon_train_dict[\"4\"]['fear'])"
      ],
      "metadata": {
        "id": "l22RjgsEtAm0",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.481641Z",
          "iopub.status.idle": "2023-07-11T14:25:05.482369Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.482122Z",
          "shell.execute_reply": "2023-07-11T14:25:05.482146Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba73184-64bb-4cd0-f2ee-b7a35ea31f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(EMP_lexicon_train_dict[\"4\"]['empathy'])"
      ],
      "metadata": {
        "id": "TFz1Azm7jqrM",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.483617Z",
          "iopub.status.idle": "2023-07-11T14:25:05.484321Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.484086Z",
          "shell.execute_reply": "2023-07-11T14:25:05.484110Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c725a8-873e-424a-cbcb-83b4e3a10fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the training logs\n",
        "train_logs = trainer.state.log_history\n",
        "\n",
        "# Extract the loss values from the logs\n",
        "train_loss_values = [log.get('loss') for log in train_logs if log.get('loss') is not None]\n",
        "eval_loss_values = [log.get('eval_loss') for log in train_logs if log.get('eval_loss') is not None]\n",
        "train_epochs = [log.get('epoch') for log in train_logs if log.get('loss') is not None]\n",
        "eval_epochs = [log.get('epoch') for log in train_logs if log.get('eval_loss') is not None]"
      ],
      "metadata": {
        "id": "Dd-3octehTlH",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.485624Z",
          "iopub.status.idle": "2023-07-11T14:25:05.486312Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.486072Z",
          "shell.execute_reply": "2023-07-11T14:25:05.486096Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_logs"
      ],
      "metadata": {
        "id": "C7mO8pWYK-y3",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.487606Z",
          "iopub.status.idle": "2023-07-11T14:25:05.488315Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.488081Z",
          "shell.execute_reply": "2023-07-11T14:25:05.488105Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcaee634-62e4-4cf9-d115-1e01bc558ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'loss': 0.0282, 'learning_rate': 4.5e-05, 'epoch': 1.0, 'step': 155},\n",
              " {'eval_loss': 0.020074021071195602,\n",
              "  'eval_sklearn_accuracy': 0.0,\n",
              "  'eval_roc_auc_micro': 0.5,\n",
              "  'eval_accuracy': 0.0,\n",
              "  'eval_micro_precision': 0.0,\n",
              "  'eval_micro_recall': 0.0,\n",
              "  'eval_micro_f': 0.0,\n",
              "  'eval_macro_precision': 0.0,\n",
              "  'eval_macro_recall': 0.0,\n",
              "  'eval_macro_f': 0.0,\n",
              "  'eval_runtime': 10.4102,\n",
              "  'eval_samples_per_second': 15.562,\n",
              "  'eval_steps_per_second': 3.938,\n",
              "  'epoch': 1.94,\n",
              "  'step': 300},\n",
              " {'loss': 0.0183, 'learning_rate': 4e-05, 'epoch': 2.0, 'step': 310},\n",
              " {'loss': 0.0181, 'learning_rate': 3.5e-05, 'epoch': 3.0, 'step': 465},\n",
              " {'eval_loss': 0.020009759813547134,\n",
              "  'eval_sklearn_accuracy': 0.0,\n",
              "  'eval_roc_auc_micro': 0.5,\n",
              "  'eval_accuracy': 0.0,\n",
              "  'eval_micro_precision': 0.0,\n",
              "  'eval_micro_recall': 0.0,\n",
              "  'eval_micro_f': 0.0,\n",
              "  'eval_macro_precision': 0.0,\n",
              "  'eval_macro_recall': 0.0,\n",
              "  'eval_macro_f': 0.0,\n",
              "  'eval_runtime': 9.7816,\n",
              "  'eval_samples_per_second': 16.562,\n",
              "  'eval_steps_per_second': 4.192,\n",
              "  'epoch': 3.87,\n",
              "  'step': 600},\n",
              " {'loss': 0.018, 'learning_rate': 3e-05, 'epoch': 4.0, 'step': 620},\n",
              " {'loss': 0.0179, 'learning_rate': 2.5e-05, 'epoch': 5.0, 'step': 775},\n",
              " {'eval_loss': 0.020016588270664215,\n",
              "  'eval_sklearn_accuracy': 0.0,\n",
              "  'eval_roc_auc_micro': 0.5,\n",
              "  'eval_accuracy': 0.0,\n",
              "  'eval_micro_precision': 0.0,\n",
              "  'eval_micro_recall': 0.0,\n",
              "  'eval_micro_f': 0.0,\n",
              "  'eval_macro_precision': 0.0,\n",
              "  'eval_macro_recall': 0.0,\n",
              "  'eval_macro_f': 0.0,\n",
              "  'eval_runtime': 9.6584,\n",
              "  'eval_samples_per_second': 16.773,\n",
              "  'eval_steps_per_second': 4.245,\n",
              "  'epoch': 5.81,\n",
              "  'step': 900},\n",
              " {'loss': 0.0181, 'learning_rate': 2e-05, 'epoch': 6.0, 'step': 930},\n",
              " {'loss': 0.018, 'learning_rate': 1.5e-05, 'epoch': 7.0, 'step': 1085},\n",
              " {'eval_loss': 0.019968057051301003,\n",
              "  'eval_sklearn_accuracy': 0.0,\n",
              "  'eval_roc_auc_micro': 0.5,\n",
              "  'eval_accuracy': 0.0,\n",
              "  'eval_micro_precision': 0.0,\n",
              "  'eval_micro_recall': 0.0,\n",
              "  'eval_micro_f': 0.0,\n",
              "  'eval_macro_precision': 0.0,\n",
              "  'eval_macro_recall': 0.0,\n",
              "  'eval_macro_f': 0.0,\n",
              "  'eval_runtime': 9.5466,\n",
              "  'eval_samples_per_second': 16.969,\n",
              "  'eval_steps_per_second': 4.295,\n",
              "  'epoch': 7.74,\n",
              "  'step': 1200},\n",
              " {'loss': 0.018, 'learning_rate': 1e-05, 'epoch': 8.0, 'step': 1240},\n",
              " {'loss': 0.0179, 'learning_rate': 5e-06, 'epoch': 9.0, 'step': 1395},\n",
              " {'eval_loss': 0.019977137446403503,\n",
              "  'eval_sklearn_accuracy': 0.0,\n",
              "  'eval_roc_auc_micro': 0.5,\n",
              "  'eval_accuracy': 0.0,\n",
              "  'eval_micro_precision': 0.0,\n",
              "  'eval_micro_recall': 0.0,\n",
              "  'eval_micro_f': 0.0,\n",
              "  'eval_macro_precision': 0.0,\n",
              "  'eval_macro_recall': 0.0,\n",
              "  'eval_macro_f': 0.0,\n",
              "  'eval_runtime': 9.8064,\n",
              "  'eval_samples_per_second': 16.52,\n",
              "  'eval_steps_per_second': 4.181,\n",
              "  'epoch': 9.68,\n",
              "  'step': 1500},\n",
              " {'loss': 0.0179, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 1550},\n",
              " {'train_runtime': 742.8613,\n",
              "  'train_samples_per_second': 8.319,\n",
              "  'train_steps_per_second': 2.087,\n",
              "  'total_flos': 1637860407091200.0,\n",
              "  'train_loss': 0.019029162006993446,\n",
              "  'epoch': 10.0,\n",
              "  'step': 1550}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curve(train_loss_values, eval_loss_values, loss_epochs, eval_epochs,\"loss\", f\"{model_config['model_name']}_loss.png\")"
      ],
      "metadata": {
        "id": "ECEu3ajRl6k3",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.489595Z",
          "iopub.status.idle": "2023-07-11T14:25:05.490319Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.490076Z",
          "shell.execute_reply": "2023-07-11T14:25:05.490099Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "cd0da222-c360-4fe8-decb-db350185d763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'plot_loss_curve'\u001b[0m is not defined\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'plot_loss_curve'</span> is not defined\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "Rc5stfSah0Kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotions(results, gold_emotions):\n",
        "\n",
        "  binarized_predictions = np.where(results.predictions >= 0.5, 1, 0)\n",
        "\n",
        "  for i, bin_pred in enumerate(binarized_predictions):\n",
        "    if np.all(bin_pred==0):\n",
        "      binarized_predictions[i][np.argmax(results.predictions[i])] = 1\n",
        "\n",
        "  predicted_emotions = label_encoder.decode(binarized_predictions)\n",
        "  return predicted_emotions\n"
      ],
      "metadata": {
        "id": "19G80dVoH3HZ",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.491654Z",
          "iopub.status.idle": "2023-07-11T14:25:05.492339Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.492094Z",
          "shell.execute_reply": "2023-07-11T14:25:05.492117Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.state.best_model_checkpoint"
      ],
      "metadata": {
        "id": "2YlWuaKoRH5r",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.493661Z",
          "iopub.status.idle": "2023-07-11T14:25:05.494357Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.494103Z",
          "shell.execute_reply": "2023-07-11T14:25:05.494125Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nKipfvn9MPT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outs = trainer.predict(dev_set)"
      ],
      "metadata": {
        "id": "S35gRAI-D8cY",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.495633Z",
          "iopub.status.idle": "2023-07-11T14:25:05.496310Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.496073Z",
          "shell.execute_reply": "2023-07-11T14:25:05.496095Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gold_emotions = gold_emotions = label_encoder.decode(outs.label_ids)\n",
        "predicted_emotions = predict_emotions(outs, gold_emotions)"
      ],
      "metadata": {
        "id": "PIKGrBNlYDa1",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.497630Z",
          "iopub.status.idle": "2023-07-11T14:25:05.498322Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.498085Z",
          "shell.execute_reply": "2023-07-11T14:25:05.498108Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_EMO_predictions(predicted_emotions, model_config['model_id']+\"_predictions_EMO.tsv\")\n",
        "challenge_metrics = compute_EMO_metrics(golds=gold_emotions, predictions=predicted_emotions)\n",
        "write_dict_to_json(challenge_metrics, model_config['model_id']+\"_dev_metrics.json\")\n",
        "challenge_metrics"
      ],
      "metadata": {
        "id": "Im2VGnmQs7bY",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.499767Z",
          "iopub.status.idle": "2023-07-11T14:25:05.500464Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.500210Z",
          "shell.execute_reply": "2023-07-11T14:25:05.500233Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(golds=gold_emotions, predictions=predicted_emotions, path=model_config['model_id']+\"_confusion_matrix.pdf\", title=model_config['model_id'])"
      ],
      "metadata": {
        "id": "ITunC36XXLoN",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.501754Z",
          "iopub.status.idle": "2023-07-11T14:25:05.502443Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.502193Z",
          "shell.execute_reply": "2023-07-11T14:25:05.502215Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the desired label names\n",
        "label_names = ['Anger', 'Disgust', 'Fear', 'Hope', 'Joy', 'Neutral', 'Sadness', 'Surprise']\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(gold_emotions, predicted_emotions, labels=label_names)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(cm, cmap='Blues')\n",
        "\n",
        "# Customize the plot\n",
        "ax.set_xticks(np.arange(len(label_names)))\n",
        "ax.set_yticks(np.arange(len(label_names)))\n",
        "ax.set_xticklabels(label_names, rotation=45)\n",
        "ax.set_yticklabels(label_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "\n",
        "# Add numbers in each cell\n",
        "for i in range(len(label_names)):\n",
        "    for j in range(len(label_names)):\n",
        "        text = ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"w\")\n",
        "\n",
        "# Add colorbar\n",
        "cbar = ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NNDV2IPmgaWy",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.503765Z",
          "iopub.status.idle": "2023-07-11T14:25:05.504457Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.504206Z",
          "shell.execute_reply": "2023-07-11T14:25:05.504229Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model_graph(model=model, input_data=tokenizer(\"Hello world!\", return_tensors=\"pt\"), path=model_config['model_id']+\"_graph\")"
      ],
      "metadata": {
        "id": "TJHxnmO7v8SJ",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.505749Z",
          "iopub.status.idle": "2023-07-11T14:25:05.506449Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.506191Z",
          "shell.execute_reply": "2023-07-11T14:25:05.506214Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_model_summary(model=model, path=model_config['model_id']+\"_summary.txt\")"
      ],
      "metadata": {
        "id": "K33Q2SfFwR30",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.507738Z",
          "iopub.status.idle": "2023-07-11T14:25:05.508435Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.508177Z",
          "shell.execute_reply": "2023-07-11T14:25:05.508199Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model on Google Drive"
      ],
      "metadata": {
        "id": "7DuCaju6tSHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.state.best_model_checkpoint"
      ],
      "metadata": {
        "id": "QtK-k5ITtRzN",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.509756Z",
          "iopub.status.idle": "2023-07-11T14:25:05.510519Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.510238Z",
          "shell.execute_reply": "2023-07-11T14:25:05.510277Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv $trainer.state.best_model_checkpoint /content/drive/MyDrive/hlt"
      ],
      "metadata": {
        "id": "b1KcxQQ0uUl6",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.511944Z",
          "iopub.status.idle": "2023-07-11T14:25:05.512653Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.512396Z",
          "shell.execute_reply": "2023-07-11T14:25:05.512419Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "9pkHv9w4tM1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"/content/drive/MyDrive/hlt/best-roberta\""
      ],
      "metadata": {
        "id": "v6hEtBLztMeC",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.513920Z",
          "iopub.status.idle": "2023-07-11T14:25:05.514634Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.514369Z",
          "shell.execute_reply": "2023-07-11T14:25:05.514392Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, truncation=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    num_labels=NUM_LABELS,\n",
        "    ignore_mismatched_sizes=True,\n",
        "    problem_type=\"multi_label_classification\")"
      ],
      "metadata": {
        "id": "hWFw9keWvCy3",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.515931Z",
          "iopub.status.idle": "2023-07-11T14:25:05.516643Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.516384Z",
          "shell.execute_reply": "2023-07-11T14:25:05.516408Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load checkpoint"
      ],
      "metadata": {
        "id": "Xi38gs-o1IGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the checkpoint file\n",
        "checkpoint_file = \"/content/roberta-base/checkpoint-1200\"\n",
        "#model = AutoModelForSequenceClassification.from_pretrained(checkpoint_file, num_labels=NUM_LABELS)\n",
        "model = CustomSequenceClassification.from_pretrained(checkpoint_file, num_labels=NUM_LABELS, num_extra_dims = 10)\n",
        "trainer = Trainer(model=model)\n",
        "# Perform prediction using the loaded checkpoint\n",
        "predictions = trainer.predict(dev_set)"
      ],
      "metadata": {
        "id": "ncPpGans0XIG",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.517942Z",
          "iopub.status.idle": "2023-07-11T14:25:05.518654Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.518396Z",
          "shell.execute_reply": "2023-07-11T14:25:05.518419Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gold_emotions = label_encoder.decode(predictions.label_ids)\n",
        "predicted_emotions = predict_emotions(predictions, gold_emotions)"
      ],
      "metadata": {
        "id": "dOOGuVrJ00R2",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.519925Z",
          "iopub.status.idle": "2023-07-11T14:25:05.520633Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.520375Z",
          "shell.execute_reply": "2023-07-11T14:25:05.520398Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_EMO_predictions(predicted_emotions, model_config['model_id']+\"_predictions_EMO.tsv\")\n",
        "challenge_metrics = compute_EMO_metrics(golds=gold_emotions, predictions=predicted_emotions)\n",
        "write_dict_to_json(challenge_metrics, model_config['model_id']+\"_dev_metrics.json\")\n",
        "challenge_metrics"
      ],
      "metadata": {
        "id": "rWWcct0E06bQ",
        "execution": {
          "iopub.status.busy": "2023-07-11T14:25:05.522375Z",
          "iopub.status.idle": "2023-07-11T14:25:05.523115Z",
          "shell.execute_reply.started": "2023-07-11T14:25:05.522880Z",
          "shell.execute_reply": "2023-07-11T14:25:05.522903Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}