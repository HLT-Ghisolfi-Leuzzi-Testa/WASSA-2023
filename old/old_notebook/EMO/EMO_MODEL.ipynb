{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_B-_QwdhWLe"
      },
      "source": [
        "# WASSA2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:04:39.939508Z",
          "iopub.status.busy": "2023-07-11T19:04:39.938937Z",
          "iopub.status.idle": "2023-07-11T19:04:39.955669Z",
          "shell.execute_reply": "2023-07-11T19:04:39.954582Z",
          "shell.execute_reply.started": "2023-07-11T19:04:39.939467Z"
        },
        "id": "9sDeMksltGSk",
        "outputId": "ce4c81fc-86ed-4b2f-de76-a4f1118f138a",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15KoBLrVhbI8"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FTWi38mQKxUK"
      },
      "outputs": [],
      "source": [
        "repo_path = \"https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/\"\n",
        "branch = \"main\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:04:39.958361Z",
          "iopub.status.busy": "2023-07-11T19:04:39.958022Z",
          "iopub.status.idle": "2023-07-11T19:06:28.298280Z",
          "shell.execute_reply": "2023-07-11T19:06:28.297057Z",
          "shell.execute_reply.started": "2023-07-11T19:04:39.958330Z"
        },
        "id": "1gnWTVNYDMx2",
        "outputId": "e46f1371-c209-4815-8a27-0028d88fece5",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for NRCLex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers -q\n",
        "!pip install accelerate -U -q\n",
        "!pip install datasets -q\n",
        "!pip install torch-summary -q\n",
        "!pip install graphviz -q\n",
        "!pip install torchview -q\n",
        "!pip install bertviz -q\n",
        "!pip install NRCLex -q\n",
        "!pip install textblob -q\n",
        "!python -m textblob.download_corpora -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:28.300542Z",
          "iopub.status.busy": "2023-07-11T19:06:28.299931Z",
          "iopub.status.idle": "2023-07-11T19:06:30.619028Z",
          "shell.execute_reply": "2023-07-11T19:06:30.617896Z",
          "shell.execute_reply.started": "2023-07-11T19:06:28.300504Z"
        },
        "id": "9Xbo-Ei3IAYB",
        "outputId": "8cbe3879-e85b-4219-f306-16819eb9fb42",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-13 12:45:38--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27866 (27K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "\rutils.py              0%[                    ]       0  --.-KB/s               \rutils.py            100%[===================>]  27.21K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-13 12:45:38 (157 MB/s) - ‘utils.py’ saved [27866/27866]\n",
            "\n",
            "--2023-07-13 12:45:38--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/evaluation.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10675 (10K) [text/plain]\n",
            "Saving to: ‘evaluation.py’\n",
            "\n",
            "evaluation.py       100%[===================>]  10.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-13 12:45:38 (109 MB/s) - ‘evaluation.py’ saved [10675/10675]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "utils_url = f\"{repo_path}{branch}/utils.py\"\n",
        "evaluation_url = f\"{repo_path}{branch}/evaluation.py\"\n",
        "\n",
        "import os\n",
        "if os.path.exists(\"utils.py\"):\n",
        "  !rm \"utils.py\"\n",
        "if os.path.exists(\"evaluation.py\"):\n",
        "  !rm \"evaluation.py\"\n",
        "\n",
        "!wget {utils_url}\n",
        "!wget {evaluation_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:30.622919Z",
          "iopub.status.busy": "2023-07-11T19:06:30.622582Z",
          "iopub.status.idle": "2023-07-11T19:06:38.755450Z",
          "shell.execute_reply": "2023-07-11T19:06:38.754266Z",
          "shell.execute_reply.started": "2023-07-11T19:06:30.622890Z"
        },
        "id": "kEVk5afqZjf1",
        "outputId": "2416969b-c2ef-4842-a12a-4db7c795c15e",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-13 12:45:38--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMO23_lexicon_per_word_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13477977 (13M) [text/plain]\n",
            "Saving to: ‘EMO23_lexicon_per_word_train.json’\n",
            "\n",
            "\r          EMO23_lex   0%[                    ]       0  --.-KB/s               \rEMO23_lexicon_per_w 100%[===================>]  12.85M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-07-13 12:45:38 (295 MB/s) - ‘EMO23_lexicon_per_word_train.json’ saved [13477977/13477977]\n",
            "\n",
            "--2023-07-13 12:45:38--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMP23_lexicon_per_word_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7607723 (7.3M) [text/plain]\n",
            "Saving to: ‘EMP23_lexicon_per_word_train.json’\n",
            "\n",
            "EMP23_lexicon_per_w 100%[===================>]   7.25M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-07-13 12:45:38 (242 MB/s) - ‘EMP23_lexicon_per_word_train.json’ saved [7607723/7607723]\n",
            "\n",
            "--2023-07-13 12:45:38--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMO23_lexicon_per_word_dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1058526 (1.0M) [text/plain]\n",
            "Saving to: ‘EMO23_lexicon_per_word_dev.json’\n",
            "\n",
            "EMO23_lexicon_per_w 100%[===================>]   1.01M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-07-13 12:45:38 (70.7 MB/s) - ‘EMO23_lexicon_per_word_dev.json’ saved [1058526/1058526]\n",
            "\n",
            "--2023-07-13 12:45:38--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMP23_lexicon_per_word_dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 595839 (582K) [text/plain]\n",
            "Saving to: ‘EMP23_lexicon_per_word_dev.json’\n",
            "\n",
            "EMP23_lexicon_per_w 100%[===================>] 581.87K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2023-07-13 12:45:38 (154 MB/s) - ‘EMP23_lexicon_per_word_dev.json’ saved [595839/595839]\n",
            "\n",
            "--2023-07-13 12:45:38--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMO23_lexicon_per_word_test.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 651198 (636K) [text/plain]\n",
            "Saving to: ‘EMO23_lexicon_per_word_test.json’\n",
            "\n",
            "EMO23_lexicon_per_w 100%[===================>] 635.94K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2023-07-13 12:45:39 (139 MB/s) - ‘EMO23_lexicon_per_word_test.json’ saved [651198/651198]\n",
            "\n",
            "--2023-07-13 12:45:39--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMP23_lexicon_per_word_test.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 362281 (354K) [text/plain]\n",
            "Saving to: ‘EMP23_lexicon_per_word_test.json’\n",
            "\n",
            "EMP23_lexicon_per_w 100%[===================>] 353.79K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2023-07-13 12:45:39 (38.4 MB/s) - ‘EMP23_lexicon_per_word_test.json’ saved [362281/362281]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EMO_json_path_train = f\"{repo_path}{branch}/datasets/EMO23_lexicon_per_word_train.json\"\n",
        "EMP_json_path_train = f\"{repo_path}{branch}/datasets/EMP23_lexicon_per_word_train.json\"\n",
        "EMO_json_path_dev = f\"{repo_path}{branch}/datasets/EMO23_lexicon_per_word_dev.json\"\n",
        "EMP_json_path_dev = f\"{repo_path}{branch}/datasets/EMP23_lexicon_per_word_dev.json\"\n",
        "EMO_json_path_test = f\"{repo_path}{branch}/datasets/EMO23_lexicon_per_word_test.json\"\n",
        "EMP_json_path_test = f\"{repo_path}{branch}/datasets/EMP23_lexicon_per_word_test.json\"\n",
        "\n",
        "!wget {EMO_json_path_train}\n",
        "!wget {EMP_json_path_train}\n",
        "!wget {EMO_json_path_dev}\n",
        "!wget {EMP_json_path_dev}\n",
        "!wget {EMO_json_path_test}\n",
        "!wget {EMP_json_path_test}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:38.757963Z",
          "iopub.status.busy": "2023-07-11T19:06:38.757555Z",
          "iopub.status.idle": "2023-07-11T19:06:52.358142Z",
          "shell.execute_reply": "2023-07-11T19:06:52.357177Z",
          "shell.execute_reply.started": "2023-07-11T19:06:38.757924Z"
        },
        "id": "XDmQslVxDhy1",
        "outputId": "b4152ada-45cb-4169-ec65-c62473621ba3",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'utils' from '/content/utils.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "import string\n",
        "from torch import nn\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
        "from transformers import TrainingArguments, Trainer, TrainerCallback, EarlyStoppingCallback\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import AutoConfig, BertForSequenceClassification, RobertaForSequenceClassification, RobertaModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from typing import Optional, Union, Tuple\n",
        "from nrclex import NRCLex\n",
        "import importlib\n",
        "import sys\n",
        "from torch.utils.data import Dataset\n",
        "from utils import *\n",
        "importlib.reload(sys.modules['utils'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:52.360520Z",
          "iopub.status.busy": "2023-07-11T19:06:52.359527Z",
          "iopub.status.idle": "2023-07-11T19:06:52.392731Z",
          "shell.execute_reply": "2023-07-11T19:06:52.391807Z",
          "shell.execute_reply.started": "2023-07-11T19:06:52.360482Z"
        },
        "id": "quom7lWCDiiI",
        "outputId": "856fe27e-9239-4d19-a018-2c6f837633e4",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= CUDA Available =======\n"
          ]
        }
      ],
      "source": [
        "# set CUDA if available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"======= CUDA Available =======\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"======= CUDA NOT Available, run on CPU =======\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gsXzUtCBv-j"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIUOnGp-_6lV"
      },
      "source": [
        "### WASSA dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:52.394814Z",
          "iopub.status.busy": "2023-07-11T19:06:52.394204Z",
          "iopub.status.idle": "2023-07-11T19:06:52.406593Z",
          "shell.execute_reply": "2023-07-11T19:06:52.405612Z",
          "shell.execute_reply.started": "2023-07-11T19:06:52.394779Z"
        },
        "id": "S2o5IfHdgXXf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "emotions_names = [\n",
        "    'fear',\n",
        "    'anger',\n",
        "    'anticipation',\n",
        "    'trust',\n",
        "    'surprise',\n",
        "    'positive',\n",
        "    'negative',\n",
        "    'sadness',\n",
        "    'disgust',\n",
        "    'joy',\n",
        "    'hope'\n",
        "]\n",
        "\n",
        "TASK = \"EMO\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:52.410007Z",
          "iopub.status.busy": "2023-07-11T19:06:52.409372Z",
          "iopub.status.idle": "2023-07-11T19:06:52.429476Z",
          "shell.execute_reply": "2023-07-11T19:06:52.428716Z",
          "shell.execute_reply.started": "2023-07-11T19:06:52.409972Z"
        },
        "id": "WOuBgl-TmlM-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class WASSADataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer,\n",
        "        essay,\n",
        "        essay_id,\n",
        "        targets,\n",
        "        sep=False,\n",
        "        prompt=None,\n",
        "        EMP_lexicon = None,\n",
        "        EMO_lexicon = None,\n",
        "        global_features = None,\n",
        "        local_emotions = False,\n",
        "        local_empathy = False,\n",
        "        local_distress = False,\n",
        "        max_len=None\n",
        "        ):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.essay = essay\n",
        "        self.essay_id = essay_id\n",
        "        self.targets = targets\n",
        "        self.EMP_lexicon = EMP_lexicon\n",
        "        self.EMO_lexicon = EMO_lexicon\n",
        "        self.sep = sep\n",
        "        self.prompt = prompt\n",
        "\n",
        "        self.global_features = global_features\n",
        "        self.local_emotions = local_emotions\n",
        "        self.local_empathy = local_empathy\n",
        "        self.local_distress = local_distress\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        essay = str(self.essay[index])\n",
        "\n",
        "        essay_id = self.essay_id[index]\n",
        "\n",
        "        prompt = \"\"\n",
        "        if self.prompt is not None:\n",
        "          for i, p in enumerate(self.prompt[index]):\n",
        "            prompt += \" \" + str(p)\n",
        "\n",
        "        text = essay\n",
        "        text_pair = None\n",
        "        if self.sep:\n",
        "          text_pair = prompt\n",
        "        else:\n",
        "          if self.prompt is not None:\n",
        "            text += prompt\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text=essay,\n",
        "            text_pair=text_pair,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "          'input_ids': inputs['input_ids'].flatten(),\n",
        "          'attention_mask': inputs['attention_mask'].flatten(),\n",
        "          'token_type_ids': inputs[\"token_type_ids\"].flatten()\n",
        "        }\n",
        "\n",
        "        if self.targets is not None:\n",
        "          item['labels'] = torch.FloatTensor(self.targets[index])\n",
        "\n",
        "        if self.global_features is not None:\n",
        "          item['global_features'] = self.global_features[index]\n",
        "\n",
        "        n_local_features = 0\n",
        "        features_tokens_row = []\n",
        "        if self.local_emotions:\n",
        "            n_local_features += len(emotions_names)\n",
        "            for i in range(len(emotions_names)):\n",
        "                features_tokens_row.append(0)\n",
        "        if self.local_empathy:\n",
        "            n_local_features += 1\n",
        "            features_tokens_row.append(4)\n",
        "        if self.local_distress:\n",
        "            n_local_features += 1\n",
        "            features_tokens_row.append(0)\n",
        "\n",
        "        if n_local_features > 0:\n",
        "            features_tokens = np.full((self.tokenizer.model_max_length, n_local_features), features_tokens_row)\n",
        "        else:\n",
        "          features_tokens = None\n",
        "\n",
        "        word_count=0\n",
        "        first_char=True\n",
        "        last_char_is_space=False\n",
        "        for char_idx, char in enumerate(essay):\n",
        "          token_idx = inputs.char_to_token(char_idx)\n",
        "          if token_idx is None:\n",
        "            if first_char: last_char_is_space=True\n",
        "            if not last_char_is_space and not first_char:\n",
        "              word_count+=1\n",
        "              last_char_is_space=True\n",
        "            continue\n",
        "          elif last_char_is_space:\n",
        "            last_char_is_space=False\n",
        "          first_char=False\n",
        "\n",
        "          j = 0\n",
        "          if char not in string.punctuation:\n",
        "            if self.local_emotions:\n",
        "              for i, emo in enumerate(emotions_names):\n",
        "                features_tokens[token_idx][i] = self.EMO_lexicon[str(essay_id)][emo][word_count]\n",
        "              j += len(emotions_names)\n",
        "\n",
        "            if self.local_empathy:\n",
        "              features_tokens[token_idx][j] = self.EMP_lexicon[str(essay_id)]['empathy'][word_count]\n",
        "              j += 1\n",
        "\n",
        "\n",
        "            if self.local_distress:\n",
        "              features_tokens[token_idx][j] = self.EMP_lexicon[str(essay_id)]['distress'][word_count]\n",
        "\n",
        "        if features_tokens is not None:\n",
        "            item['local_features'] = torch.FloatTensor(features_tokens)\n",
        "\n",
        "        #item['return_dict']=True\n",
        "\n",
        "        return item"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUd7BQjSsVMJ"
      },
      "source": [
        "Dataset paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:09:57.899510Z",
          "iopub.status.busy": "2023-07-11T19:09:57.899102Z",
          "iopub.status.idle": "2023-07-11T19:09:57.904814Z",
          "shell.execute_reply": "2023-07-11T19:09:57.903813Z",
          "shell.execute_reply.started": "2023-07-11T19:09:57.899476Z"
        },
        "id": "BjM03TscDwcz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "TRAIN_DATA = f\"{repo_path}{branch}/datasets/WASSA23_essay_level_original_internal_train_preproc.tsv\"\n",
        "VAL_DATA = f\"{repo_path}{branch}/datasets/WASSA23_essay_level_original_internal_val_preproc.tsv\"\n",
        "DEV_DATA = f\"{repo_path}{branch}/datasets/WASSA23_essay_level_dev_preproc.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFI6AulQsYci"
      },
      "source": [
        "Read dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:05.747579Z",
          "iopub.status.busy": "2023-07-11T19:10:05.747000Z",
          "iopub.status.idle": "2023-07-11T19:10:05.979691Z",
          "shell.execute_reply": "2023-07-11T19:10:05.978760Z",
          "shell.execute_reply.started": "2023-07-11T19:10:05.747546Z"
        },
        "id": "Sppn6sPYsBqA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(TRAIN_DATA, sep='\\t')\n",
        "val_df = pd.read_csv(VAL_DATA, sep='\\t')\n",
        "dev_df = pd.read_csv(DEV_DATA, sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:05.983199Z",
          "iopub.status.busy": "2023-07-11T19:10:05.982479Z",
          "iopub.status.idle": "2023-07-11T19:10:05.991153Z",
          "shell.execute_reply": "2023-07-11T19:10:05.989896Z",
          "shell.execute_reply.started": "2023-07-11T19:10:05.983164Z"
        },
        "id": "hygjdzlasIEL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "label_encoder = EmotionsLabelEncoder()\n",
        "label_encoder.fit(train_df.emotion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDJWlHhwsfwL"
      },
      "source": [
        "Encode targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.006808Z",
          "iopub.status.busy": "2023-07-11T19:10:06.006358Z",
          "iopub.status.idle": "2023-07-11T19:10:06.021824Z",
          "shell.execute_reply": "2023-07-11T19:10:06.020868Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.006776Z"
        },
        "id": "6LKqRnKdsJdu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y_train = label_encoder.encode(train_df.emotion)\n",
        "y_val = label_encoder.encode(val_df.emotion)\n",
        "y_dev = label_encoder.encode(dev_df.emotion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "g78XkRZL6xHY"
      },
      "outputs": [],
      "source": [
        "#@title Model Class\n",
        "MODEL_CLASS_STRING = \"BertForSequenceClassification\" #@param [\"BertForSequenceClassification\", \"RobertaForSequenceClassification\"]\n",
        "model_id = 'BertEmpDisLocal' #@param {type:\"string\"}\n",
        "model_name = 'bert-base' #@param [\"bert-base\", \"roberta-base\"]\n",
        "\n",
        "if MODEL_CLASS_STRING == \"BertForSequenceClassification\":\n",
        "  MODEL_CLASS = BertForSequenceClassification\n",
        "else:\n",
        "  MODEL_CLASS = RobertaForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.026995Z",
          "iopub.status.busy": "2023-07-11T19:10:06.026313Z",
          "iopub.status.idle": "2023-07-11T19:10:06.034340Z",
          "shell.execute_reply": "2023-07-11T19:10:06.033205Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.026970Z"
        },
        "id": "j6y4HnEP6gcI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#@title Global Features\n",
        "emo_count_global = False #@param {type:\"boolean\"}\n",
        "empathy_count_global = False #@param {type:\"boolean\"}\n",
        "distress_count_global = False #@param {type:\"boolean\"}\n",
        "gold_empathy = False #@param {type:\"boolean\"}\n",
        "gold_distress = False #@param {type:\"boolean\"}\n",
        "bio_global = False #@param {type:\"boolean\"}\n",
        "global_features_names = []\n",
        "emotions_count = ['fear_count',\t'anger_count','anticipation_count',\t'trust_count',\n",
        "                 'positive_count',\t'negative_count', 'surprise_count',\n",
        "                 'sadness_count',\t'disgust_count',\t'joy_count',\t'hope_count']\n",
        "bio = ['gender', 'age', 'income', 'race', 'education']\n",
        "if emo_count_global:\n",
        "  for emo in emotions_count: global_features_names.append(emo)\n",
        "if empathy_count_global: global_features_names.append('empathy_count')\n",
        "if distress_count_global: global_features_names.append('distress_count')\n",
        "if gold_empathy: global_features_names.append('empathy')\n",
        "if gold_distress: global_features_names.append('distress')\n",
        "if bio_global:\n",
        "  for b in bio: global_features_names.append(b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.036262Z",
          "iopub.status.busy": "2023-07-11T19:10:06.035925Z",
          "iopub.status.idle": "2023-07-11T19:10:06.048932Z",
          "shell.execute_reply": "2023-07-11T19:10:06.048042Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.036232Z"
        },
        "id": "n3snAqfK6728",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#@title Local Features\n",
        "emo_count_local = False #@param {type:\"boolean\"}\n",
        "empathy_count_local = True #@param {type:\"boolean\"}\n",
        "distress_count_local = True #@param {type:\"boolean\"}\n",
        "\n",
        "local_features_names = []\n",
        "if emo_count_local: local_features_names.append('emotions')\n",
        "if empathy_count_local: local_features_names.append('empathy')\n",
        "if distress_count_local: local_features_names.append('distress')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EaTQUHDY6xHZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Prompt\n",
        "bio_prompt = False #@param {type:\"boolean\"}\n",
        "emo_prompt = False #@param {type:\"boolean\"}\n",
        "empathy_prompt = False #@param {type:\"boolean\"}\n",
        "prompt = []\n",
        "prompt_names = [\"prompt_bio\", \"prompt_emp\", \"prompt_emo\"]\n",
        "if bio_prompt:\n",
        "    prompt.append(prompt_names[0])\n",
        "if empathy_prompt:\n",
        "    prompt.append(prompt_names[1])\n",
        "if emo_prompt:\n",
        "    prompt.append(prompt_names[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.052235Z",
          "iopub.status.busy": "2023-07-11T19:10:06.051958Z",
          "iopub.status.idle": "2023-07-11T19:10:06.059593Z",
          "shell.execute_reply": "2023-07-11T19:10:06.058689Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.052213Z"
        },
        "id": "7JyTdDiw9TWP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#@title Number of labels\n",
        "num_labels = 8 #@param {type:\"number\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.061536Z",
          "iopub.status.busy": "2023-07-11T19:10:06.061089Z",
          "iopub.status.idle": "2023-07-11T19:10:06.069916Z",
          "shell.execute_reply": "2023-07-11T19:10:06.069051Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.061505Z"
        },
        "id": "dA224FxADpqd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "NUM_LABELS = num_labels\n",
        "GLOBAL_FEATURES_NAMES = global_features_names\n",
        "LOCAL_FEATURES_NAMES = local_features_names\n",
        "DIM_EXTRA_FEATURES = len(GLOBAL_FEATURES_NAMES) + len(LOCAL_FEATURES_NAMES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbCKVWh7-gpg"
      },
      "source": [
        "Extra global features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7VpOAsXL6xHa"
      },
      "outputs": [],
      "source": [
        "if len(global_features_names) > 0:\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(np.array(train_df[GLOBAL_FEATURES_NAMES]))\n",
        "\n",
        "  def scandar_scalar_features(features):\n",
        "    return scaler.transform(features)\n",
        "\n",
        "  features_train =  scandar_scalar_features(np.array(train_df[GLOBAL_FEATURES_NAMES]))\n",
        "  features_val =  scandar_scalar_features(np.array(val_df[GLOBAL_FEATURES_NAMES]))\n",
        "  features_dev =  scandar_scalar_features(np.array(dev_df[GLOBAL_FEATURES_NAMES]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfm0n2Mk6xHb"
      },
      "source": [
        "Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5WnGSQwv6xHb"
      },
      "outputs": [],
      "source": [
        "prompt_train = np.array(train_df[prompt])\n",
        "prompt_val = np.array(val_df[prompt])\n",
        "prompt_dev = np.array(dev_df[prompt])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwYXJId_-Sb5"
      },
      "source": [
        "## Lexicons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:09.185627Z",
          "iopub.status.busy": "2023-07-11T19:11:09.185261Z",
          "iopub.status.idle": "2023-07-11T19:11:09.667265Z",
          "shell.execute_reply": "2023-07-11T19:11:09.666254Z",
          "shell.execute_reply.started": "2023-07-11T19:11:09.185595Z"
        },
        "id": "Qg0D38kk-Rrv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "with open(\"/content/EMO23_lexicon_per_word_train.json\") as json_file:\n",
        "  EMO_lexicon_train_dict = json.load(json_file)\n",
        "with open(\"/content/EMP23_lexicon_per_word_train.json\") as json_file:\n",
        "  EMP_lexicon_train_dict = json.load(json_file)\n",
        "with open(\"/content/EMO23_lexicon_per_word_dev.json\") as json_file:\n",
        "  EMO_lexicon_dev_dict = json.load(json_file)\n",
        "with open(\"/content/EMP23_lexicon_per_word_dev.json\") as json_file:\n",
        "  EMP_lexicon_dev_dict = json.load(json_file)\n",
        "with open(\"/content/EMO23_lexicon_per_word_test.json\") as json_file:\n",
        "  EMO_lexicon_test_dict = json.load(json_file)\n",
        "with open(\"/content/EMP23_lexicon_per_word_test.json\") as json_file:\n",
        "  EMP_lexicon_test_dict = json.load(json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXIimY5ABmlc"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:17.217440Z",
          "iopub.status.busy": "2023-07-11T19:11:17.217004Z",
          "iopub.status.idle": "2023-07-11T19:11:17.225859Z",
          "shell.execute_reply": "2023-07-11T19:11:17.224898Z",
          "shell.execute_reply.started": "2023-07-11T19:11:17.217403Z"
        },
        "id": "wtbV4tekujaC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_type ={\n",
        "  'distilroberta-emotion':'j-hartmann/emotion-english-distilroberta-base',\n",
        "  'roberta-emotion':'j-hartmann/emotion-english-roberta-large',\n",
        "  'bert-base': 'bert-base-cased',\n",
        "  'roberta-base' : 'roberta-base'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:17.229021Z",
          "iopub.status.busy": "2023-07-11T19:11:17.228297Z",
          "iopub.status.idle": "2023-07-11T19:11:17.240056Z",
          "shell.execute_reply": "2023-07-11T19:11:17.239129Z",
          "shell.execute_reply.started": "2023-07-11T19:11:17.228988Z"
        },
        "id": "Cxq0isZT6KQW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_config = {\n",
        "    'model_id': model_id,\n",
        "    'tokenizer_name': model_type.get(model_name),\n",
        "    'model_name': model_type.get(model_name),\n",
        "    'train_batch_size': 8,\n",
        "    'val_batch_size': 8,\n",
        "    'learning_rate': 5e-5,\n",
        "    'weight_decay': 0,\n",
        "    'epochs': 30,\n",
        "    'seed': 42,\n",
        "    'patience': 5,\n",
        "    'early_stopping_threshold': 0,\n",
        "    'weighted_loss': True\n",
        "}\n",
        "\n",
        "path_tosave = f\"{model_config['model_id']}\"\n",
        "!mkdir $path_tosave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:22.362620Z",
          "iopub.status.busy": "2023-07-11T19:11:22.361776Z",
          "iopub.status.idle": "2023-07-11T19:11:23.697235Z",
          "shell.execute_reply": "2023-07-11T19:11:23.696230Z",
          "shell.execute_reply.started": "2023-07-11T19:11:22.362585Z"
        },
        "id": "wd7W2HhYsbai",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "08d21e1269c84ac091ffb25a1792f9e6",
            "f7f2a17d50b545d79cb711cd49def6e9",
            "545decdf626641f2bd9af1f9724f91e7",
            "01bfcdeb83044a05a759f07f01a648b3",
            "e470374e07e445a5a15c3f6346d3f4ed",
            "7e2a4201f50346ca97786884a3c6d213",
            "0700b87a04614eb494cd0db76d14610a",
            "47600c76977346158118e50663acad0b",
            "cddaac22b1674944952dac85770a5c69",
            "ab6522c7500c49afb801ce44428079a5",
            "55f6cd473a14465eb9f98747e5c704b4",
            "bcff1394adc84fcd887e2362176ddf94",
            "1b13a239fb0546419c6a369d143a30c5",
            "444f53010cad487abd82dc2c19f5af04",
            "23959cddb2a142a38c7a3a2af00baaa3",
            "a59f023ccda945fe99da9c49a5763fd9",
            "1a3af1e6e0484854907f9b507f3ba29b",
            "058118a1bf98493cb5a8c4f6c3119c2f",
            "495e0d6dee3a4eceaf66597f087a9142",
            "70a40856665c4f6c8c4b4754d1ded00f",
            "3ae57dccf5c240c4a0804407064dc557",
            "4c31aa3e121948b39e5d29251195d50c",
            "3dc85087cb514612902ff3fd7a31f52a",
            "67ed863795cc427ba0229f11c189574f",
            "89ece8051a4145a1a9250c3619cc3d69",
            "1c19bd6f12eb43fb8b1762dca0f7156d",
            "2ddb6cd7dae64f9ca8f1eed7041e549d",
            "2555f02e19634cf09e6d90fcd19bc8f9",
            "836f5ec726ef4b10bd81111399051351",
            "835d552b1671477ab175af2b3972e78a",
            "fb0e85b22ba341b7ae712bf691f5ea57",
            "af037d77fefc4384bf30175364ed290a",
            "c97e1afc87de42ae82db0b1f1008477c",
            "21d263226f9c4286b82dd889b6ad3bfc",
            "b5fe108b978d44e0a23a4b7aea132ae0",
            "260c4c6643c849c5beb873eb546f611f",
            "0c2407cf57fd4fd49b16f40f01b56b8d",
            "1382797841724e53838fcc6f790add4e",
            "4a04eb864a8547a8b76f72dbf977d422",
            "c4115191c24949b19fa61d34e5304c42",
            "7621eea7b1024de6909d0b26e3cf5663",
            "a69147d3d76f45239a3fae7383ec8da4",
            "3bfc5f70940949f3820bf842e1949a29",
            "251c3cb9a12949a089b44f7f1333e6d0"
          ]
        },
        "outputId": "0033aedf-a318-4533-96e5-5fc6b5773fce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08d21e1269c84ac091ffb25a1792f9e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcff1394adc84fcd887e2362176ddf94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dc85087cb514612902ff3fd7a31f52a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21d263226f9c4286b82dd889b6ad3bfc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_config['tokenizer_name'], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:17.243014Z",
          "iopub.status.busy": "2023-07-11T19:11:17.241592Z",
          "iopub.status.idle": "2023-07-11T19:11:17.253391Z",
          "shell.execute_reply": "2023-07-11T19:11:17.252383Z",
          "shell.execute_reply.started": "2023-07-11T19:11:17.242979Z"
        },
        "id": "hfwVaaj-0qDq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_loss_weights(y):\n",
        "  inverse_n_samples = 1 / np.sum(y, axis=0)\n",
        "  sum_inverses = sum(inverse_n_samples)\n",
        "  weights_train = inverse_n_samples / sum_inverses\n",
        "  return torch.cuda.FloatTensor(weights_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:17.257384Z",
          "iopub.status.busy": "2023-07-11T19:11:17.255861Z",
          "iopub.status.idle": "2023-07-11T19:11:22.360433Z",
          "shell.execute_reply": "2023-07-11T19:11:22.359379Z",
          "shell.execute_reply.started": "2023-07-11T19:11:17.257351Z"
        },
        "id": "wVh3_jCFzmK7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if model_config.get('weighted_loss'):\n",
        "  loss_weights_train = get_loss_weights(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6aAhPift1UL"
      },
      "source": [
        "### Custom model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:23.702374Z",
          "iopub.status.busy": "2023-07-11T19:11:23.702059Z",
          "iopub.status.idle": "2023-07-11T19:11:23.732141Z",
          "shell.execute_reply": "2023-07-11T19:11:23.730692Z",
          "shell.execute_reply.started": "2023-07-11T19:11:23.702348Z"
        },
        "id": "2Vj3W-oUhBMZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    #Head for sentence-level classification tasks.\n",
        "\n",
        "    def __init__(self, config, num_extra_dims, hidden_layers_to_concat, classifier_dropout, local_features, mean_last_cls):\n",
        "        super().__init__()\n",
        "        self.local_features = local_features\n",
        "\n",
        "        if mean_last_cls:\n",
        "          total_dims = config.hidden_size + num_extra_dims\n",
        "        else:\n",
        "          total_dims = config.hidden_size*hidden_layers_to_concat + num_extra_dims\n",
        "        if self.local_features:\n",
        "          total_dims += config.hidden_size\n",
        "        self.dense = nn.Linear(total_dims, total_dims)\n",
        "        self.dropout = nn.Dropout(classifier_dropout)\n",
        "        self.out_proj = nn.Linear(total_dims, config.num_labels)\n",
        "\n",
        "    def forward(self, features, **kwargs):\n",
        "        features = features.to(torch.float32) # by default float32 is used as the dtype\n",
        "        x = self.dense(features)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.out_proj(x)\n",
        "        return x\n",
        "\n",
        "class CustomSequenceClassification(MODEL_CLASS):\n",
        "\n",
        "    def __init__(self, config, num_extra_dims=0, local_features_name=None, loss_weights=None, last_cls = 1, mean_last_cls = False):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.config = config\n",
        "        self.local_features_name = local_features_name\n",
        "        self.loss_weights = loss_weights\n",
        "        self.last_cls = last_cls\n",
        "        self.mean_last_cls = mean_last_cls\n",
        "        if MODEL_CLASS_STRING == \"BertForSequenceClassification\":\n",
        "          self.bert = BertModel(config)\n",
        "        else:\n",
        "          self.bert = RobertaModel(config)\n",
        "        classifier_dropout = (\n",
        "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
        "        )\n",
        "        self.dropout = nn.Dropout(classifier_dropout)\n",
        "        self.classifier = ClassificationHead(config,\n",
        "                                            num_extra_dims,\n",
        "                                            last_cls,\n",
        "                                            classifier_dropout,\n",
        "                                            local_features_name is not None,\n",
        "                                            mean_last_cls)\n",
        "        self.post_init()\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.LongTensor] = None,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        local_features = None,\n",
        "        global_features = None,\n",
        "        token_type_ids: Optional[torch.LongTensor] = None,\n",
        "        position_ids: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = True,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
        "\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        cls_tokens = []\n",
        "        for i in range(1, self.last_cls + 1):\n",
        "            cls_tokens.append(outputs.hidden_states[-1 * i][:, 0, :])\n",
        "        if self.mean_last_cls:\n",
        "          # average cls tokens\n",
        "          output = torch.mean(torch.stack(cls_tokens), dim=0)\n",
        "        else:\n",
        "          # concat cls tokens\n",
        "          output = torch.cat(cls_tokens, dim=1)\n",
        "\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        if local_features is not None:\n",
        "          tokens_output = outputs.last_hidden_state\n",
        "          tokens_output = self.dropout(tokens_output)\n",
        "\n",
        "          tokens_output = torch.cat((\n",
        "                  tokens_output,\n",
        "                  local_features.reshape(outputs.last_hidden_state.shape[0], outputs.last_hidden_state.shape[1], -1)),\n",
        "                             dim=2)\n",
        "\n",
        "          mask = torch.zeros_like(attention_mask)\n",
        "          # unmask tokens with high or low empathy, high distress levels, or expressing at least one emotion\n",
        "          j = 0\n",
        "          print(self.local_features_name)\n",
        "          if 'emotions' in self.local_features_name:\n",
        "            emotion_values = local_features[:,:,:11]\n",
        "            mask[emotion_values.sum(dim=-1)>=1] = 1.0\n",
        "            j += 11\n",
        "\n",
        "          if 'empathy' in self.local_features_name:\n",
        "            empathy_values = local_features[:,:,j]\n",
        "            mask[(empathy_values>5) | ((empathy_values<3) & (empathy_values>=1))] = 1.0\n",
        "            j += 1\n",
        "\n",
        "          if 'distress' in self.local_features_name:\n",
        "            distress_values = local_features[:,:,j]\n",
        "            mask[distress_values>4] = 1.0\n",
        "\n",
        "          # mean pooling of unmasked tokens\n",
        "          input_mask_expanded = mask.unsqueeze(-1).expand(tokens_output.size()).float()\n",
        "          sum_embeddings = torch.sum(tokens_output * input_mask_expanded, 1)\n",
        "          sum_mask = input_mask_expanded.sum(1)\n",
        "          sum_mask = torch.clamp(sum_mask, min = 1e-9)\n",
        "          tokens_output = sum_embeddings/sum_mask\n",
        "\n",
        "          # concat pooled tokens lexically relevant with cls token\n",
        "          output = torch.cat((output, tokens_output), dim=-1)\n",
        "\n",
        "\n",
        "        if global_features is not None: # global\n",
        "          output = torch.cat((output, global_features), dim=-1)\n",
        "\n",
        "        logits = self.classifier(output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.config.problem_type is None:\n",
        "                if self.num_labels == 1:\n",
        "                    self.config.problem_type = \"regression\"\n",
        "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
        "                    self.config.problem_type = \"single_label_classification\"\n",
        "                else:\n",
        "                    self.config.problem_type = \"multi_label_classification\"\n",
        "\n",
        "            if self.config.problem_type == \"regression\":\n",
        "                loss_fct = nn.MSELoss()\n",
        "                if self.num_labels == 1:\n",
        "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
        "                else:\n",
        "                    loss = loss_fct(logits, labels)\n",
        "            elif self.config.problem_type == \"single_label_classification\":\n",
        "                loss_fct = nn.CrossEntropyLoss(weight = self.loss_weights)\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            elif self.config.problem_type == \"multi_label_classification\":\n",
        "                loss_fct = nn.BCEWithLogitsLoss(weight = self.loss_weights)\n",
        "                loss = loss_fct(logits, labels)\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:23.734900Z",
          "iopub.status.busy": "2023-07-11T19:11:23.734558Z",
          "iopub.status.idle": "2023-07-11T19:11:27.562951Z",
          "shell.execute_reply": "2023-07-11T19:11:27.562030Z",
          "shell.execute_reply.started": "2023-07-11T19:11:23.734871Z"
        },
        "id": "GvJbF80XhSDE",
        "outputId": "56a64ed7-6158-4f49-b970-6566f57479a6",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing CustomSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing CustomSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = CustomSequenceClassification.from_pretrained(model_config.get(\"model_name\"),\n",
        "                                                     problem_type = \"multi_label_classification\",\n",
        "                                                     num_labels=NUM_LABELS,\n",
        "                                                     classifier_dropout=0.3,\n",
        "                                                     num_extra_dims=DIM_EXTRA_FEATURES,\n",
        "                                                     local_features_name = ['empathy', 'distress']\n",
        "                                                     #last_cls = 4,\n",
        "                                                     #mean_last_cls = True\n",
        "                                                     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xvHbhOhhttG"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY0SLN6usjYs"
      },
      "source": [
        "Prepare datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.565429Z",
          "iopub.status.busy": "2023-07-11T19:11:27.564800Z",
          "iopub.status.idle": "2023-07-11T19:11:27.572683Z",
          "shell.execute_reply": "2023-07-11T19:11:27.571493Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.565394Z"
        },
        "id": "DUIqO6AiZ8al",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_set = WASSADataset(tokenizer=tokenizer,\n",
        "                    essay=train_df.essay,\n",
        "                    #prompt=prompt_train,\n",
        "                    #sep=True,\n",
        "                    essay_id = train_df.essay_id,\n",
        "                    targets=y_train,\n",
        "                    EMO_lexicon=EMO_lexicon_train_dict,\n",
        "                    EMP_lexicon=EMP_lexicon_train_dict,\n",
        "                    #global_features = features_train\n",
        "                    local_emotions = False,\n",
        "                    local_empathy = True,\n",
        "                    local_distress = True\n",
        "                )\n",
        "\n",
        "val_set = WASSADataset(tokenizer=tokenizer,\n",
        "                    essay=val_df.essay,\n",
        "                    #prompt=prompt_val,\n",
        "                    #sep=True,\n",
        "                    essay_id = val_df.essay_id,\n",
        "                    targets=y_val,\n",
        "                    EMO_lexicon=EMO_lexicon_train_dict,\n",
        "                    EMP_lexicon=EMP_lexicon_train_dict,\n",
        "                    #global_features = features_val\n",
        "                    local_emotions = False,\n",
        "                    local_empathy = True,\n",
        "                    local_distress = True\n",
        "                )\n",
        "dev_set = WASSADataset(tokenizer=tokenizer,\n",
        "                    essay=dev_df.essay,\n",
        "                    #prompt=prompt_dev,\n",
        "                    #sep=True,\n",
        "                    essay_id = dev_df.essay_id,\n",
        "                    targets=y_dev,\n",
        "                    EMO_lexicon=EMO_lexicon_train_dict,\n",
        "                    EMP_lexicon=EMP_lexicon_train_dict,\n",
        "                    #global_features = features_dev\n",
        "                    local_emotions = False,\n",
        "                    local_empathy = True,\n",
        "                    local_distress = True\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvduRx8HsteS"
      },
      "source": [
        "Set up training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.574736Z",
          "iopub.status.busy": "2023-07-11T19:11:27.574061Z",
          "iopub.status.idle": "2023-07-11T19:11:27.586314Z",
          "shell.execute_reply": "2023-07-11T19:11:27.585303Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.574702Z"
        },
        "id": "Z1DbZxhkD1R7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_arguments = TrainingArguments(\n",
        "    output_dir=f\"./{model_config['model_name']}\",\n",
        "    per_device_train_batch_size=model_config['train_batch_size'],\n",
        "    per_device_eval_batch_size=model_config['val_batch_size'],\n",
        "    num_train_epochs=model_config['epochs'],\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    eval_steps = 150,\n",
        "    save_steps = 150,\n",
        "    learning_rate=model_config['learning_rate'],\n",
        "    weight_decay=model_config['weight_decay'],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_macro_f1',\n",
        "    seed=model_config['seed'],\n",
        "    logging_strategy = \"epoch\"\n",
        ") # TODO: custom other params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.588557Z",
          "iopub.status.busy": "2023-07-11T19:11:27.587598Z",
          "iopub.status.idle": "2023-07-11T19:11:27.726922Z",
          "shell.execute_reply": "2023-07-11T19:11:27.725911Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.588523Z"
        },
        "id": "hrI2rj4U3K2Q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=train_arguments,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=val_set,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_EMO_metrics_trainer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-sruHQdsraI"
      },
      "source": [
        "Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.731325Z",
          "iopub.status.busy": "2023-07-11T19:11:27.731059Z",
          "iopub.status.idle": "2023-07-11T19:11:27.738285Z",
          "shell.execute_reply": "2023-07-11T19:11:27.737157Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.731302Z"
        },
        "id": "4kUY7tU3sqr3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class TrainerLoggingCallback(TrainerCallback):\n",
        "    def __init__(self, log_path):\n",
        "        self.log_path = log_path\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        _ = logs.pop(\"total_flos\", None)\n",
        "        if state.is_local_process_zero: # whether this process is the main one in a distributed setting\n",
        "            with open(self.log_path, \"a\") as f:\n",
        "                f.write(json.dumps(logs) + \"\\n\")\n",
        "\n",
        "trainer.add_callback(EarlyStoppingCallback(\n",
        "    early_stopping_patience=model_config['patience'],\n",
        "    early_stopping_threshold=model_config['early_stopping_threshold']))\n",
        "\n",
        "trainer.add_callback(TrainerLoggingCallback(model_config['model_id']+\"_log.json\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcCqSooFsw0X"
      },
      "source": [
        "Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.740439Z",
          "iopub.status.busy": "2023-07-11T19:11:27.740100Z",
          "iopub.status.idle": "2023-07-11T19:20:18.229718Z",
          "shell.execute_reply": "2023-07-11T19:20:18.228678Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.740408Z"
        },
        "id": "L8xAPa81D5tu",
        "outputId": "ca3342c4-3a89-4658-993e-cf2006e31dfa",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['empathy', 'distress']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1645\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1642 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1643 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1644 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1645 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1646 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1647 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1648 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1938\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1935 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_step_begin(args, \u001b[96mself\u001b[0m.state,  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1936 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1937 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.accelerator.accumulate(model):                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1938 \u001b[2m│   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1939 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1940 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1941 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0margs.logging_nan_inf_filter                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2759\u001b[0m in \u001b[92mtraining_step\u001b[0m            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2756 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m loss_mb.reduce_mean().detach().to(\u001b[96mself\u001b[0m.args.device)                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2757 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2758 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.compute_loss_context_manager():                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2759 \u001b[2m│   │   │   \u001b[0mloss = \u001b[96mself\u001b[0m.compute_loss(model, inputs)                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2760 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2761 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.n_gpu > \u001b[94m1\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2762 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = loss.mean()  \u001b[2m# mean() to average on multi-gpu parallel training\u001b[0m        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2784\u001b[0m in \u001b[92mcompute_loss\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2781 \u001b[0m\u001b[2m│   │   │   \u001b[0mlabels = inputs.pop(\u001b[33m\"\u001b[0m\u001b[33mlabels\u001b[0m\u001b[33m\"\u001b[0m)                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2782 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2783 \u001b[0m\u001b[2m│   │   │   \u001b[0mlabels = \u001b[94mNone\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2784 \u001b[2m│   │   \u001b[0moutputs = model(**inputs)                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2785 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Save past state if it exists\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2786 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# TODO: this needs to be fixed and made cleaner later.\u001b[0m                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2787 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.past_index >= \u001b[94m0\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mforward\u001b[0m:\u001b[94m136\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mforward\u001b[0m:\u001b[94m20\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mlinear.py\u001b[0m:\u001b[94m114\u001b[0m in \u001b[92mforward\u001b[0m                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0minit.uniform_(\u001b[96mself\u001b[0m.bias, -bound, bound)                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.linear(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.bias)                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mextra_repr\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[96mstr\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[33m'\u001b[0m\u001b[33min_features=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m, out_features=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m, bias=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m.format(                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mRuntimeError: \u001b[0mmat1 and mat2 shapes cannot be multiplied \u001b[1m(\u001b[0m8x1538 and 1536x1536\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1645</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1645 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1646 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1647 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1648 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1938</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1935 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_step_begin(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1936 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1937 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.accumulate(model):                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1938 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1939 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1940 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1941 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2759</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2756 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss_mb.reduce_mean().detach().to(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.device)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2757 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2758 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_loss_context_manager():                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2759 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_loss(model, inputs)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2760 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2761 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.n_gpu &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2762 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss = loss.mean()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># mean() to average on multi-gpu parallel training</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2784</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_loss</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2781 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>labels = inputs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"labels\"</span>)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2782 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2783 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>labels = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2784 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = model(**inputs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2785 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Save past state if it exists</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2786 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># TODO: this needs to be fixed and made cleaner later.</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2787 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.past_index &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">136</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">linear.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">114</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>init.uniform_(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias, -bound, bound)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>114 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.linear(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extra_repr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #808000; text-decoration-color: #808000\">'in_features={}, out_features={}, bias={}'</span>.format(                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>mat1 and mat2 shapes cannot be multiplied <span style=\"font-weight: bold\">(</span>8x1538 and 1536x1536<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:20:18.263809Z",
          "iopub.status.busy": "2023-07-11T19:20:18.263461Z",
          "iopub.status.idle": "2023-07-11T19:20:18.274394Z",
          "shell.execute_reply": "2023-07-11T19:20:18.272774Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.263776Z"
        },
        "id": "Dd-3octehTlH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Access the training logs\n",
        "train_logs = trainer.state.log_history\n",
        "\n",
        "metrics = [list(log.keys())[:-5] for log in train_logs if log.get('eval_loss') is not None][0]\n",
        "\n",
        "eval_metrics_values = []\n",
        "\n",
        "# Extract the values from the logs\n",
        "train_loss_values = [log.get('loss') for log in train_logs if log.get('loss') is not None]\n",
        "eval_loss_values = [log.get('eval_loss') for log in train_logs if log.get('eval_loss') is not None]\n",
        "for metric in metrics:\n",
        "  eval_metrics_values.append([log.get(metric) for log in train_logs if log.get(metric) is not None])\n",
        "train_epochs = [log.get('epoch') for log in train_logs if log.get('loss') is not None]\n",
        "eval_epochs = [log.get('epoch') for log in train_logs if log.get('eval_loss') is not None]\n",
        "best_epoch_train = np.argmax([(log.get('eval_macro_f1'), log.get('epoch'))for log in train_logs if log.get('eval_loss') is not None])\n",
        "best_counter_val = np.argmax([log.get('eval_macro_f1')for log in train_logs if log.get('eval_loss') is not None])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V5eavAamxKr"
      },
      "source": [
        "Plot losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:20:18.303708Z",
          "iopub.status.busy": "2023-07-11T19:20:18.303144Z",
          "iopub.status.idle": "2023-07-11T19:20:18.378460Z",
          "shell.execute_reply": "2023-07-11T19:20:18.376257Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.303655Z"
        },
        "id": "ECEu3ajRl6k3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "fig_name = \"losses\"\n",
        "plot_metric_curve(\n",
        "    values = [train_loss_values, eval_loss_values],\n",
        "    epochs = [train_epochs, eval_epochs],\n",
        "    metrics = [\"train loss\", \"eval loss\"],\n",
        "    title = fig_name,\n",
        "    path = f\"{path_tosave}/{fig_name}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms0inN8amz33"
      },
      "source": [
        "Plot metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgGrIimdm3si"
      },
      "outputs": [],
      "source": [
        "fig_name = \"metrics\"\n",
        "plot_metric_curve(\n",
        "    values = eval_metrics_values,\n",
        "    epochs = [eval_epochs for _ in eval_metrics_values],\n",
        "    metrics = metrics,\n",
        "    title = fig_name,\n",
        "    path = f\"{path_tosave}/{fig_name}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc5stfSah0Kj"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:32:52.626228Z",
          "iopub.status.busy": "2023-07-11T19:32:52.625699Z",
          "iopub.status.idle": "2023-07-11T19:32:52.641902Z",
          "shell.execute_reply": "2023-07-11T19:32:52.638400Z",
          "shell.execute_reply.started": "2023-07-11T19:32:52.626186Z"
        },
        "id": "19G80dVoH3HZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def predict_emotions(results, gold_emotions):\n",
        "\n",
        "  binarized_predictions = np.where(results >= 0.5, 1, 0)\n",
        "\n",
        "  for i, bin_pred in enumerate(binarized_predictions):\n",
        "    if np.all(bin_pred==0):\n",
        "      binarized_predictions[i][np.argmax(results[i])] = 1\n",
        "\n",
        "  predicted_emotions = label_encoder.decode(binarized_predictions)\n",
        "  return predicted_emotions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSqi0J48F3gF"
      },
      "outputs": [],
      "source": [
        "trainer.state.best_model_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WIAU6a7Mox4"
      },
      "outputs": [],
      "source": [
        "outs = trainer.predict(dev_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:33:06.725818Z",
          "iopub.status.busy": "2023-07-11T19:33:06.725448Z",
          "iopub.status.idle": "2023-07-11T19:33:06.789138Z",
          "shell.execute_reply": "2023-07-11T19:33:06.786525Z",
          "shell.execute_reply.started": "2023-07-11T19:33:06.725788Z"
        },
        "id": "PIKGrBNlYDa1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "gold_emotions = label_encoder.decode(outs.label_ids)\n",
        "predicted_emotions = predict_emotions(outs.predictions[0], gold_emotions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T19:20:18.388286Z",
          "iopub.status.idle": "2023-07-11T19:20:18.389135Z",
          "shell.execute_reply": "2023-07-11T19:20:18.388900Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.388873Z"
        },
        "id": "Im2VGnmQs7bY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "path_predictions = f\"{path_tosave}/predictions_{TASK}.tsv\"\n",
        "path_metrics = f\"{path_tosave}/dev_metrics_{TASK}.json\"\n",
        "\n",
        "scores = {\n",
        "    'train_loss' : train_loss_values[best_epoch_train],\n",
        "    'eval_loss' : eval_loss_values[best_counter_val]\n",
        "}\n",
        "#TODO write predictions con TASK come stringa\n",
        "write_EMO_predictions(predicted_emotions, path_predictions)\n",
        "challenge_metrics = compute_EMO_metrics(golds=gold_emotions, predictions=predicted_emotions)\n",
        "scores.update(challenge_metrics)\n",
        "write_dict_to_json(scores, path_metrics)\n",
        "\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T19:20:18.390758Z",
          "iopub.status.idle": "2023-07-11T19:20:18.391292Z",
          "shell.execute_reply": "2023-07-11T19:20:18.391058Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.391035Z"
        },
        "id": "ITunC36XXLoN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "fig_name = \"confusion_matrix\"\n",
        "plot_confusion_matrix(golds=gold_emotions,\n",
        "                      predictions=predicted_emotions,\n",
        "                      title=fig_name,\n",
        "                      path= f\"{path_tosave}/{fig_name}.png\"\n",
        "                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXM7Xzr36xHw"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix_per_emotions(gold_emotions, predicted_emotions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DuCaju6tSHB"
      },
      "source": [
        "## Save model on Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T19:20:18.405534Z",
          "iopub.status.idle": "2023-07-11T19:20:18.406365Z",
          "shell.execute_reply": "2023-07-11T19:20:18.406135Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.406111Z"
        },
        "id": "b1KcxQQ0uUl6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "best_model_path = trainer.state.best_model_checkpoint\n",
        "\n",
        "# move the best checkpoint in the folder with model id\n",
        "!mv $best_model_path /content/$path_tosave\n",
        "\n",
        "# move the results to personal drive\n",
        "!mv /content/$path_tosave /content/drive/MyDrive/hlt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pkHv9w4tM1F"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1u9D1Z2R_Jc"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint_and_compute_metrics(checkpoint_path):\n",
        "  model = CustomSequenceClassification.from_pretrained(checkpoint_path, num_labels=NUM_LABELS, num_extra_dims = 0)\n",
        "  trainer = Trainer(model=model)\n",
        "  # Perform prediction using the loaded checkpoint\n",
        "  predictions = trainer.predict(dev_set)\n",
        "\n",
        "  gold_emotions = label_encoder.decode(predictions.label_ids)\n",
        "  predicted_emotions = predict_emotions(predictions.predictions[0], gold_emotions)\n",
        "\n",
        "  write_EMO_predictions(predicted_emotions, model_config['model_id']+\"_predictions_EMO.tsv\")\n",
        "  challenge_metrics = compute_EMO_metrics(golds=gold_emotions, predictions=predicted_emotions)\n",
        "  write_dict_to_json(challenge_metrics, model_config['model_id']+\"_dev_metrics.json\")\n",
        "  print(challenge_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC88bo8dSSsr"
      },
      "outputs": [],
      "source": [
        "\"\"\"load_checkpoint_and_compute_metrics(\"/content/bert-base-caseda/checkpoint-1200\")\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T19:20:18.408046Z",
          "iopub.status.idle": "2023-07-11T19:20:18.408865Z",
          "shell.execute_reply": "2023-07-11T19:20:18.408622Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.408599Z"
        },
        "id": "v6hEtBLztMeC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"MODEL_PATH = \"/content/drive/MyDrive/hlt/best-roberta\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, truncation=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    num_labels=NUM_LABELS,\n",
        "    ignore_mismatched_sizes=True,\n",
        "    problem_type=\"multi_label_classification\")\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08d21e1269c84ac091ffb25a1792f9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7f2a17d50b545d79cb711cd49def6e9",
              "IPY_MODEL_545decdf626641f2bd9af1f9724f91e7",
              "IPY_MODEL_01bfcdeb83044a05a759f07f01a648b3"
            ],
            "layout": "IPY_MODEL_e470374e07e445a5a15c3f6346d3f4ed"
          }
        },
        "f7f2a17d50b545d79cb711cd49def6e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e2a4201f50346ca97786884a3c6d213",
            "placeholder": "​",
            "style": "IPY_MODEL_0700b87a04614eb494cd0db76d14610a",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "545decdf626641f2bd9af1f9724f91e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47600c76977346158118e50663acad0b",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cddaac22b1674944952dac85770a5c69",
            "value": 29
          }
        },
        "01bfcdeb83044a05a759f07f01a648b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab6522c7500c49afb801ce44428079a5",
            "placeholder": "​",
            "style": "IPY_MODEL_55f6cd473a14465eb9f98747e5c704b4",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.61kB/s]"
          }
        },
        "e470374e07e445a5a15c3f6346d3f4ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e2a4201f50346ca97786884a3c6d213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0700b87a04614eb494cd0db76d14610a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47600c76977346158118e50663acad0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cddaac22b1674944952dac85770a5c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab6522c7500c49afb801ce44428079a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55f6cd473a14465eb9f98747e5c704b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcff1394adc84fcd887e2362176ddf94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b13a239fb0546419c6a369d143a30c5",
              "IPY_MODEL_444f53010cad487abd82dc2c19f5af04",
              "IPY_MODEL_23959cddb2a142a38c7a3a2af00baaa3"
            ],
            "layout": "IPY_MODEL_a59f023ccda945fe99da9c49a5763fd9"
          }
        },
        "1b13a239fb0546419c6a369d143a30c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a3af1e6e0484854907f9b507f3ba29b",
            "placeholder": "​",
            "style": "IPY_MODEL_058118a1bf98493cb5a8c4f6c3119c2f",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "444f53010cad487abd82dc2c19f5af04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_495e0d6dee3a4eceaf66597f087a9142",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70a40856665c4f6c8c4b4754d1ded00f",
            "value": 570
          }
        },
        "23959cddb2a142a38c7a3a2af00baaa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae57dccf5c240c4a0804407064dc557",
            "placeholder": "​",
            "style": "IPY_MODEL_4c31aa3e121948b39e5d29251195d50c",
            "value": " 570/570 [00:00&lt;00:00, 40.4kB/s]"
          }
        },
        "a59f023ccda945fe99da9c49a5763fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a3af1e6e0484854907f9b507f3ba29b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058118a1bf98493cb5a8c4f6c3119c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "495e0d6dee3a4eceaf66597f087a9142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70a40856665c4f6c8c4b4754d1ded00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ae57dccf5c240c4a0804407064dc557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c31aa3e121948b39e5d29251195d50c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dc85087cb514612902ff3fd7a31f52a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67ed863795cc427ba0229f11c189574f",
              "IPY_MODEL_89ece8051a4145a1a9250c3619cc3d69",
              "IPY_MODEL_1c19bd6f12eb43fb8b1762dca0f7156d"
            ],
            "layout": "IPY_MODEL_2ddb6cd7dae64f9ca8f1eed7041e549d"
          }
        },
        "67ed863795cc427ba0229f11c189574f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2555f02e19634cf09e6d90fcd19bc8f9",
            "placeholder": "​",
            "style": "IPY_MODEL_836f5ec726ef4b10bd81111399051351",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "89ece8051a4145a1a9250c3619cc3d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835d552b1671477ab175af2b3972e78a",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb0e85b22ba341b7ae712bf691f5ea57",
            "value": 213450
          }
        },
        "1c19bd6f12eb43fb8b1762dca0f7156d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af037d77fefc4384bf30175364ed290a",
            "placeholder": "​",
            "style": "IPY_MODEL_c97e1afc87de42ae82db0b1f1008477c",
            "value": " 213k/213k [00:00&lt;00:00, 508kB/s]"
          }
        },
        "2ddb6cd7dae64f9ca8f1eed7041e549d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2555f02e19634cf09e6d90fcd19bc8f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "836f5ec726ef4b10bd81111399051351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "835d552b1671477ab175af2b3972e78a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb0e85b22ba341b7ae712bf691f5ea57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af037d77fefc4384bf30175364ed290a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c97e1afc87de42ae82db0b1f1008477c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21d263226f9c4286b82dd889b6ad3bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5fe108b978d44e0a23a4b7aea132ae0",
              "IPY_MODEL_260c4c6643c849c5beb873eb546f611f",
              "IPY_MODEL_0c2407cf57fd4fd49b16f40f01b56b8d"
            ],
            "layout": "IPY_MODEL_1382797841724e53838fcc6f790add4e"
          }
        },
        "b5fe108b978d44e0a23a4b7aea132ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a04eb864a8547a8b76f72dbf977d422",
            "placeholder": "​",
            "style": "IPY_MODEL_c4115191c24949b19fa61d34e5304c42",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "260c4c6643c849c5beb873eb546f611f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7621eea7b1024de6909d0b26e3cf5663",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a69147d3d76f45239a3fae7383ec8da4",
            "value": 435797
          }
        },
        "0c2407cf57fd4fd49b16f40f01b56b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bfc5f70940949f3820bf842e1949a29",
            "placeholder": "​",
            "style": "IPY_MODEL_251c3cb9a12949a089b44f7f1333e6d0",
            "value": " 436k/436k [00:00&lt;00:00, 693kB/s]"
          }
        },
        "1382797841724e53838fcc6f790add4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a04eb864a8547a8b76f72dbf977d422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4115191c24949b19fa61d34e5304c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7621eea7b1024de6909d0b26e3cf5663": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a69147d3d76f45239a3fae7383ec8da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3bfc5f70940949f3820bf842e1949a29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "251c3cb9a12949a089b44f7f1333e6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}