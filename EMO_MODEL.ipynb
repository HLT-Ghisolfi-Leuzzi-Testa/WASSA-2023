{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_B-_QwdhWLe"
      },
      "source": [
        "# WASSA2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:04:39.939508Z",
          "iopub.status.busy": "2023-07-11T19:04:39.938937Z",
          "iopub.status.idle": "2023-07-11T19:04:39.955669Z",
          "shell.execute_reply": "2023-07-11T19:04:39.954582Z",
          "shell.execute_reply.started": "2023-07-11T19:04:39.939467Z"
        },
        "id": "9sDeMksltGSk",
        "outputId": "681d4edd-3a07-4eed-8f1b-a3551285a068",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15KoBLrVhbI8"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FTWi38mQKxUK"
      },
      "outputs": [],
      "source": [
        "repo_path = \"https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/\"\n",
        "branch = \"main\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:04:39.958361Z",
          "iopub.status.busy": "2023-07-11T19:04:39.958022Z",
          "iopub.status.idle": "2023-07-11T19:06:28.298280Z",
          "shell.execute_reply": "2023-07-11T19:06:28.297057Z",
          "shell.execute_reply.started": "2023-07-11T19:04:39.958330Z"
        },
        "id": "1gnWTVNYDMx2",
        "outputId": "4eea8688-2772-4def-969d-b3a6366c2666",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for NRCLex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers -q\n",
        "!pip install accelerate -U -q\n",
        "!pip install datasets -q\n",
        "!pip install torch-summary -q\n",
        "!pip install graphviz -q\n",
        "!pip install torchview -q\n",
        "!pip install bertviz -q\n",
        "!pip install NRCLex -q\n",
        "!pip install textblob -q\n",
        "!python -m textblob.download_corpora -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:28.300542Z",
          "iopub.status.busy": "2023-07-11T19:06:28.299931Z",
          "iopub.status.idle": "2023-07-11T19:06:30.619028Z",
          "shell.execute_reply": "2023-07-11T19:06:30.617896Z",
          "shell.execute_reply.started": "2023-07-11T19:06:28.300504Z"
        },
        "id": "9Xbo-Ei3IAYB",
        "outputId": "cd1a6b67-d729-4082-d25c-f0f3fc981963",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-13 12:07:13--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27866 (27K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "\rutils.py              0%[                    ]       0  --.-KB/s               \rutils.py            100%[===================>]  27.21K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-07-13 12:07:13 (19.9 MB/s) - ‘utils.py’ saved [27866/27866]\n",
            "\n",
            "--2023-07-13 12:07:13--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/evaluation.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10675 (10K) [text/plain]\n",
            "Saving to: ‘evaluation.py’\n",
            "\n",
            "evaluation.py       100%[===================>]  10.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-13 12:07:14 (71.4 MB/s) - ‘evaluation.py’ saved [10675/10675]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "utils_url = f\"{repo_path}{branch}/utils.py\"\n",
        "evaluation_url = f\"{repo_path}{branch}/evaluation.py\"\n",
        "\n",
        "import os\n",
        "if os.path.exists(\"utils.py\"):\n",
        "  !rm \"utils.py\"\n",
        "if os.path.exists(\"evaluation.py\"):\n",
        "  !rm \"evaluation.py\"\n",
        "\n",
        "!wget {utils_url}\n",
        "!wget {evaluation_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:30.622919Z",
          "iopub.status.busy": "2023-07-11T19:06:30.622582Z",
          "iopub.status.idle": "2023-07-11T19:06:38.755450Z",
          "shell.execute_reply": "2023-07-11T19:06:38.754266Z",
          "shell.execute_reply.started": "2023-07-11T19:06:30.622890Z"
        },
        "id": "kEVk5afqZjf1",
        "outputId": "e5110ce0-455b-4635-fd49-49a91c112cfc",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-13 12:07:14--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMO23_lexicon_per_word_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13477977 (13M) [text/plain]\n",
            "Saving to: ‘EMO23_lexicon_per_word_train.json’\n",
            "\n",
            "EMO23_lexicon_per_w 100%[===================>]  12.85M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-07-13 12:07:15 (176 MB/s) - ‘EMO23_lexicon_per_word_train.json’ saved [13477977/13477977]\n",
            "\n",
            "--2023-07-13 12:07:15--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMP23_lexicon_per_word_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7607723 (7.3M) [text/plain]\n",
            "Saving to: ‘EMP23_lexicon_per_word_train.json’\n",
            "\n",
            "EMP23_lexicon_per_w 100%[===================>]   7.25M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-07-13 12:07:15 (151 MB/s) - ‘EMP23_lexicon_per_word_train.json’ saved [7607723/7607723]\n",
            "\n",
            "--2023-07-13 12:07:15--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMO23_lexicon_per_word_dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1058526 (1.0M) [text/plain]\n",
            "Saving to: ‘EMO23_lexicon_per_word_dev.json’\n",
            "\n",
            "EMO23_lexicon_per_w 100%[===================>]   1.01M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-07-13 12:07:16 (41.0 MB/s) - ‘EMO23_lexicon_per_word_dev.json’ saved [1058526/1058526]\n",
            "\n",
            "--2023-07-13 12:07:16--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMP23_lexicon_per_word_dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 595839 (582K) [text/plain]\n",
            "Saving to: ‘EMP23_lexicon_per_word_dev.json’\n",
            "\n",
            "EMP23_lexicon_per_w 100%[===================>] 581.87K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-07-13 12:07:17 (12.3 MB/s) - ‘EMP23_lexicon_per_word_dev.json’ saved [595839/595839]\n",
            "\n",
            "--2023-07-13 12:07:17--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMO23_lexicon_per_word_test.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 651198 (636K) [text/plain]\n",
            "Saving to: ‘EMO23_lexicon_per_word_test.json’\n",
            "\n",
            "EMO23_lexicon_per_w 100%[===================>] 635.94K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-07-13 12:07:17 (40.2 MB/s) - ‘EMO23_lexicon_per_word_test.json’ saved [651198/651198]\n",
            "\n",
            "--2023-07-13 12:07:17--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMP23_lexicon_per_word_test.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 362281 (354K) [text/plain]\n",
            "Saving to: ‘EMP23_lexicon_per_word_test.json’\n",
            "\n",
            "EMP23_lexicon_per_w 100%[===================>] 353.79K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-07-13 12:07:17 (27.0 MB/s) - ‘EMP23_lexicon_per_word_test.json’ saved [362281/362281]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EMO_json_path_train = f\"{repo_path}{branch}/datasets/EMO23_lexicon_per_word_train.json\"\n",
        "EMP_json_path_train = f\"{repo_path}{branch}/datasets/EMP23_lexicon_per_word_train.json\"\n",
        "EMO_json_path_dev = f\"{repo_path}{branch}/datasets/EMO23_lexicon_per_word_dev.json\"\n",
        "EMP_json_path_dev = f\"{repo_path}{branch}/datasets/EMP23_lexicon_per_word_dev.json\"\n",
        "EMO_json_path_test = f\"{repo_path}{branch}/datasets/EMO23_lexicon_per_word_test.json\"\n",
        "EMP_json_path_test = f\"{repo_path}{branch}/datasets/EMP23_lexicon_per_word_test.json\"\n",
        "\n",
        "!wget {EMO_json_path_train}\n",
        "!wget {EMP_json_path_train}\n",
        "!wget {EMO_json_path_dev}\n",
        "!wget {EMP_json_path_dev}\n",
        "!wget {EMO_json_path_test}\n",
        "!wget {EMP_json_path_test}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:38.757963Z",
          "iopub.status.busy": "2023-07-11T19:06:38.757555Z",
          "iopub.status.idle": "2023-07-11T19:06:52.358142Z",
          "shell.execute_reply": "2023-07-11T19:06:52.357177Z",
          "shell.execute_reply.started": "2023-07-11T19:06:38.757924Z"
        },
        "id": "XDmQslVxDhy1",
        "outputId": "bcf17727-4453-477e-cf3e-b3000d3ddf75",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'utils' from '/content/utils.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "import string\n",
        "from torch import nn\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
        "from transformers import TrainingArguments, Trainer, TrainerCallback, EarlyStoppingCallback\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import AutoConfig, BertForSequenceClassification, RobertaForSequenceClassification, RobertaModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from typing import Optional, Union, Tuple\n",
        "from nrclex import NRCLex\n",
        "import importlib\n",
        "import sys\n",
        "from torch.utils.data import Dataset\n",
        "from utils import *\n",
        "importlib.reload(sys.modules['utils'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:52.360520Z",
          "iopub.status.busy": "2023-07-11T19:06:52.359527Z",
          "iopub.status.idle": "2023-07-11T19:06:52.392731Z",
          "shell.execute_reply": "2023-07-11T19:06:52.391807Z",
          "shell.execute_reply.started": "2023-07-11T19:06:52.360482Z"
        },
        "id": "quom7lWCDiiI",
        "outputId": "f5b74ac2-d0d6-4b53-b4ea-abfa59284179",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= CUDA Available =======\n"
          ]
        }
      ],
      "source": [
        "# set CUDA if available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"======= CUDA Available =======\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"======= CUDA NOT Available, run on CPU =======\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gsXzUtCBv-j"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIUOnGp-_6lV"
      },
      "source": [
        "### WASSA dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:52.394814Z",
          "iopub.status.busy": "2023-07-11T19:06:52.394204Z",
          "iopub.status.idle": "2023-07-11T19:06:52.406593Z",
          "shell.execute_reply": "2023-07-11T19:06:52.405612Z",
          "shell.execute_reply.started": "2023-07-11T19:06:52.394779Z"
        },
        "id": "S2o5IfHdgXXf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "emotions_names = [\n",
        "    'fear',\n",
        "    'anger',\n",
        "    'anticipation',\n",
        "    'trust',\n",
        "    'surprise',\n",
        "    'positive',\n",
        "    'negative',\n",
        "    'sadness',\n",
        "    'disgust',\n",
        "    'joy',\n",
        "    'hope'\n",
        "]\n",
        "\n",
        "TASK = \"EMO\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:52.410007Z",
          "iopub.status.busy": "2023-07-11T19:06:52.409372Z",
          "iopub.status.idle": "2023-07-11T19:06:52.429476Z",
          "shell.execute_reply": "2023-07-11T19:06:52.428716Z",
          "shell.execute_reply.started": "2023-07-11T19:06:52.409972Z"
        },
        "id": "WOuBgl-TmlM-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class WASSADataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer,\n",
        "        essay,\n",
        "        essay_id,\n",
        "        targets,\n",
        "        sep=False,\n",
        "        prompt=None,\n",
        "        EMP_lexicon = None,\n",
        "        EMO_lexicon = None,\n",
        "        global_features = None,\n",
        "        local_emotions = False,\n",
        "        local_empathy = False,\n",
        "        local_distress = False,\n",
        "        max_len=None\n",
        "        ):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.essay = essay\n",
        "        self.essay_id = essay_id\n",
        "        self.targets = targets\n",
        "        self.EMP_lexicon = EMP_lexicon\n",
        "        self.EMO_lexicon = EMO_lexicon\n",
        "        self.sep = sep\n",
        "        self.prompt = prompt\n",
        "\n",
        "        self.global_features = global_features\n",
        "        self.local_emotions = local_emotions\n",
        "        self.local_empathy = local_empathy\n",
        "        self.local_distress = local_distress\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        essay = str(self.essay[index])\n",
        "\n",
        "        essay_id = self.essay_id[index]\n",
        "\n",
        "        prompt = \"\"\n",
        "        if self.prompt is not None:\n",
        "          for i, p in enumerate(self.prompt[index]):\n",
        "            prompt += \" \" + str(p)\n",
        "\n",
        "        text = essay\n",
        "        text_pair = None\n",
        "        if self.sep:\n",
        "          text_pair = prompt\n",
        "        else:\n",
        "          if self.prompt is not None:\n",
        "            text += prompt\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text=essay,\n",
        "            text_pair=text_pair,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "          'input_ids': inputs['input_ids'].flatten(),\n",
        "          'attention_mask': inputs['attention_mask'].flatten(),\n",
        "          'token_type_ids': inputs[\"token_type_ids\"].flatten()\n",
        "        }\n",
        "\n",
        "        if self.targets is not None:\n",
        "          item['labels'] = torch.FloatTensor(self.targets[index])\n",
        "\n",
        "        if self.global_features is not None:\n",
        "          item['global_features'] = self.global_features[index]\n",
        "\n",
        "        n_local_features = 0\n",
        "        features_tokens_row = []\n",
        "        if self.local_emotions:\n",
        "            n_local_features += len(emotions_names)\n",
        "            for i in range(len(emotions_names)):\n",
        "                features_tokens_row.append(0)\n",
        "        if self.local_empathy:\n",
        "            n_local_features += 1\n",
        "            features_tokens_row.append(4)\n",
        "        if self.local_distress:\n",
        "            n_local_features += 1\n",
        "            features_tokens_row.append(0)\n",
        "\n",
        "        if n_local_features > 0:\n",
        "            features_tokens = np.full((self.tokenizer.model_max_length, n_local_features), features_tokens_row)\n",
        "        else:\n",
        "          features_tokens = None\n",
        "\n",
        "        word_count=0\n",
        "        first_char=True\n",
        "        last_char_is_space=False\n",
        "        for char_idx, char in enumerate(essay):\n",
        "          token_idx = inputs.char_to_token(char_idx)\n",
        "          if token_idx is None:\n",
        "            if first_char: last_char_is_space=True\n",
        "            if not last_char_is_space and not first_char:\n",
        "              word_count+=1\n",
        "              last_char_is_space=True\n",
        "            continue\n",
        "          elif last_char_is_space:\n",
        "            last_char_is_space=False\n",
        "          first_char=False\n",
        "\n",
        "          j = 0\n",
        "          if char not in string.punctuation:\n",
        "            if self.local_emotions:\n",
        "              for i, emo in enumerate(emotions_names):\n",
        "                features_tokens[token_idx][i] = self.EMO_lexicon[str(essay_id)][emo][word_count]\n",
        "              j += len(emotions_names)\n",
        "\n",
        "            if self.local_empathy:\n",
        "              features_tokens[token_idx][j] = self.EMP_lexicon[str(essay_id)]['empathy'][word_count]\n",
        "              j += 1\n",
        "\n",
        "\n",
        "            if self.local_distress:\n",
        "              features_tokens[token_idx][j] = self.EMP_lexicon[str(essay_id)]['distress'][word_count]\n",
        "\n",
        "        if features_tokens is not None:\n",
        "            item['local_features'] = torch.FloatTensor(features_tokens)\n",
        "\n",
        "        #item['return_dict']=True\n",
        "\n",
        "        return item"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUd7BQjSsVMJ"
      },
      "source": [
        "Dataset paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:09:57.899510Z",
          "iopub.status.busy": "2023-07-11T19:09:57.899102Z",
          "iopub.status.idle": "2023-07-11T19:09:57.904814Z",
          "shell.execute_reply": "2023-07-11T19:09:57.903813Z",
          "shell.execute_reply.started": "2023-07-11T19:09:57.899476Z"
        },
        "id": "BjM03TscDwcz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "TRAIN_DATA = f\"{repo_path}{branch}/datasets/WASSA23_essay_level_original_internal_train_preproc.tsv\"\n",
        "VAL_DATA = f\"{repo_path}{branch}/datasets/WASSA23_essay_level_original_internal_val_preproc.tsv\"\n",
        "DEV_DATA = f\"{repo_path}{branch}/datasets/WASSA23_essay_level_dev_preproc.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFI6AulQsYci"
      },
      "source": [
        "Read dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:05.747579Z",
          "iopub.status.busy": "2023-07-11T19:10:05.747000Z",
          "iopub.status.idle": "2023-07-11T19:10:05.979691Z",
          "shell.execute_reply": "2023-07-11T19:10:05.978760Z",
          "shell.execute_reply.started": "2023-07-11T19:10:05.747546Z"
        },
        "id": "Sppn6sPYsBqA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(TRAIN_DATA, sep='\\t')\n",
        "val_df = pd.read_csv(VAL_DATA, sep='\\t')\n",
        "dev_df = pd.read_csv(DEV_DATA, sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:05.983199Z",
          "iopub.status.busy": "2023-07-11T19:10:05.982479Z",
          "iopub.status.idle": "2023-07-11T19:10:05.991153Z",
          "shell.execute_reply": "2023-07-11T19:10:05.989896Z",
          "shell.execute_reply.started": "2023-07-11T19:10:05.983164Z"
        },
        "id": "hygjdzlasIEL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "label_encoder = EmotionsLabelEncoder()\n",
        "label_encoder.fit(train_df.emotion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDJWlHhwsfwL"
      },
      "source": [
        "Encode targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.006808Z",
          "iopub.status.busy": "2023-07-11T19:10:06.006358Z",
          "iopub.status.idle": "2023-07-11T19:10:06.021824Z",
          "shell.execute_reply": "2023-07-11T19:10:06.020868Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.006776Z"
        },
        "id": "6LKqRnKdsJdu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y_train = label_encoder.encode(train_df.emotion)\n",
        "y_val = label_encoder.encode(val_df.emotion)\n",
        "y_dev = label_encoder.encode(dev_df.emotion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "g78XkRZL6xHY"
      },
      "outputs": [],
      "source": [
        "#@title Model Class\n",
        "MODEL_CLASS_STRING = \"BertForSequenceClassification\" #@param [\"BertForSequenceClassification\", \"RobertaForSequenceClassification\"]\n",
        "model_id = 'BertBioPrompt' #@param {type:\"string\"}\n",
        "model_name = 'bert-base' #@param [\"bert-base\", \"roberta-base\"]\n",
        "\n",
        "if MODEL_CLASS_STRING == \"BertForSequenceClassification\":\n",
        "  MODEL_CLASS = BertForSequenceClassification\n",
        "else:\n",
        "  MODEL_CLASS = RobertaForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.026995Z",
          "iopub.status.busy": "2023-07-11T19:10:06.026313Z",
          "iopub.status.idle": "2023-07-11T19:10:06.034340Z",
          "shell.execute_reply": "2023-07-11T19:10:06.033205Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.026970Z"
        },
        "id": "j6y4HnEP6gcI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#@title Global Features\n",
        "emo_count_global = False #@param {type:\"boolean\"}\n",
        "empathy_count_global = False #@param {type:\"boolean\"}\n",
        "distress_count_global = False #@param {type:\"boolean\"}\n",
        "gold_empathy = False #@param {type:\"boolean\"}\n",
        "gold_distress = False #@param {type:\"boolean\"}\n",
        "bio_global = False #@param {type:\"boolean\"}\n",
        "global_features_names = []\n",
        "emotions_count = ['fear_count',\t'anger_count','anticipation_count',\t'trust_count',\n",
        "                 'positive_count',\t'negative_count', 'surprise_count',\n",
        "                 'sadness_count',\t'disgust_count',\t'joy_count',\t'hope_count']\n",
        "bio = ['gender', 'age', 'income', 'race', 'education']\n",
        "if emo_count_global:\n",
        "  for emo in emotions_count: global_features_names.append(emo)\n",
        "if empathy_count_global: global_features_names.append('empathy_count')\n",
        "if distress_count_global: global_features_names.append('distress_count')\n",
        "if gold_empathy: global_features_names.append('empathy')\n",
        "if gold_distress: global_features_names.append('distress')\n",
        "if bio_global:\n",
        "  for b in bio: global_features_names.append(b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.036262Z",
          "iopub.status.busy": "2023-07-11T19:10:06.035925Z",
          "iopub.status.idle": "2023-07-11T19:10:06.048932Z",
          "shell.execute_reply": "2023-07-11T19:10:06.048042Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.036232Z"
        },
        "id": "n3snAqfK6728",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#@title Local Features\n",
        "emo_count_local = False #@param {type:\"boolean\"}\n",
        "empathy_count_local = False #@param {type:\"boolean\"}\n",
        "distress_count_local = False #@param {type:\"boolean\"}\n",
        "\n",
        "local_features_names = []\n",
        "if emo_count_local: local_features_names.append('emotions')\n",
        "if empathy_count_local: local_features_names.append('empathy')\n",
        "if distress_count_local: local_features_names.append('distress')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "EaTQUHDY6xHZ"
      },
      "outputs": [],
      "source": [
        "#@title Prompt\n",
        "bio_prompt = True #@param {type:\"boolean\"}\n",
        "emo_prompt = False #@param {type:\"boolean\"}\n",
        "empathy_prompt = False #@param {type:\"boolean\"}\n",
        "prompt = []\n",
        "prompt_names = [\"prompt_bio\", \"prompt_emp\", \"prompt_emo\"]\n",
        "if bio_prompt:\n",
        "    prompt.append(prompt_names[0])\n",
        "if empathy_prompt:\n",
        "    prompt.append(prompt_names[1])\n",
        "if emo_prompt:\n",
        "    prompt.append(prompt_names[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.052235Z",
          "iopub.status.busy": "2023-07-11T19:10:06.051958Z",
          "iopub.status.idle": "2023-07-11T19:10:06.059593Z",
          "shell.execute_reply": "2023-07-11T19:10:06.058689Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.052213Z"
        },
        "id": "7JyTdDiw9TWP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#@title Number of labels\n",
        "num_labels = 8 #@param {type:\"number\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.061536Z",
          "iopub.status.busy": "2023-07-11T19:10:06.061089Z",
          "iopub.status.idle": "2023-07-11T19:10:06.069916Z",
          "shell.execute_reply": "2023-07-11T19:10:06.069051Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.061505Z"
        },
        "id": "dA224FxADpqd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "NUM_LABELS = num_labels\n",
        "GLOBAL_FEATURES_NAMES = global_features_names\n",
        "LOCAL_FEATURES_NAMES = local_features_names\n",
        "DIM_EXTRA_FEATURES_GLOBAL = len(GLOBAL_FEATURES_NAMES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbCKVWh7-gpg"
      },
      "source": [
        "Extra global features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "7VpOAsXL6xHa"
      },
      "outputs": [],
      "source": [
        "if len(global_features_names) > 0:\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(np.array(train_df[GLOBAL_FEATURES_NAMES]))\n",
        "\n",
        "  def scandar_scalar_features(features):\n",
        "    return scaler.transform(features)\n",
        "\n",
        "  features_train =  scandar_scalar_features(np.array(train_df[GLOBAL_FEATURES_NAMES]))\n",
        "  features_val =  scandar_scalar_features(np.array(val_df[GLOBAL_FEATURES_NAMES]))\n",
        "  features_dev =  scandar_scalar_features(np.array(dev_df[GLOBAL_FEATURES_NAMES]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfm0n2Mk6xHb"
      },
      "source": [
        "Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "5WnGSQwv6xHb"
      },
      "outputs": [],
      "source": [
        "prompt_train = np.array(train_df[prompt])\n",
        "prompt_val = np.array(val_df[prompt])\n",
        "prompt_dev = np.array(dev_df[prompt])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwYXJId_-Sb5"
      },
      "source": [
        "## Lexicons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:09.185627Z",
          "iopub.status.busy": "2023-07-11T19:11:09.185261Z",
          "iopub.status.idle": "2023-07-11T19:11:09.667265Z",
          "shell.execute_reply": "2023-07-11T19:11:09.666254Z",
          "shell.execute_reply.started": "2023-07-11T19:11:09.185595Z"
        },
        "id": "Qg0D38kk-Rrv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "with open(\"/content/EMO23_lexicon_per_word_train.json\") as json_file:\n",
        "  EMO_lexicon_train_dict = json.load(json_file)\n",
        "with open(\"/content/EMP23_lexicon_per_word_train.json\") as json_file:\n",
        "  EMP_lexicon_train_dict = json.load(json_file)\n",
        "with open(\"/content/EMO23_lexicon_per_word_dev.json\") as json_file:\n",
        "  EMO_lexicon_dev_dict = json.load(json_file)\n",
        "with open(\"/content/EMP23_lexicon_per_word_dev.json\") as json_file:\n",
        "  EMP_lexicon_dev_dict = json.load(json_file)\n",
        "with open(\"/content/EMO23_lexicon_per_word_test.json\") as json_file:\n",
        "  EMO_lexicon_test_dict = json.load(json_file)\n",
        "with open(\"/content/EMP23_lexicon_per_word_test.json\") as json_file:\n",
        "  EMP_lexicon_test_dict = json.load(json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXIimY5ABmlc"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:17.217440Z",
          "iopub.status.busy": "2023-07-11T19:11:17.217004Z",
          "iopub.status.idle": "2023-07-11T19:11:17.225859Z",
          "shell.execute_reply": "2023-07-11T19:11:17.224898Z",
          "shell.execute_reply.started": "2023-07-11T19:11:17.217403Z"
        },
        "id": "wtbV4tekujaC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_type ={\n",
        "  'distilroberta-emotion':'j-hartmann/emotion-english-distilroberta-base',\n",
        "  'roberta-emotion':'j-hartmann/emotion-english-roberta-large',\n",
        "  'bert-base': 'bert-base-cased',\n",
        "  'roberta-base' : 'roberta-base'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:17.229021Z",
          "iopub.status.busy": "2023-07-11T19:11:17.228297Z",
          "iopub.status.idle": "2023-07-11T19:11:17.240056Z",
          "shell.execute_reply": "2023-07-11T19:11:17.239129Z",
          "shell.execute_reply.started": "2023-07-11T19:11:17.228988Z"
        },
        "id": "Cxq0isZT6KQW",
        "outputId": "7d9c0b29-46e9-4007-c81f-ef9e81609cb2",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘BertBioPrompt’: File exists\n"
          ]
        }
      ],
      "source": [
        "model_config = {\n",
        "    'model_id': model_id,\n",
        "    'tokenizer_name': model_type.get(model_name),\n",
        "    'model_name': model_type.get(model_name),\n",
        "    'train_batch_size': 8,\n",
        "    'val_batch_size': 8,\n",
        "    'learning_rate': 5e-5,\n",
        "    'weight_decay': 0,\n",
        "    'epochs': 30,\n",
        "    'seed': 42,\n",
        "    'patience': 5,\n",
        "    'early_stopping_threshold': 0,\n",
        "    'weighted_loss': True\n",
        "}\n",
        "\n",
        "path_tosave = f\"{model_config['model_id']}\"\n",
        "!mkdir $path_tosave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:22.362620Z",
          "iopub.status.busy": "2023-07-11T19:11:22.361776Z",
          "iopub.status.idle": "2023-07-11T19:11:23.697235Z",
          "shell.execute_reply": "2023-07-11T19:11:23.696230Z",
          "shell.execute_reply.started": "2023-07-11T19:11:22.362585Z"
        },
        "id": "wd7W2HhYsbai",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_config['tokenizer_name'], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:17.243014Z",
          "iopub.status.busy": "2023-07-11T19:11:17.241592Z",
          "iopub.status.idle": "2023-07-11T19:11:17.253391Z",
          "shell.execute_reply": "2023-07-11T19:11:17.252383Z",
          "shell.execute_reply.started": "2023-07-11T19:11:17.242979Z"
        },
        "id": "hfwVaaj-0qDq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_loss_weights(y):\n",
        "  inverse_n_samples = 1 / np.sum(y, axis=0)\n",
        "  sum_inverses = sum(inverse_n_samples)\n",
        "  weights_train = inverse_n_samples / sum_inverses\n",
        "  return torch.cuda.FloatTensor(weights_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:17.257384Z",
          "iopub.status.busy": "2023-07-11T19:11:17.255861Z",
          "iopub.status.idle": "2023-07-11T19:11:22.360433Z",
          "shell.execute_reply": "2023-07-11T19:11:22.359379Z",
          "shell.execute_reply.started": "2023-07-11T19:11:17.257351Z"
        },
        "id": "wVh3_jCFzmK7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if model_config.get('weighted_loss'):\n",
        "  loss_weights_train = get_loss_weights(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6aAhPift1UL"
      },
      "source": [
        "### Custom model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:23.702374Z",
          "iopub.status.busy": "2023-07-11T19:11:23.702059Z",
          "iopub.status.idle": "2023-07-11T19:11:23.732141Z",
          "shell.execute_reply": "2023-07-11T19:11:23.730692Z",
          "shell.execute_reply.started": "2023-07-11T19:11:23.702348Z"
        },
        "id": "2Vj3W-oUhBMZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    #Head for sentence-level classification tasks.\n",
        "\n",
        "    def __init__(self, config, num_extra_dims, hidden_layers_to_concat, classifier_dropout, local_features, mean_last_cls):\n",
        "        super().__init__()\n",
        "        self.local_features = local_features\n",
        "\n",
        "        if mean_last_cls:\n",
        "          total_dims = config.hidden_size + num_extra_dims\n",
        "        else:\n",
        "          total_dims = config.hidden_size*hidden_layers_to_concat + num_extra_dims\n",
        "        if self.local_features:\n",
        "          total_dims += config.hidden_size\n",
        "        self.dense = nn.Linear(total_dims, total_dims)\n",
        "        self.dropout = nn.Dropout(classifier_dropout)\n",
        "        self.out_proj = nn.Linear(total_dims, config.num_labels)\n",
        "\n",
        "    def forward(self, features, **kwargs):\n",
        "        x = self.dense(features)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.out_proj(x)\n",
        "        return x\n",
        "\n",
        "class CustomSequenceClassification(MODEL_CLASS):\n",
        "\n",
        "    def __init__(self, config, num_extra_dims=0, local_features_name=None, loss_weights=None, last_cls = 1, mean_last_cls = False):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.config = config\n",
        "        self.local_features_name = local_features_name\n",
        "        self.loss_weights = loss_weights\n",
        "        self.last_cls = last_cls\n",
        "        self.mean_last_cls = mean_last_cls\n",
        "        if MODEL_CLASS_STRING == \"BertForSequenceClassification\":\n",
        "          self.bert = BertModel(config)\n",
        "        else:\n",
        "          self.bert = RobertaModel(config)\n",
        "        classifier_dropout = (\n",
        "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
        "        )\n",
        "        self.dropout = nn.Dropout(classifier_dropout)\n",
        "        self.classifier = ClassificationHead(config,\n",
        "                                            num_extra_dims,\n",
        "                                            last_cls,\n",
        "                                            classifier_dropout,\n",
        "                                            local_features_name is not None,\n",
        "                                            mean_last_cls)\n",
        "        self.post_init()\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.LongTensor] = None,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        local_features = None,\n",
        "        global_features = None,\n",
        "        token_type_ids: Optional[torch.LongTensor] = None,\n",
        "        position_ids: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = True,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
        "\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        cls_tokens = []\n",
        "        for i in range(1, self.last_cls + 1):\n",
        "            cls_tokens.append(outputs.hidden_states[-1 * i][:, 0, :])\n",
        "        if self.mean_last_cls:\n",
        "          # average cls tokens\n",
        "          output = torch.mean(torch.stack(cls_tokens), dim=0)\n",
        "        else:\n",
        "          # concat cls tokens\n",
        "          output = torch.cat(cls_tokens, dim=1)\n",
        "\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        if local_features is not None:\n",
        "          tokens_output = outputs.last_hidden_state\n",
        "          tokens_output = self.dropout(tokens_output)\n",
        "\n",
        "          tokens_output = torch.cat((\n",
        "                  tokens_output,\n",
        "                  local_features.reshape(outputs.last_hidden_state.shape[0], outputs.last_hidden_state.shape[1], -1)),\n",
        "                             dim=2)\n",
        "\n",
        "          mask = torch.zeros_like(attention_mask)\n",
        "          # unmask tokens with high or low empathy, high distress levels, or expressing at least one emotion\n",
        "          j = 0\n",
        "          if 'emotions' in self.local_features_name:\n",
        "            emotion_values = local_features[:,:,:11]\n",
        "            mask[emotion_values.sum(dim=-1)>=1] = 1.0\n",
        "            j += 11\n",
        "\n",
        "          if 'empathy' in self.local_features_name:\n",
        "            empathy_values = local_features[:,:,j]\n",
        "            mask[(empathy_values>5) | ((empathy_values<3) & (empathy_values>=1))] = 1.0\n",
        "            j += 1\n",
        "\n",
        "          if 'distress' in self.local_features_name:\n",
        "            distress_values = local_features[:,:,j]\n",
        "            mask[distress_values>4] = 1.0\n",
        "\n",
        "          # mean pooling of unmasked tokens\n",
        "          input_mask_expanded = mask.unsqueeze(-1).expand(tokens_output.size()).float()\n",
        "          sum_embeddings = torch.sum(tokens_output * input_mask_expanded, 1)\n",
        "          sum_mask = input_mask_expanded.sum(1)\n",
        "          sum_mask = torch.clamp(sum_mask, min = 1e-9)\n",
        "          tokens_output = sum_embeddings/sum_mask\n",
        "\n",
        "          # concat pooled tokens lexically relevant with cls token\n",
        "          output = torch.cat((output, tokens_output), dim=-1)\n",
        "\n",
        "\n",
        "        if global_features is not None: # global\n",
        "          output = torch.cat((output, global_features), dim=-1)\n",
        "\n",
        "        logits = self.classifier(output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.config.problem_type is None:\n",
        "                if self.num_labels == 1:\n",
        "                    self.config.problem_type = \"regression\"\n",
        "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
        "                    self.config.problem_type = \"single_label_classification\"\n",
        "                else:\n",
        "                    self.config.problem_type = \"multi_label_classification\"\n",
        "\n",
        "            if self.config.problem_type == \"regression\":\n",
        "                loss_fct = nn.MSELoss()\n",
        "                if self.num_labels == 1:\n",
        "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
        "                else:\n",
        "                    loss = loss_fct(logits, labels)\n",
        "            elif self.config.problem_type == \"single_label_classification\":\n",
        "                loss_fct = nn.CrossEntropyLoss(weight = self.loss_weights)\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            elif self.config.problem_type == \"multi_label_classification\":\n",
        "                loss_fct = nn.BCEWithLogitsLoss(weight = self.loss_weights)\n",
        "                loss = loss_fct(logits, labels)\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:23.734900Z",
          "iopub.status.busy": "2023-07-11T19:11:23.734558Z",
          "iopub.status.idle": "2023-07-11T19:11:27.562951Z",
          "shell.execute_reply": "2023-07-11T19:11:27.562030Z",
          "shell.execute_reply.started": "2023-07-11T19:11:23.734871Z"
        },
        "id": "GvJbF80XhSDE",
        "outputId": "10b202df-cf16-4894-ebd6-fecd61a606bc",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing CustomSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing CustomSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = CustomSequenceClassification.from_pretrained(model_config.get(\"model_name\"),\n",
        "                                                     problem_type = \"multi_label_classification\",\n",
        "                                                     num_labels=NUM_LABELS,\n",
        "                                                     classifier_dropout=0.3,\n",
        "                                                     num_extra_dims=DIM_EXTRA_FEATURES_GLOBAL#,\n",
        "                                                     #last_cls = 4,\n",
        "                                                     #mean_last_cls = True\n",
        "                                                     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xvHbhOhhttG"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY0SLN6usjYs"
      },
      "source": [
        "Prepare datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.565429Z",
          "iopub.status.busy": "2023-07-11T19:11:27.564800Z",
          "iopub.status.idle": "2023-07-11T19:11:27.572683Z",
          "shell.execute_reply": "2023-07-11T19:11:27.571493Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.565394Z"
        },
        "id": "DUIqO6AiZ8al",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_set = WASSADataset(tokenizer=tokenizer,\n",
        "                    essay=train_df.essay,\n",
        "                    prompt=prompt_train,\n",
        "                    #sep=True,\n",
        "                    essay_id = train_df.essay_id,\n",
        "                    targets=y_train#,\n",
        "                    #EMO_lexicon=EMO_lexicon_train_dict,\n",
        "                    #EMP_lexicon=EMP_lexicon_train_dict,\n",
        "                    #global_features = features_train\n",
        "                    #local_emotions = True,\n",
        "                    #local_empathy = True,\n",
        "                    #local_distress = True\n",
        "                )\n",
        "\n",
        "val_set = WASSADataset(tokenizer=tokenizer,\n",
        "                    essay=val_df.essay,\n",
        "                    prompt=prompt_val,\n",
        "                    #sep=True,\n",
        "                    essay_id = val_df.essay_id,\n",
        "                    targets=y_val#,\n",
        "                    #EMO_lexicon=EMO_lexicon_train_dict,\n",
        "                    #EMP_lexicon=EMP_lexicon_train_dict,\n",
        "                    #global_features = features_val\n",
        "                    #local_emotions = True,\n",
        "                    #local_empathy = True,\n",
        "                    #local_distress = True\n",
        "                )\n",
        "dev_set = WASSADataset(tokenizer=tokenizer,\n",
        "                    essay=dev_df.essay,\n",
        "                    prompt=prompt_dev,\n",
        "                    #sep=True,\n",
        "                    essay_id = dev_df.essay_id,\n",
        "                    targets=y_dev#,\n",
        "                    #EMO_lexicon=EMO_lexicon_train_dict,\n",
        "                    #EMP_lexicon=EMP_lexicon_train_dict,\n",
        "                    #global_features = features_dev\n",
        "                    #local_emotions = True,\n",
        "                    #local_empathy = True,\n",
        "                    #local_distress = True\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvduRx8HsteS"
      },
      "source": [
        "Set up training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.574736Z",
          "iopub.status.busy": "2023-07-11T19:11:27.574061Z",
          "iopub.status.idle": "2023-07-11T19:11:27.586314Z",
          "shell.execute_reply": "2023-07-11T19:11:27.585303Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.574702Z"
        },
        "id": "Z1DbZxhkD1R7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_arguments = TrainingArguments(\n",
        "    output_dir=f\"./{model_config['model_name']}\",\n",
        "    per_device_train_batch_size=model_config['train_batch_size'],\n",
        "    per_device_eval_batch_size=model_config['val_batch_size'],\n",
        "    num_train_epochs=model_config['epochs'],\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    eval_steps = 150,\n",
        "    save_steps = 150,\n",
        "    learning_rate=model_config['learning_rate'],\n",
        "    weight_decay=model_config['weight_decay'],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_macro_f1',\n",
        "    seed=model_config['seed'],\n",
        "    logging_strategy = \"epoch\"\n",
        ") # TODO: custom other params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.588557Z",
          "iopub.status.busy": "2023-07-11T19:11:27.587598Z",
          "iopub.status.idle": "2023-07-11T19:11:27.726922Z",
          "shell.execute_reply": "2023-07-11T19:11:27.725911Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.588523Z"
        },
        "id": "hrI2rj4U3K2Q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=train_arguments,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=val_set,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_EMO_metrics_trainer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-sruHQdsraI"
      },
      "source": [
        "Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.731325Z",
          "iopub.status.busy": "2023-07-11T19:11:27.731059Z",
          "iopub.status.idle": "2023-07-11T19:11:27.738285Z",
          "shell.execute_reply": "2023-07-11T19:11:27.737157Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.731302Z"
        },
        "id": "4kUY7tU3sqr3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class TrainerLoggingCallback(TrainerCallback):\n",
        "    def __init__(self, log_path):\n",
        "        self.log_path = log_path\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        _ = logs.pop(\"total_flos\", None)\n",
        "        if state.is_local_process_zero: # whether this process is the main one in a distributed setting\n",
        "            with open(self.log_path, \"a\") as f:\n",
        "                f.write(json.dumps(logs) + \"\\n\")\n",
        "\n",
        "trainer.add_callback(EarlyStoppingCallback(\n",
        "    early_stopping_patience=model_config['patience'],\n",
        "    early_stopping_threshold=model_config['early_stopping_threshold']))\n",
        "\n",
        "trainer.add_callback(TrainerLoggingCallback(model_config['model_id']+\"_log.json\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcCqSooFsw0X"
      },
      "source": [
        "Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.740439Z",
          "iopub.status.busy": "2023-07-11T19:11:27.740100Z",
          "iopub.status.idle": "2023-07-11T19:20:18.229718Z",
          "shell.execute_reply": "2023-07-11T19:20:18.228678Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.740408Z"
        },
        "id": "L8xAPa81D5tu",
        "outputId": "d126c999-c977-4978-e529-b87adbd312e9",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17' max='2340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  17/2340 00:10 < 26:18, 1.47 it/s, Epoch 0.21/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:20:18.263809Z",
          "iopub.status.busy": "2023-07-11T19:20:18.263461Z",
          "iopub.status.idle": "2023-07-11T19:20:18.274394Z",
          "shell.execute_reply": "2023-07-11T19:20:18.272774Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.263776Z"
        },
        "id": "Dd-3octehTlH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Access the training logs\n",
        "train_logs = trainer.state.log_history\n",
        "\n",
        "metrics = [list(log.keys())[:-5] for log in train_logs if log.get('eval_loss') is not None][0]\n",
        "\n",
        "eval_metrics_values = []\n",
        "\n",
        "# Extract the values from the logs\n",
        "train_loss_values = [log.get('loss') for log in train_logs if log.get('loss') is not None]\n",
        "eval_loss_values = [log.get('eval_loss') for log in train_logs if log.get('eval_loss') is not None]\n",
        "for metric in metrics:\n",
        "  eval_metrics_values.append([log.get(metric) for log in train_logs if log.get(metric) is not None])\n",
        "train_epochs = [log.get('epoch') for log in train_logs if log.get('loss') is not None]\n",
        "eval_epochs = [log.get('epoch') for log in train_logs if log.get('eval_loss') is not None]\n",
        "best_epoch_train = np.argmax([(log.get('eval_macro_f1'), log.get('epoch'))for log in train_logs if log.get('eval_loss') is not None])\n",
        "best_counter_val = np.argmax([log.get('eval_macro_f1')for log in train_logs if log.get('eval_loss') is not None])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V5eavAamxKr"
      },
      "source": [
        "Plot losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:20:18.303708Z",
          "iopub.status.busy": "2023-07-11T19:20:18.303144Z",
          "iopub.status.idle": "2023-07-11T19:20:18.378460Z",
          "shell.execute_reply": "2023-07-11T19:20:18.376257Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.303655Z"
        },
        "id": "ECEu3ajRl6k3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "fig_name = \"losses\"\n",
        "plot_metric_curve(\n",
        "    values = [train_loss_values, eval_loss_values],\n",
        "    epochs = [train_epochs, eval_epochs],\n",
        "    metrics = [\"train loss\", \"eval loss\"],\n",
        "    title = fig_name,\n",
        "    path = f\"{path_tosave}/{fig_name}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms0inN8amz33"
      },
      "source": [
        "Plot metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgGrIimdm3si"
      },
      "outputs": [],
      "source": [
        "fig_name = \"metrics\"\n",
        "plot_metric_curve(\n",
        "    values = eval_metrics_values,\n",
        "    epochs = [eval_epochs for _ in eval_metrics_values],\n",
        "    metrics = metrics,\n",
        "    title = fig_name,\n",
        "    path = f\"{path_tosave}/{fig_name}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc5stfSah0Kj"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:32:52.626228Z",
          "iopub.status.busy": "2023-07-11T19:32:52.625699Z",
          "iopub.status.idle": "2023-07-11T19:32:52.641902Z",
          "shell.execute_reply": "2023-07-11T19:32:52.638400Z",
          "shell.execute_reply.started": "2023-07-11T19:32:52.626186Z"
        },
        "id": "19G80dVoH3HZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def predict_emotions(results, gold_emotions):\n",
        "\n",
        "  binarized_predictions = np.where(results >= 0.5, 1, 0)\n",
        "\n",
        "  for i, bin_pred in enumerate(binarized_predictions):\n",
        "    if np.all(bin_pred==0):\n",
        "      binarized_predictions[i][np.argmax(results[i])] = 1\n",
        "\n",
        "  predicted_emotions = label_encoder.decode(binarized_predictions)\n",
        "  return predicted_emotions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSqi0J48F3gF"
      },
      "outputs": [],
      "source": [
        "trainer.state.best_model_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WIAU6a7Mox4"
      },
      "outputs": [],
      "source": [
        "outs = trainer.predict(dev_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:33:06.725818Z",
          "iopub.status.busy": "2023-07-11T19:33:06.725448Z",
          "iopub.status.idle": "2023-07-11T19:33:06.789138Z",
          "shell.execute_reply": "2023-07-11T19:33:06.786525Z",
          "shell.execute_reply.started": "2023-07-11T19:33:06.725788Z"
        },
        "id": "PIKGrBNlYDa1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "gold_emotions = label_encoder.decode(outs.label_ids)\n",
        "predicted_emotions = predict_emotions(outs.predictions[0], gold_emotions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T19:20:18.388286Z",
          "iopub.status.idle": "2023-07-11T19:20:18.389135Z",
          "shell.execute_reply": "2023-07-11T19:20:18.388900Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.388873Z"
        },
        "id": "Im2VGnmQs7bY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "path_predictions = f\"{path_tosave}/predictions_{TASK}.tsv\"\n",
        "path_metrics = f\"{path_tosave}/dev_metrics_{TASK}.json\"\n",
        "\n",
        "scores = {\n",
        "    'train_loss' : train_loss_values[best_epoch_train],\n",
        "    'eval_loss' : eval_loss_values[best_counter_val]\n",
        "}\n",
        "#TODO write predictions con TASK come stringa\n",
        "write_EMO_predictions(predicted_emotions, path_predictions)\n",
        "challenge_metrics = compute_EMO_metrics(golds=gold_emotions, predictions=predicted_emotions)\n",
        "scores.update(challenge_metrics)\n",
        "write_dict_to_json(scores, path_metrics)\n",
        "\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T19:20:18.390758Z",
          "iopub.status.idle": "2023-07-11T19:20:18.391292Z",
          "shell.execute_reply": "2023-07-11T19:20:18.391058Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.391035Z"
        },
        "id": "ITunC36XXLoN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "fig_name = \"confusion_matrix\"\n",
        "plot_confusion_matrix(golds=gold_emotions,\n",
        "                      predictions=predicted_emotions,\n",
        "                      title=fig_name,\n",
        "                      path= f\"{path_tosave}/{fig_name}.png\"\n",
        "                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXM7Xzr36xHw"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix_per_emotions(gold_emotions, predicted_emotions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DuCaju6tSHB"
      },
      "source": [
        "## Save model on Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T19:20:18.405534Z",
          "iopub.status.idle": "2023-07-11T19:20:18.406365Z",
          "shell.execute_reply": "2023-07-11T19:20:18.406135Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.406111Z"
        },
        "id": "b1KcxQQ0uUl6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "best_model_path = trainer.state.best_model_checkpoint\n",
        "\n",
        "# move the best checkpoint in the folder with model id\n",
        "!mv $best_model_path /content/$path_tosave\n",
        "\n",
        "# move the results to personal drive\n",
        "!mv /content/$path_tosave /content/drive/MyDrive/hlt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pkHv9w4tM1F"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1u9D1Z2R_Jc"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint_and_compute_metrics(checkpoint_path):\n",
        "  model = CustomSequenceClassification.from_pretrained(checkpoint_path, num_labels=NUM_LABELS, num_extra_dims = 0)\n",
        "  trainer = Trainer(model=model)\n",
        "  # Perform prediction using the loaded checkpoint\n",
        "  predictions = trainer.predict(dev_set)\n",
        "\n",
        "  gold_emotions = label_encoder.decode(predictions.label_ids)\n",
        "  predicted_emotions = predict_emotions(predictions.predictions[0], gold_emotions)\n",
        "\n",
        "  write_EMO_predictions(predicted_emotions, model_config['model_id']+\"_predictions_EMO.tsv\")\n",
        "  challenge_metrics = compute_EMO_metrics(golds=gold_emotions, predictions=predicted_emotions)\n",
        "  write_dict_to_json(challenge_metrics, model_config['model_id']+\"_dev_metrics.json\")\n",
        "  print(challenge_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC88bo8dSSsr"
      },
      "outputs": [],
      "source": [
        "\"\"\"load_checkpoint_and_compute_metrics(\"/content/bert-base-caseda/checkpoint-1200\")\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T19:20:18.408046Z",
          "iopub.status.idle": "2023-07-11T19:20:18.408865Z",
          "shell.execute_reply": "2023-07-11T19:20:18.408622Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.408599Z"
        },
        "id": "v6hEtBLztMeC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"MODEL_PATH = \"/content/drive/MyDrive/hlt/best-roberta\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, truncation=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    num_labels=NUM_LABELS,\n",
        "    ignore_mismatched_sizes=True,\n",
        "    problem_type=\"multi_label_classification\")\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}