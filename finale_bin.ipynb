{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_B-_QwdhWLe"
      },
      "source": [
        "# WASSA2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:04:39.939508Z",
          "iopub.status.busy": "2023-07-11T19:04:39.938937Z",
          "iopub.status.idle": "2023-07-11T19:04:39.955669Z",
          "shell.execute_reply": "2023-07-11T19:04:39.954582Z",
          "shell.execute_reply.started": "2023-07-11T19:04:39.939467Z"
        },
        "id": "9sDeMksltGSk",
        "outputId": "10471e91-e457-4729-d1dd-f6fb9af85fb7",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15KoBLrVhbI8"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "FTWi38mQKxUK"
      },
      "outputs": [],
      "source": [
        "repo_path = \"https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/\"\n",
        "branch = \"main\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:04:39.958361Z",
          "iopub.status.busy": "2023-07-11T19:04:39.958022Z",
          "iopub.status.idle": "2023-07-11T19:06:28.298280Z",
          "shell.execute_reply": "2023-07-11T19:06:28.297057Z",
          "shell.execute_reply.started": "2023-07-11T19:04:39.958330Z"
        },
        "id": "1gnWTVNYDMx2",
        "outputId": "4d5ea9f0-67ce-4f64-ccc5-cfc125c9ac94",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers -q\n",
        "!pip install accelerate -U -q\n",
        "!pip install datasets -q\n",
        "!pip install torch-summary -q\n",
        "!pip install graphviz -q\n",
        "!pip install torchview -q\n",
        "!pip install bertviz -q\n",
        "!pip install NRCLex -q\n",
        "!pip install textblob -q\n",
        "!python -m textblob.download_corpora -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:28.300542Z",
          "iopub.status.busy": "2023-07-11T19:06:28.299931Z",
          "iopub.status.idle": "2023-07-11T19:06:30.619028Z",
          "shell.execute_reply": "2023-07-11T19:06:30.617896Z",
          "shell.execute_reply.started": "2023-07-11T19:06:28.300504Z"
        },
        "id": "9Xbo-Ei3IAYB",
        "outputId": "d47995b5-4dbc-4ae6-b3a4-7854cd89fe0a",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-18 17:55:44--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38193 (37K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "\rutils.py              0%[                    ]       0  --.-KB/s               \rutils.py            100%[===================>]  37.30K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-07-18 17:55:44 (13.0 MB/s) - ‘utils.py’ saved [38193/38193]\n",
            "\n",
            "--2023-07-18 17:55:44--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/evaluation.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10675 (10K) [text/plain]\n",
            "Saving to: ‘evaluation.py’\n",
            "\n",
            "evaluation.py       100%[===================>]  10.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-18 17:55:44 (77.2 MB/s) - ‘evaluation.py’ saved [10675/10675]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "utils_url = f\"{repo_path}{branch}/utils.py\"\n",
        "evaluation_url = f\"{repo_path}{branch}/evaluation.py\"\n",
        "\n",
        "import os\n",
        "if os.path.exists(\"utils.py\"):\n",
        "  !rm \"utils.py\"\n",
        "if os.path.exists(\"evaluation.py\"):\n",
        "  !rm \"evaluation.py\"\n",
        "\n",
        "!wget {utils_url}\n",
        "!wget {evaluation_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:30.622919Z",
          "iopub.status.busy": "2023-07-11T19:06:30.622582Z",
          "iopub.status.idle": "2023-07-11T19:06:38.755450Z",
          "shell.execute_reply": "2023-07-11T19:06:38.754266Z",
          "shell.execute_reply.started": "2023-07-11T19:06:30.622890Z"
        },
        "id": "kEVk5afqZjf1",
        "outputId": "6e4f6700-285b-4a0c-b041-386c419e739a",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-18 17:55:44--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMO23_lexicon_per_word_.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14536741 (14M) [text/plain]\n",
            "Saving to: ‘EMO23_lexicon_per_word_.json.1’\n",
            "\n",
            "EMO23_lexicon_per_w 100%[===================>]  13.86M  87.5MB/s    in 0.2s    \n",
            "\n",
            "2023-07-18 17:55:45 (87.5 MB/s) - ‘EMO23_lexicon_per_word_.json.1’ saved [14536741/14536741]\n",
            "\n",
            "--2023-07-18 17:55:45--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMP23_lexicon_per_word_.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8203800 (7.8M) [text/plain]\n",
            "Saving to: ‘EMP23_lexicon_per_word_.json.1’\n",
            "\n",
            "EMP23_lexicon_per_w 100%[===================>]   7.82M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-07-18 17:55:46 (65.3 MB/s) - ‘EMP23_lexicon_per_word_.json.1’ saved [8203800/8203800]\n",
            "\n",
            "--2023-07-18 17:55:46--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMO23_lexicon_per_word_test.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 651198 (636K) [text/plain]\n",
            "Saving to: ‘EMO23_lexicon_per_word_test.json.1’\n",
            "\n",
            "EMO23_lexicon_per_w 100%[===================>] 635.94K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-07-18 17:55:46 (24.5 MB/s) - ‘EMO23_lexicon_per_word_test.json.1’ saved [651198/651198]\n",
            "\n",
            "--2023-07-18 17:55:46--  https://raw.githubusercontent.com/HLT-Ghisolfi-Leuzzi-Testa/WASSA-2023/main/datasets/EMP23_lexicon_per_word_test.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 362281 (354K) [text/plain]\n",
            "Saving to: ‘EMP23_lexicon_per_word_test.json.1’\n",
            "\n",
            "EMP23_lexicon_per_w 100%[===================>] 353.79K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-07-18 17:55:47 (15.5 MB/s) - ‘EMP23_lexicon_per_word_test.json.1’ saved [362281/362281]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EMO_json_path_train = f\"{repo_path}{branch}/datasets/EMO23_lexicon_per_word_.json\"\n",
        "EMP_json_path_train = f\"{repo_path}{branch}/datasets/EMP23_lexicon_per_word_.json\"\n",
        "EMO_json_path_test = f\"{repo_path}{branch}/datasets/EMO23_lexicon_per_word_test.json\"\n",
        "EMP_json_path_test = f\"{repo_path}{branch}/datasets/EMP23_lexicon_per_word_test.json\"\n",
        "\n",
        "!wget {EMO_json_path_train}\n",
        "!wget {EMP_json_path_train}\n",
        "!wget {EMO_json_path_test}\n",
        "!wget {EMP_json_path_test}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:38.757963Z",
          "iopub.status.busy": "2023-07-11T19:06:38.757555Z",
          "iopub.status.idle": "2023-07-11T19:06:52.358142Z",
          "shell.execute_reply": "2023-07-11T19:06:52.357177Z",
          "shell.execute_reply.started": "2023-07-11T19:06:38.757924Z"
        },
        "id": "XDmQslVxDhy1",
        "outputId": "782fb977-5b9e-41ec-bce0-bc8064359079",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'utils' from '/content/utils.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "import string\n",
        "from torch import nn\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
        "from transformers import TrainingArguments, Trainer, TrainerCallback, EarlyStoppingCallback\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import AutoConfig, BertForSequenceClassification, RobertaForSequenceClassification, RobertaModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from typing import Optional, Union, Tuple\n",
        "from nrclex import NRCLex\n",
        "import importlib\n",
        "import sys\n",
        "from torch.utils.data import Dataset\n",
        "from utils import *\n",
        "importlib.reload(sys.modules['utils'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:52.360520Z",
          "iopub.status.busy": "2023-07-11T19:06:52.359527Z",
          "iopub.status.idle": "2023-07-11T19:06:52.392731Z",
          "shell.execute_reply": "2023-07-11T19:06:52.391807Z",
          "shell.execute_reply.started": "2023-07-11T19:06:52.360482Z"
        },
        "id": "quom7lWCDiiI",
        "outputId": "b962a44a-63ab-4813-faa5-2e7739b4ba65",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= CUDA Available =======\n"
          ]
        }
      ],
      "source": [
        "# set CUDA if available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"======= CUDA Available =======\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"======= CUDA NOT Available, run on CPU =======\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLrhz2zGdhJT"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:52.394814Z",
          "iopub.status.busy": "2023-07-11T19:06:52.394204Z",
          "iopub.status.idle": "2023-07-11T19:06:52.406593Z",
          "shell.execute_reply": "2023-07-11T19:06:52.405612Z",
          "shell.execute_reply.started": "2023-07-11T19:06:52.394779Z"
        },
        "id": "S2o5IfHdgXXf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "EMOTIONS_NAMES = [\n",
        "    'fear',\n",
        "    'anger',\n",
        "    'anticipation',\n",
        "    'trust',\n",
        "    'surprise',\n",
        "    'positive',\n",
        "    'negative',\n",
        "    'sadness',\n",
        "    'disgust',\n",
        "    'joy',\n",
        "    'hope'\n",
        "]\n",
        "\n",
        "config = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "GMoRVEFkQIPx"
      },
      "outputs": [],
      "source": [
        "#@title Global Features\n",
        "TASK = \"EMO\" #@param [\"EMO\", \"EMP\"]\n",
        "binary_EMO = True #@param {type:\"boolean\"}\n",
        "EMO_binary_emotion = \"fear\" #@param [\"fear\", \"anger\", \"surprise\", \"sadness\", \"disgust\", \"joy\", \"hope\", \"neutral\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.052235Z",
          "iopub.status.busy": "2023-07-11T19:10:06.051958Z",
          "iopub.status.idle": "2023-07-11T19:10:06.059593Z",
          "shell.execute_reply": "2023-07-11T19:10:06.058689Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.052213Z"
        },
        "id": "7JyTdDiw9TWP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#@title Number of labels\n",
        "num_labels = 8 #@param {type:\"integer\"}\n",
        "config['num_labels'] = num_labels\n",
        "if binary_EMO:\n",
        "  config['num_labels'] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "cellView": "form",
        "id": "g78XkRZL6xHY"
      },
      "outputs": [],
      "source": [
        "#@title Model Class\n",
        "model_id = 'distil-1cls' #@param {type:\"string\"}\n",
        "model_class_string = \"RobertaPreTrainedModel\" #@param [\"BertPreTrainedModel\", \"RobertaPreTrainedModel\"]\n",
        "model_name = 'distilroberta-emotion' #@param [\"bert-base\", \"roberta-base\", \"roberta-emotion\", \"distilroberta-emotion\", \"roberta-empathy\"]\n",
        "\n",
        "if model_class_string == \"BertPreTrainedModel\":\n",
        "  model_class = BertForSequenceClassification\n",
        "else:\n",
        "  model_class = RobertaForSequenceClassification\n",
        "\n",
        "config['model_id'] = model_id\n",
        "config['model_class_string'] = model_class_string\n",
        "config['model_name'] = model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.026995Z",
          "iopub.status.busy": "2023-07-11T19:10:06.026313Z",
          "iopub.status.idle": "2023-07-11T19:10:06.034340Z",
          "shell.execute_reply": "2023-07-11T19:10:06.033205Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.026970Z"
        },
        "id": "j6y4HnEP6gcI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#@title Global Features\n",
        "emo_count_global = False #@param {type:\"boolean\"}\n",
        "empathy_count_global = False #@param {type:\"boolean\"}\n",
        "distress_count_global = False #@param {type:\"boolean\"}\n",
        "bio_global = True #@param {type:\"boolean\"}\n",
        "gold_emotions = False #@param {type:\"boolean\"}\n",
        "gold_empathy = True #@param {type:\"boolean\"}\n",
        "gold_distress = True #@param {type:\"boolean\"}\n",
        "\n",
        "if TASK == \"EMO\":\n",
        "  gold_emotions = False\n",
        "if TASK ==\"EMP\":\n",
        "  gold_distress = False\n",
        "  gold_empathy = False\n",
        "\n",
        "global_features_names = []\n",
        "emotions_count = ['fear_count',\t'anger_count','anticipation_count',\t'trust_count',\n",
        "                 'positive_count',\t'negative_count', 'surprise_count',\n",
        "                 'sadness_count',\t'disgust_count',\t'joy_count',\t'hope_count']\n",
        "bio = ['gender', 'age', 'income', 'race', 'education']\n",
        "if emo_count_global:\n",
        "  for emo in emotions_count: global_features_names.append(emo)\n",
        "if empathy_count_global: global_features_names.append('empathy_count')\n",
        "if distress_count_global: global_features_names.append('distress_count')\n",
        "if bio_global:\n",
        "  for b in bio: global_features_names.append(b)\n",
        "\n",
        "if gold_empathy: global_features_names.append('empathy')\n",
        "if gold_distress: global_features_names.append('distress')\n",
        "\n",
        "config['emo_count_global'] = emo_count_global\n",
        "config['empathy_count_global'] = empathy_count_global\n",
        "config['distress_count_global'] = distress_count_global\n",
        "config['bio_global'] = bio_global\n",
        "config['gold_emotions'] = gold_emotions\n",
        "config['gold_empathy'] = gold_empathy\n",
        "config['gold_distress'] = gold_distress\n",
        "config['global_features_names'] = global_features_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.036262Z",
          "iopub.status.busy": "2023-07-11T19:10:06.035925Z",
          "iopub.status.idle": "2023-07-11T19:10:06.048932Z",
          "shell.execute_reply": "2023-07-11T19:10:06.048042Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.036232Z"
        },
        "id": "n3snAqfK6728",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#@title Local Features\n",
        "emo_count_local = False #@param {type:\"boolean\"}\n",
        "empathy_count_local = False #@param {type:\"boolean\"}\n",
        "distress_count_local = False #@param {type:\"boolean\"}\n",
        "\n",
        "local_features_names = []\n",
        "num_local_features = 0\n",
        "if emo_count_local:\n",
        "  local_features_names.append('emotions')\n",
        "  num_local_features += len(EMOTIONS_NAMES)\n",
        "if empathy_count_local:\n",
        "  local_features_names.append('empathy')\n",
        "  num_local_features += 1\n",
        "if distress_count_local:\n",
        "  local_features_names.append('distress')\n",
        "  num_local_features += 1\n",
        "\n",
        "if len(local_features_names) == 0: local_features_names = None\n",
        "\n",
        "config['emo_count_local'] = emo_count_local\n",
        "config['empathy_count_local'] = empathy_count_local\n",
        "config['distress_count_local'] = distress_count_local\n",
        "config['local_features_names'] = local_features_names\n",
        "\n",
        "dim_extra_features = 0\n",
        "if gold_emotions:\n",
        "  dim_extra_features = len(global_features_names) + 8\n",
        "else:\n",
        "  dim_extra_features = len(global_features_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "cellView": "form",
        "id": "EaTQUHDY6xHZ"
      },
      "outputs": [],
      "source": [
        "#@title Prompt\n",
        "bio_prompt = True #@param {type:\"boolean\"}\n",
        "bio_sep = 'after SEP' #@param [\"after SEP\", \"before SEP\"]\n",
        "emo_prompt = False #@param {type:\"boolean\"}\n",
        "emo_sep = 'before SEP' #@param [\"after SEP\", \"before SEP\"]\n",
        "empathy_prompt = False #@param {type:\"boolean\"}\n",
        "emp_sep = 'before SEP' #@param [\"after SEP\", \"before SEP\"]\n",
        "\n",
        "prompt_names_before_SEP = []\n",
        "prompt_names_after_SEP = []\n",
        "if bio_prompt:\n",
        "    if bio_sep=='before SEP':\n",
        "        prompt_names_before_SEP.append('prompt_bio')\n",
        "    else:\n",
        "        prompt_names_after_SEP.append('prompt_bio')\n",
        "if empathy_prompt:\n",
        "    if emp_sep=='before SEP':\n",
        "        prompt_names_before_SEP.append('prompt_emp')\n",
        "    else:\n",
        "        prompt_names_after_SEP.append('prompt_emp')\n",
        "if emo_prompt:\n",
        "    if emo_sep=='before SEP':\n",
        "        prompt_names_before_SEP.append('prompt_emo')\n",
        "    else:\n",
        "        prompt_names_after_SEP.append('prompt_emo')\n",
        "\n",
        "config['bio_prompt'] = bio_prompt\n",
        "config['emo_prompt'] = emo_prompt\n",
        "config['empathy_prompt'] = empathy_prompt\n",
        "config['prompt_names_before_SEP'] = prompt_names_before_SEP\n",
        "config['prompt_names_after_SEP'] = prompt_names_after_SEP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "cellView": "form",
        "id": "V361RpgifLr-"
      },
      "outputs": [],
      "source": [
        "#@title Last CLSs\n",
        "n_last_cls = 4 #@param {type:\"integer\"}\n",
        "mean_last_cls = False #@param {type: \"boolean\"}\n",
        "concat_local_features = False #@param {type: \"boolean\"}\n",
        "config['n_last_cls'] = n_last_cls\n",
        "config['mean_last_cls'] = mean_last_cls\n",
        "config['concat_local_features'] = concat_local_features\n",
        "\n",
        "if concat_local_features:\n",
        "  dim_extra_features += num_local_features\n",
        "\n",
        "config['dim_extra_features'] = dim_extra_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgMIYk-HyEbS"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "cellView": "form",
        "id": "SwMOxxRRg0Vh"
      },
      "outputs": [],
      "source": [
        "#@title Model configuration\n",
        "train_batch_size = 8 #@param {type:\"integer\"}\n",
        "val_batch_size = 8 #@param {type:\"integer\"}\n",
        "learning_rate = 5e-5 #@param {type:\"number\"}\n",
        "weight_decay = 0.08 #@param {type:\"number\"}\n",
        "epochs = 30 #@param {type:\"integer\"}\n",
        "patience = 5 #@param {type:\"integer\"}\n",
        "dropout = 0.3 #@param {type:\"number\"}\n",
        "weighted_loss = \"None\" #@param [\"None\", \"normalized_inverse\", \"balanced\"]\n",
        "\n",
        "model_type ={\n",
        "  'distilroberta-emotion':'j-hartmann/emotion-english-distilroberta-base',\n",
        "  'roberta-emotion':'j-hartmann/emotion-english-roberta-large',\n",
        "  'roberta-empathy': 'bdotloh/roberta-base-empathy',\n",
        "  'bert-base': 'bert-base-cased',\n",
        "  'roberta-base' : 'roberta-base'\n",
        "}\n",
        "\n",
        "model_config = {\n",
        "    'model_id': model_id,\n",
        "    'tokenizer_name': model_type.get(model_name),\n",
        "    'model_name': model_type.get(model_name),\n",
        "    'train_batch_size': train_batch_size,\n",
        "    'val_batch_size': val_batch_size,\n",
        "    'learning_rate': learning_rate,\n",
        "    'weight_decay': weight_decay,\n",
        "    'epochs': epochs,\n",
        "    'seed': 42,\n",
        "    'patience': patience,\n",
        "    'early_stopping_threshold': 0,\n",
        "    'weighted_loss': weighted_loss,\n",
        "    'dropout' : dropout\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.061536Z",
          "iopub.status.busy": "2023-07-11T19:10:06.061089Z",
          "iopub.status.idle": "2023-07-11T19:10:06.069916Z",
          "shell.execute_reply": "2023-07-11T19:10:06.069051Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.061505Z"
        },
        "id": "dA224FxADpqd",
        "outputId": "6d152f64-b51e-4c1e-b211-25cb9b3f0a38",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘EMO_distil-1cls’: File exists\n",
            "\n",
            "CONFIGURATION\n",
            "num_labels: 2\n",
            "model_id: distil-1cls\n",
            "model_class_string: RobertaPreTrainedModel\n",
            "model_name: j-hartmann/emotion-english-distilroberta-base\n",
            "emo_count_global: False\n",
            "empathy_count_global: False\n",
            "distress_count_global: False\n",
            "bio_global: True\n",
            "gold_emotions: False\n",
            "gold_empathy: True\n",
            "gold_distress: True\n",
            "global_features_names: ['gender', 'age', 'income', 'race', 'education', 'empathy', 'distress']\n",
            "emo_count_local: False\n",
            "empathy_count_local: False\n",
            "distress_count_local: False\n",
            "local_features_names: None\n",
            "bio_prompt: True\n",
            "emo_prompt: False\n",
            "empathy_prompt: False\n",
            "prompt_names_before_SEP: []\n",
            "prompt_names_after_SEP: ['prompt_bio']\n",
            "n_last_cls: 4\n",
            "mean_last_cls: False\n",
            "concat_local_features: False\n",
            "dim_extra_features: 7\n",
            "tokenizer_name: j-hartmann/emotion-english-distilroberta-base\n",
            "train_batch_size: 8\n",
            "val_batch_size: 8\n",
            "learning_rate: 5e-05\n",
            "weight_decay: 0.08\n",
            "epochs: 30\n",
            "seed: 42\n",
            "patience: 5\n",
            "early_stopping_threshold: 0\n",
            "weighted_loss: None\n",
            "dropout: 0.3\n"
          ]
        }
      ],
      "source": [
        "path_tosave = f\"{TASK}_{model_config['model_id']}\"\n",
        "!mkdir $path_tosave\n",
        "\n",
        "config.update(model_config)\n",
        "write_dict_to_json(config, f\"{path_tosave}/config.json\")\n",
        "\n",
        "print(\"\\nCONFIGURATION\")\n",
        "for k,v in config.items():\n",
        "  print(f\"{k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gsXzUtCBv-j"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIUOnGp-_6lV"
      },
      "source": [
        "### WASSA dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:06:52.410007Z",
          "iopub.status.busy": "2023-07-11T19:06:52.409372Z",
          "iopub.status.idle": "2023-07-11T19:06:52.429476Z",
          "shell.execute_reply": "2023-07-11T19:06:52.428716Z",
          "shell.execute_reply.started": "2023-07-11T19:06:52.409972Z"
        },
        "id": "WOuBgl-TmlM-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class WASSADataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer,\n",
        "        essay,\n",
        "        essay_id,\n",
        "        targets,\n",
        "        prompt_before_SEP=None,\n",
        "        prompt_after_SEP=None,\n",
        "        EMP_lexicon = None,\n",
        "        EMO_lexicon = None,\n",
        "        global_features = None,\n",
        "        local_emotions = False,\n",
        "        local_empathy = False,\n",
        "        local_distress = False,\n",
        "        max_len=None\n",
        "        ):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.essay = essay\n",
        "        self.essay_id = essay_id\n",
        "        self.targets = targets\n",
        "        self.EMP_lexicon = EMP_lexicon\n",
        "        self.EMO_lexicon = EMO_lexicon\n",
        "\n",
        "        self.prompt_before_SEP = prompt_before_SEP\n",
        "        self.prompt_after_SEP = prompt_after_SEP\n",
        "\n",
        "        self.global_features = global_features\n",
        "        self.local_emotions = local_emotions\n",
        "        self.local_empathy = local_empathy\n",
        "        self.local_distress = local_distress\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        essay = str(self.essay[index])\n",
        "\n",
        "        essay_id = self.essay_id[index]\n",
        "\n",
        "        prompt_before_SEP = \"\"\n",
        "        if self.prompt_before_SEP is not None:\n",
        "          for p in self.prompt_before_SEP[index]:\n",
        "            prompt_before_SEP += \" \" + str(p)\n",
        "\n",
        "        prompt_after_SEP = \"\"\n",
        "        if self.prompt_after_SEP is not None:\n",
        "          for p in self.prompt_after_SEP[index]:\n",
        "            prompt_after_SEP += \" \" + str(p)\n",
        "\n",
        "        text = essay\n",
        "        text_pair = None\n",
        "        if prompt_before_SEP != \"\":\n",
        "          text += str(prompt_before_SEP)\n",
        "        if prompt_after_SEP != \"\":\n",
        "          text_pair = str(prompt_after_SEP)\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text=essay,\n",
        "            text_pair=text_pair,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "          'input_ids': inputs['input_ids'].flatten(),\n",
        "          'attention_mask': inputs['attention_mask'].flatten(),\n",
        "          'token_type_ids': inputs[\"token_type_ids\"].flatten()\n",
        "        }\n",
        "\n",
        "        if self.targets is not None:\n",
        "          item['labels'] = torch.FloatTensor(self.targets[index])\n",
        "\n",
        "        if self.global_features is not None:\n",
        "          item['global_features'] = self.global_features[index]\n",
        "\n",
        "        n_local_features = 0\n",
        "        features_tokens_row = []\n",
        "        if self.local_emotions:\n",
        "            n_local_features += len(EMOTIONS_NAMES)\n",
        "            for i in range(len(EMOTIONS_NAMES)):\n",
        "                features_tokens_row.append(0)\n",
        "        if self.local_empathy:\n",
        "            n_local_features += 1\n",
        "            features_tokens_row.append(4)\n",
        "        if self.local_distress:\n",
        "            n_local_features += 1\n",
        "            features_tokens_row.append(0)\n",
        "\n",
        "        if n_local_features > 0:\n",
        "            features_tokens = np.full((self.tokenizer.model_max_length, n_local_features), features_tokens_row)\n",
        "        else:\n",
        "          features_tokens = None\n",
        "\n",
        "        word_count=0\n",
        "        first_char=True\n",
        "        last_char_is_space=False\n",
        "        for char_idx, char in enumerate(essay):\n",
        "          token_idx = inputs.char_to_token(char_idx)\n",
        "          if token_idx is None:\n",
        "            if first_char: last_char_is_space=True\n",
        "            if not last_char_is_space and not first_char:\n",
        "              word_count+=1\n",
        "              last_char_is_space=True\n",
        "            continue\n",
        "          elif last_char_is_space:\n",
        "            last_char_is_space=False\n",
        "          first_char=False\n",
        "\n",
        "          j = 0\n",
        "          if char not in string.punctuation:\n",
        "            if self.local_emotions:\n",
        "              for i, emo in enumerate(EMOTIONS_NAMES):\n",
        "                features_tokens[token_idx][i] = self.EMO_lexicon[str(essay_id)][emo][word_count]\n",
        "              j += len(EMOTIONS_NAMES)\n",
        "\n",
        "            if self.local_empathy:\n",
        "              features_tokens[token_idx][j] = self.EMP_lexicon[str(essay_id)]['empathy'][word_count]\n",
        "              j += 1\n",
        "\n",
        "\n",
        "            if self.local_distress:\n",
        "              features_tokens[token_idx][j] = self.EMP_lexicon[str(essay_id)]['distress'][word_count]\n",
        "\n",
        "        if features_tokens is not None:\n",
        "            item['local_features'] = torch.FloatTensor(features_tokens)\n",
        "\n",
        "        #item['return_dict']=True\n",
        "\n",
        "        return item"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFI6AulQsYci"
      },
      "source": [
        "Read dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:09:57.899510Z",
          "iopub.status.busy": "2023-07-11T19:09:57.899102Z",
          "iopub.status.idle": "2023-07-11T19:09:57.904814Z",
          "shell.execute_reply": "2023-07-11T19:09:57.903813Z",
          "shell.execute_reply.started": "2023-07-11T19:09:57.899476Z"
        },
        "id": "BjM03TscDwcz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"TRAIN_DATA = f\"{repo_path}{branch}/datasets/WASSA_essay_level_internal_train_preproc_upsampled.tsv\"\n",
        "VAL_DATA = f\"{repo_path}{branch}/datasets/WASSA_essay_level_internal_val_preproc.tsv\"\n",
        "DEV_DATA = f\"{repo_path}{branch}/datasets/WASSA_essay_level_dev_preproc.tsv\"\n",
        "\"\"\"\n",
        "if binary_EMO:\n",
        "    TRAIN_DATA = f\"{repo_path}{branch}/dataset_binary/WASSA23_essay_level_train_preproc_downsampled_{EMO_binary_emotion}.tsv\"\n",
        "    all_train_df = pd.read_csv(TRAIN_DATA, sep='\\t')\n",
        "    train_df, val_df = split_train_val(all_train_df, val_size=0.1)\n",
        "else:\n",
        "    TRAIN_DATA = f\"{repo_path}{branch}/datasets/WASSA23_essay_level_internal_train_preproc.tsv\"\n",
        "    VAL_DATA = f\"{repo_path}{branch}/datasets/WASSA23_essay_level_internal_val_preproc.tsv\"\n",
        "    train_df = pd.read_csv(TRAIN_DATA, sep='\\t')\n",
        "    val_df = pd.read_csv(VAL_DATA, sep='\\t')\n",
        "\n",
        "DEV_DATA = f\"{repo_path}{branch}/datasets/WASSA23_essay_level_dev_preproc.tsv\"\n",
        "dev_df = pd.read_csv(DEV_DATA, sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDJWlHhwsfwL"
      },
      "source": [
        "Encode targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:10:06.006808Z",
          "iopub.status.busy": "2023-07-11T19:10:06.006358Z",
          "iopub.status.idle": "2023-07-11T19:10:06.021824Z",
          "shell.execute_reply": "2023-07-11T19:10:06.020868Z",
          "shell.execute_reply.started": "2023-07-11T19:10:06.006776Z"
        },
        "id": "6LKqRnKdsJdu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if TASK ==\"EMO\":\n",
        "  label_encoder = EmotionsLabelEncoder()\n",
        "  label_encoder.fit(train_df.emotion)\n",
        "  y_train = label_encoder.encode(train_df.emotion)\n",
        "  y_val = label_encoder.encode(val_df.emotion)\n",
        "  y_dev = label_encoder.encode(dev_df.emotion)\n",
        "\n",
        "if TASK == \"EMP\":\n",
        "  y_train = np.array(train_df[['empathy', 'distress']])\n",
        "  y_val = np.array(val_df[['empathy', 'distress']])\n",
        "  y_dev = np.array(dev_df[['empathy', 'distress']])\n",
        "\n",
        "if binary_EMO:\n",
        "  y_train = np.array(train_df.emotion_dataset).reshape(-1, 1)\n",
        "  y_train_encoded = np.zeros((y_train.shape[0], 2))\n",
        "  for i in range(y_train.shape[0]):\n",
        "    if y_train[i]==0:\n",
        "      y_train_encoded[i][0] = 1\n",
        "      y_train_encoded[i][1] = 0\n",
        "    else:\n",
        "      y_train_encoded[i][0] = 0\n",
        "      y_train_encoded[i][1] = 1\n",
        "  y_train = y_train_encoded\n",
        "\n",
        "  y_val = np.array(val_df.emotion_dataset).reshape(-1, 1)\n",
        "  y_val_encoded = np.zeros((y_val.shape[0], 2))\n",
        "  for i in range(y_val.shape[0]):\n",
        "    if y_val[i]==0:\n",
        "      y_val_encoded[i][0] = 1\n",
        "      y_val_encoded[i][1] = 0\n",
        "    else:\n",
        "      y_val_encoded[i][0] = 0\n",
        "      y_val_encoded[i][1] = 1\n",
        "  y_val = y_val_encoded\n",
        "\n",
        "  y_dev_encoded = []\n",
        "  for emo in dev_df['emotion']:\n",
        "    if EMO_binary_emotion in emo:\n",
        "      y_dev_encoded.append([0.0,1.0])\n",
        "    else:\n",
        "      y_dev_encoded.append([1.0,0.0])\n",
        "  y_dev_encoded = np.array(y_dev_encoded)\n",
        "  y_dev = y_dev_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbCKVWh7-gpg"
      },
      "source": [
        "Extra global features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "7VpOAsXL6xHa"
      },
      "outputs": [],
      "source": [
        "global_features_train = None\n",
        "global_features_val = None\n",
        "global_features_dev = None\n",
        "\n",
        "if len(config.get('global_features_names')) > 0:\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(np.array(train_df[config.get('global_features_names')]))\n",
        "\n",
        "  def standard_scalar_features(features):\n",
        "    return scaler.transform(features)\n",
        "\n",
        "\n",
        "  global_features_train =  standard_scalar_features(np.array(train_df[config.get('global_features_names')]))\n",
        "  global_features_val =  standard_scalar_features(np.array(val_df[config.get('global_features_names')]))\n",
        "  global_features_dev =  standard_scalar_features(np.array(dev_df[config.get('global_features_names')]))\n",
        "\n",
        "  if TASK == \"EMP\":\n",
        "    label_encoder = EmotionsLabelEncoder()\n",
        "    label_encoder.fit(train_df.emotion)\n",
        "    gold_emotions_train = label_encoder.encode(train_df.emotion)\n",
        "    gold_emotions_val = label_encoder.encode(val_df.emotion)\n",
        "    gold_emotions_dev = label_encoder.encode(dev_df.emotion)\n",
        "    global_features_train = np.concatenate((global_features_train, gold_emotions_train), axis = 1)\n",
        "    global_features_val = np.concatenate((global_features_val, gold_emotions_val), axis = 1)\n",
        "    global_features_dev = np.concatenate((global_features_dev, gold_emotions_dev), axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfm0n2Mk6xHb"
      },
      "source": [
        "Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "5WnGSQwv6xHb"
      },
      "outputs": [],
      "source": [
        "prompt_before_SEP_train = None\n",
        "prompt_after_SEP_train = None\n",
        "prompt_before_SEP_val = None\n",
        "prompt_after_SEP_val = None\n",
        "prompt_before_SEP_dev = None\n",
        "prompt_after_SEP_dev = None\n",
        "\n",
        "if len(config.get('prompt_names_before_SEP')) > 0:\n",
        "  prompt_before_SEP_train = np.array(train_df[config.get('prompt_names_before_SEP')])\n",
        "  prompt_before_SEP_val = np.array(val_df[config.get('prompt_names_before_SEP')])\n",
        "  prompt_before_SEP_dev = np.array(dev_df[config.get('prompt_names_before_SEP')])\n",
        "\n",
        "if len(config.get('prompt_names_after_SEP')) > 0:\n",
        "  prompt_after_SEP_train = np.array(train_df[config.get('prompt_names_after_SEP')])\n",
        "  prompt_after_SEP_val = np.array(val_df[config.get('prompt_names_after_SEP')])\n",
        "  prompt_after_SEP_dev = np.array(dev_df[config.get('prompt_names_after_SEP')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwYXJId_-Sb5"
      },
      "source": [
        "Lexicons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:09.185627Z",
          "iopub.status.busy": "2023-07-11T19:11:09.185261Z",
          "iopub.status.idle": "2023-07-11T19:11:09.667265Z",
          "shell.execute_reply": "2023-07-11T19:11:09.666254Z",
          "shell.execute_reply.started": "2023-07-11T19:11:09.185595Z"
        },
        "id": "Qg0D38kk-Rrv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "EMO_lexicon_train_dict = None\n",
        "EMP_lexicon_train_dict = None\n",
        "EMO_lexicon_dev_dict = None\n",
        "EMP_lexicon_dev_dict = None\n",
        "EMO_lexicon_test_dict = None\n",
        "EMP_lexicon_test_dict = None\n",
        "if config.get('local_features_names') is not None:\n",
        "  if 'emotions' in config.get('local_features_names'):\n",
        "    with open(\"/content/EMO23_lexicon_per_word_.json\") as json_file:\n",
        "      EMO_lexicon_train_dict = json.load(json_file)\n",
        "    with open(\"/content/EMO23_lexicon_per_word_test.json\") as json_file:\n",
        "      EMO_lexicon_test_dict = json.load(json_file)\n",
        "\n",
        "  if 'empathy' in config.get('local_features_names') or 'distress' in config.get('local_features_names'):\n",
        "    with open(\"/content/EMP23_lexicon_per_word_.json\") as json_file:\n",
        "      EMP_lexicon_train_dict = json.load(json_file)\n",
        "    with open(\"/content/EMP23_lexicon_per_word_test.json\") as json_file:\n",
        "      EMP_lexicon_test_dict = json.load(json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXIimY5ABmlc"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:17.243014Z",
          "iopub.status.busy": "2023-07-11T19:11:17.241592Z",
          "iopub.status.idle": "2023-07-11T19:11:17.253391Z",
          "shell.execute_reply": "2023-07-11T19:11:17.252383Z",
          "shell.execute_reply.started": "2023-07-11T19:11:17.242979Z"
        },
        "id": "hfwVaaj-0qDq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_loss_weights(y, method):\n",
        "  if method == 'balanced':\n",
        "    weights_train = y.shape[0] / (y.shape[1] * np.sum(y, axis=0))\n",
        "  else:\n",
        "    inverse_n_samples = 1 / np.sum(y, axis=0)\n",
        "    sum_inverses = sum(inverse_n_samples)\n",
        "    weights_train = inverse_n_samples / sum_inverses\n",
        "  return torch.cuda.FloatTensor(weights_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:17.257384Z",
          "iopub.status.busy": "2023-07-11T19:11:17.255861Z",
          "iopub.status.idle": "2023-07-11T19:11:22.360433Z",
          "shell.execute_reply": "2023-07-11T19:11:22.359379Z",
          "shell.execute_reply.started": "2023-07-11T19:11:17.257351Z"
        },
        "id": "wVh3_jCFzmK7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "loss_weights_train = None\n",
        "if model_config.get('weighted_loss')!='None':\n",
        "  loss_weights_train = get_loss_weights(y_train, model_config.get('weighted_loss'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6aAhPift1UL"
      },
      "source": [
        "### Custom model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:23.702374Z",
          "iopub.status.busy": "2023-07-11T19:11:23.702059Z",
          "iopub.status.idle": "2023-07-11T19:11:23.732141Z",
          "shell.execute_reply": "2023-07-11T19:11:23.730692Z",
          "shell.execute_reply.started": "2023-07-11T19:11:23.702348Z"
        },
        "id": "2Vj3W-oUhBMZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    #Head for sentence-level classification tasks.\n",
        "\n",
        "    def __init__(self, config, dim_extra_features, hidden_layers_to_concat, classifier_dropout, local_features, mean_last_cls):\n",
        "        super().__init__()\n",
        "        self.local_features = local_features\n",
        "\n",
        "        if mean_last_cls:\n",
        "          total_dims = config.hidden_size + dim_extra_features\n",
        "        else:\n",
        "          total_dims = config.hidden_size*hidden_layers_to_concat + dim_extra_features\n",
        "        if self.local_features:\n",
        "          total_dims += config.hidden_size\n",
        "        self.dense = nn.Linear(total_dims, total_dims)\n",
        "        self.dropout = nn.Dropout(classifier_dropout)\n",
        "        self.out_proj = nn.Linear(total_dims, config.num_labels)\n",
        "\n",
        "    def forward(self, features, **kwargs):\n",
        "        features = features.to(torch.float32) # by default float32 is used as the dtype\n",
        "        x = self.dense(features)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.out_proj(x)\n",
        "        return x\n",
        "\n",
        "class CustomSequenceClassification(model_class):\n",
        "\n",
        "    def __init__(self, config, dim_extra_features=0, model_class = None, local_features_names=None, loss_weights=None, n_last_cls = 1, mean_last_cls = False, concat_local_features = False):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.config = config\n",
        "        self.local_features_names = local_features_names\n",
        "        self.loss_weights = loss_weights\n",
        "        self.n_last_cls = n_last_cls\n",
        "        self.mean_last_cls = mean_last_cls\n",
        "        self.concat_local_features = concat_local_features\n",
        "        self.model_class = model_class\n",
        "        if self.model_class == \"BertPreTrainedModel\":\n",
        "          self.bert = BertModel(config)\n",
        "\n",
        "        if self.model_class == \"RobertaPreTrainedModel\":\n",
        "          self.roberta = RobertaModel(config)\n",
        "\n",
        "        classifier_dropout = (\n",
        "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
        "        )\n",
        "        self.dropout = nn.Dropout(classifier_dropout)\n",
        "        self.classifier = ClassificationHead(config,\n",
        "                                            dim_extra_features,\n",
        "                                            n_last_cls,\n",
        "                                            classifier_dropout,\n",
        "                                            local_features_names is not None,\n",
        "                                            mean_last_cls)\n",
        "        self.post_init()\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.LongTensor] = None,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        local_features = None,\n",
        "        global_features = None,\n",
        "        token_type_ids: Optional[torch.LongTensor] = None,\n",
        "        position_ids: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = True,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
        "\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if self.model_class == \"BertPreTrainedModel\":\n",
        "          outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        if self.model_class == \"RobertaPreTrainedModel\":\n",
        "          outputs = self.roberta(\n",
        "              input_ids,\n",
        "              attention_mask=attention_mask,\n",
        "              token_type_ids=token_type_ids,\n",
        "              position_ids=position_ids,\n",
        "              head_mask=head_mask,\n",
        "              inputs_embeds=inputs_embeds,\n",
        "              output_attentions=output_attentions,\n",
        "              output_hidden_states=output_hidden_states,\n",
        "              return_dict=return_dict,\n",
        "          )\n",
        "\n",
        "        cls_tokens = []\n",
        "        for i in range(1, self.n_last_cls + 1):\n",
        "            cls_tokens.append(outputs.hidden_states[-1 * i][:, 0, :])\n",
        "        if self.mean_last_cls:\n",
        "          # average cls tokens\n",
        "          output = torch.mean(torch.stack(cls_tokens), dim=0)\n",
        "        else:\n",
        "          # concat cls tokens\n",
        "          output = torch.cat(cls_tokens, dim=1)\n",
        "\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        if local_features is not None:\n",
        "          tokens_output = outputs.last_hidden_state\n",
        "          tokens_output = self.dropout(tokens_output)\n",
        "\n",
        "          if self.concat_local_features:\n",
        "            tokens_output = torch.cat((\n",
        "                    tokens_output,\n",
        "                    local_features.reshape(outputs.last_hidden_state.shape[0], outputs.last_hidden_state.shape[1], -1)),\n",
        "                              dim=2)\n",
        "\n",
        "          mask = torch.zeros_like(attention_mask)\n",
        "          # unmask tokens with high or low empathy, high distress levels, or expressing at least one emotion\n",
        "          j = 0\n",
        "          if 'emotions' in self.local_features_names:\n",
        "            emotion_values = local_features[:,:,:11]\n",
        "            mask[emotion_values.sum(dim=-1)>=1] = 1.0\n",
        "            j += 11\n",
        "\n",
        "          if 'empathy' in self.local_features_names:\n",
        "            empathy_values = local_features[:,:,j]\n",
        "            mask[(empathy_values>5) | ((empathy_values<3) & (empathy_values>=1))] = 1.0\n",
        "            j += 1\n",
        "\n",
        "          if 'distress' in self.local_features_names:\n",
        "            distress_values = local_features[:,:,j]\n",
        "            mask[distress_values>4] = 1.0\n",
        "\n",
        "          # mean pooling of unmasked tokens\n",
        "          input_mask_expanded = mask.unsqueeze(-1).expand(tokens_output.size()).float()\n",
        "          sum_embeddings = torch.sum(tokens_output * input_mask_expanded, 1)\n",
        "          sum_mask = input_mask_expanded.sum(1)\n",
        "          sum_mask = torch.clamp(sum_mask, min = 1e-9)\n",
        "          tokens_output = sum_embeddings/sum_mask\n",
        "\n",
        "          # concat pooled tokens lexically relevant with cls token\n",
        "          output = torch.cat((output, tokens_output), dim=-1)\n",
        "\n",
        "\n",
        "        if global_features is not None: # global\n",
        "          output = torch.cat((output, global_features), dim=-1)\n",
        "\n",
        "        logits = self.classifier(output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.config.problem_type is None:\n",
        "                if self.num_labels == 1:\n",
        "                    self.config.problem_type = \"regression\"\n",
        "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
        "                    self.config.problem_type = \"single_label_classification\"\n",
        "                else:\n",
        "                    self.config.problem_type = \"multi_label_classification\"\n",
        "\n",
        "            if self.config.problem_type == \"regression\":\n",
        "                loss_fct = nn.MSELoss()\n",
        "                if self.num_labels == 1:\n",
        "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
        "                else:\n",
        "                    loss = loss_fct(logits, labels)\n",
        "            elif self.config.problem_type == \"single_label_classification\":\n",
        "                loss_fct = nn.CrossEntropyLoss(weight = self.loss_weights)\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            elif self.config.problem_type == \"multi_label_classification\":\n",
        "                loss_fct = nn.BCEWithLogitsLoss(weight = self.loss_weights)\n",
        "                loss = loss_fct(logits, labels)\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryDataset(Dataset):\n",
        "\n",
        "\n",
        "  def __init__(\n",
        "  self,\n",
        "  tokenizer,\n",
        "  essay,\n",
        "  targets,\n",
        "  max_len=None\n",
        "  ):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "    self.essay = essay\n",
        "    self.targets = targets\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    essay = str(self.essay[index])\n",
        "\n",
        "\n",
        "    inputs = self.tokenizer.encode_plus(\n",
        "    text=essay,\n",
        "    add_special_tokens=True,\n",
        "    max_length=self.max_len,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt',\n",
        "    return_token_type_ids=True\n",
        "    )\n",
        "\n",
        "\n",
        "    item = {\n",
        "    'input_ids': inputs['input_ids'].flatten(),\n",
        "    'attention_mask': inputs['attention_mask'].flatten(),\n",
        "    'token_type_ids': inputs[\"token_type_ids\"].flatten()\n",
        "    }\n",
        "\n",
        "    if self.targets is not None:\n",
        "      item['labels'] = torch.FloatTensor(self.targets[index])\n",
        "\n",
        "\n",
        "    return item"
      ],
      "metadata": {
        "id": "RLvG99jbk3iB"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:22.362620Z",
          "iopub.status.busy": "2023-07-11T19:11:22.361776Z",
          "iopub.status.idle": "2023-07-11T19:11:23.697235Z",
          "shell.execute_reply": "2023-07-11T19:11:23.696230Z",
          "shell.execute_reply.started": "2023-07-11T19:11:22.362585Z"
        },
        "id": "wd7W2HhYsbai",
        "outputId": "474414d9-837e-4d2b-92c3-58f3aa7d67b2",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaTokenizerFast(name_or_path='j-hartmann/emotion-english-distilroberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)}, clean_up_tokenization_spaces=True)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(config.get('tokenizer_name'), truncation=True)\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:23.734900Z",
          "iopub.status.busy": "2023-07-11T19:11:23.734558Z",
          "iopub.status.idle": "2023-07-11T19:11:27.562951Z",
          "shell.execute_reply": "2023-07-11T19:11:27.562030Z",
          "shell.execute_reply.started": "2023-07-11T19:11:23.734871Z"
        },
        "id": "GvJbF80XhSDE",
        "outputId": "776513b7-07e4-4731-9e3c-723c39bfd50a",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at j-hartmann/emotion-english-distilroberta-base and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([7, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([7]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ],
      "source": [
        "if TASK == \"EMO\":\n",
        "  problem_type = \"multi_label_classification\"\n",
        "if TASK == \"EMP\":\n",
        "  problem_type = \"regression\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "  config.get('model_name'),\n",
        "  problem_type = \"multi_label_classification\",\n",
        "  num_labels = config.get('num_labels'),\n",
        "  classifier_dropout = config.get('dropout'),\n",
        "  ignore_mismatched_sizes=True)\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xvHbhOhhttG"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY0SLN6usjYs"
      },
      "source": [
        "Prepare datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.565429Z",
          "iopub.status.busy": "2023-07-11T19:11:27.564800Z",
          "iopub.status.idle": "2023-07-11T19:11:27.572683Z",
          "shell.execute_reply": "2023-07-11T19:11:27.571493Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.565394Z"
        },
        "id": "DUIqO6AiZ8al",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_set = BinaryDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    essay=train_df.essay,\n",
        "    targets = y_train)\n",
        "\n",
        "val_set = BinaryDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    essay=val_df.essay,\n",
        "    targets = y_val)\n",
        "\n",
        "dev_set = BinaryDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    essay=dev_df.essay,\n",
        "    targets = y_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvduRx8HsteS"
      },
      "source": [
        "Set up training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "ba9vfO44N58k"
      },
      "outputs": [],
      "source": [
        "if TASK == \"EMO\":\n",
        "  metric_for_val = \"eval_macro_f1\"\n",
        "  compute_metrics_trainer = compute_EMO_metrics_trainer\n",
        "if TASK == \"EMP\":\n",
        "  metric_for_val = \"eval_avg_pearson\"\n",
        "  compute_metrics_trainer = compute_EMP_metrics_trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.574736Z",
          "iopub.status.busy": "2023-07-11T19:11:27.574061Z",
          "iopub.status.idle": "2023-07-11T19:11:27.586314Z",
          "shell.execute_reply": "2023-07-11T19:11:27.585303Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.574702Z"
        },
        "id": "Z1DbZxhkD1R7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_arguments = TrainingArguments(\n",
        "    output_dir=f\"./{config.get('model_name')}\",\n",
        "    per_device_train_batch_size = config.get('train_batch_size'),\n",
        "    per_device_eval_batch_size = config.get('val_batch_size'),\n",
        "    num_train_epochs = config.get('epochs'),\n",
        "    evaluation_strategy = \"steps\",\n",
        "    save_strategy = \"steps\",\n",
        "    logging_strategy = \"steps\",\n",
        "    logging_steps = 150,\n",
        "    eval_steps = 150,\n",
        "    save_steps = 150,\n",
        "    learning_rate=config.get('learning_rate'),\n",
        "    weight_decay=config.get('weight_decay'),\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = \"eval_loss\",\n",
        "    seed=config.get('seed'),\n",
        ") # TODO: custom other params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.588557Z",
          "iopub.status.busy": "2023-07-11T19:11:27.587598Z",
          "iopub.status.idle": "2023-07-11T19:11:27.726922Z",
          "shell.execute_reply": "2023-07-11T19:11:27.725911Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.588523Z"
        },
        "id": "hrI2rj4U3K2Q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=train_arguments,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=val_set,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics_trainer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-sruHQdsraI"
      },
      "source": [
        "Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.731325Z",
          "iopub.status.busy": "2023-07-11T19:11:27.731059Z",
          "iopub.status.idle": "2023-07-11T19:11:27.738285Z",
          "shell.execute_reply": "2023-07-11T19:11:27.737157Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.731302Z"
        },
        "id": "4kUY7tU3sqr3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class TrainerLoggingCallback(TrainerCallback):\n",
        "    def __init__(self, log_path):\n",
        "        self.log_path = log_path\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        _ = logs.pop(\"total_flos\", None)\n",
        "        if state.is_local_process_zero: # whether this process is the main one in a distributed setting\n",
        "            with open(self.log_path, \"a\") as f:\n",
        "                f.write(json.dumps(logs) + \"\\n\")\n",
        "\n",
        "trainer.add_callback(EarlyStoppingCallback(\n",
        "    early_stopping_patience = config.get('patience'),\n",
        "    early_stopping_threshold = config.get('early_stopping_threshold')))\n",
        "\n",
        "trainer.add_callback(TrainerLoggingCallback(config.get('model_id')+\"_log.json\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcCqSooFsw0X"
      },
      "source": [
        "Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "execution": {
          "iopub.execute_input": "2023-07-11T19:11:27.740439Z",
          "iopub.status.busy": "2023-07-11T19:11:27.740100Z",
          "iopub.status.idle": "2023-07-11T19:20:18.229718Z",
          "shell.execute_reply": "2023-07-11T19:20:18.228678Z",
          "shell.execute_reply.started": "2023-07-11T19:11:27.740408Z"
        },
        "id": "L8xAPa81D5tu",
        "outputId": "197115ae-8ca2-43b5-a9a6-acd0bf8ae04e",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='151' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 151/1800 00:55 < 10:12, 2.69 it/s, Epoch 2.50/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Jaccard</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Sklearn Accuracy</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.399400</td>\n",
              "      <td>0.656792</td>\n",
              "      <td>0.834957</td>\n",
              "      <td>0.836066</td>\n",
              "      <td>0.718310</td>\n",
              "      <td>0.837691</td>\n",
              "      <td>0.834052</td>\n",
              "      <td>0.836066</td>\n",
              "      <td>0.836066</td>\n",
              "      <td>0.836066</td>\n",
              "      <td>0.836066</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:20:18.263809Z",
          "iopub.status.busy": "2023-07-11T19:20:18.263461Z",
          "iopub.status.idle": "2023-07-11T19:20:18.274394Z",
          "shell.execute_reply": "2023-07-11T19:20:18.272774Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.263776Z"
        },
        "id": "Dd-3octehTlH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Access the training logs\n",
        "train_logs = trainer.state.log_history\n",
        "\n",
        "metrics = [list(log.keys())[:-5] for log in train_logs if log.get('eval_loss') is not None][0]\n",
        "\n",
        "train_loss_values = []\n",
        "eval_loss_values = []\n",
        "eval_metrics_values = []\n",
        "for _ in metrics:\n",
        "  eval_metrics_values.append([])\n",
        "train_epochs = []\n",
        "eval_epochs = []\n",
        "\n",
        "best_metric = 0\n",
        "best_train_loss = float('inf')\n",
        "best_eval_loss = float('inf')\n",
        "\n",
        "for log in train_logs:\n",
        "\n",
        "  if log.get(metric_for_val) is not None:\n",
        "\n",
        "    if log.get(metric_for_val) > best_metric:\n",
        "      best_metric = log.get(metric_for_val)\n",
        "      best_steps = log.get('step')\n",
        "      best_epoch_metric = log.get('epoch')\n",
        "    if log.get('eval_loss') < best_eval_loss:\n",
        "      best_eval_loss = log.get('eval_loss')\n",
        "      best_epoch_eval_loss = log.get('epoch')\n",
        "\n",
        "    for i, metric in enumerate(metrics):\n",
        "      eval_metrics_values[i].append(log.get(metric))\n",
        "\n",
        "    eval_loss_values.append(log.get('eval_loss'))\n",
        "    eval_epochs.append(log.get('epoch'))\n",
        "\n",
        "  if log.get('loss') is not None:\n",
        "    if log.get('loss') < best_train_loss:\n",
        "      best_train_loss = log.get('loss')\n",
        "\n",
        "    train_loss_values.append(log.get('loss'))\n",
        "    train_epochs.append(log.get('epoch'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V5eavAamxKr"
      },
      "source": [
        "Plot losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:20:18.303708Z",
          "iopub.status.busy": "2023-07-11T19:20:18.303144Z",
          "iopub.status.idle": "2023-07-11T19:20:18.378460Z",
          "shell.execute_reply": "2023-07-11T19:20:18.376257Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.303655Z"
        },
        "id": "ECEu3ajRl6k3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "fig_name = \"losses\"\n",
        "plot_metric_curve(\n",
        "    values = [train_loss_values, eval_loss_values],\n",
        "    epochs = [train_epochs, eval_epochs],\n",
        "    metrics = [\"train loss\", \"eval loss\"],\n",
        "    title = fig_name,\n",
        "    path = f\"{path_tosave}/{fig_name}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms0inN8amz33"
      },
      "source": [
        "Plot metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgGrIimdm3si"
      },
      "outputs": [],
      "source": [
        "fig_name = \"metrics\"\n",
        "plot_metric_curve(\n",
        "    values = eval_metrics_values[1:],\n",
        "    epochs = [eval_epochs for _ in eval_metrics_values[1:]],\n",
        "    metrics = metrics[1:],\n",
        "    title = fig_name,\n",
        "    path = f\"{path_tosave}/{fig_name}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc5stfSah0Kj"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-11T19:32:52.626228Z",
          "iopub.status.busy": "2023-07-11T19:32:52.625699Z",
          "iopub.status.idle": "2023-07-11T19:32:52.641902Z",
          "shell.execute_reply": "2023-07-11T19:32:52.638400Z",
          "shell.execute_reply.started": "2023-07-11T19:32:52.626186Z"
        },
        "id": "19G80dVoH3HZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def predict_emotions(results, gold_emotions):\n",
        "\n",
        "  binarized_predictions = np.where(results >= 0.5, 1, 0)\n",
        "\n",
        "  for i, bin_pred in enumerate(binarized_predictions):\n",
        "    if np.all(bin_pred==0):\n",
        "      binarized_predictions[i][np.argmax(results[i])] = 1\n",
        "\n",
        "  predicted_emotions = label_encoder.decode(binarized_predictions)\n",
        "  return predicted_emotions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WIAU6a7Mox4"
      },
      "outputs": [],
      "source": [
        "print(trainer.state.best_model_checkpoint)\n",
        "\n",
        "outs = trainer.predict(dev_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXgFzu32_RBo"
      },
      "outputs": [],
      "source": [
        "if binary_EMO:\n",
        "  predictions = np.argmax(outs.predictions, axis=1)\n",
        "  predictions = np.where(predictions==0, f'no-{EMO_binary_emotion}', EMO_binary_emotion)\n",
        "  golds = np.argmax(outs.label_ids, axis=1)\n",
        "  golds = np.where(golds==0, f'no-{EMO_binary_emotion}', EMO_binary_emotion)\n",
        "elif TASK == \"EMO\":\n",
        "  golds = label_encoder.decode(outs.label_ids)\n",
        "  predictions = predict_emotions(outs.predictions, golds)\n",
        "if TASK == \"EMP\":\n",
        "  golds = outs.label_ids\n",
        "  predictions = outs.predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T19:20:18.388286Z",
          "iopub.status.idle": "2023-07-11T19:20:18.389135Z",
          "shell.execute_reply": "2023-07-11T19:20:18.388900Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.388873Z"
        },
        "id": "Im2VGnmQs7bY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "path_predictions = f\"{path_tosave}/predictions_{TASK}.tsv\"\n",
        "path_metrics = f\"{path_tosave}/dev_metrics_{TASK}.json\"\n",
        "\n",
        "scores = {\n",
        "    'train_loss': float(best_train_loss),\n",
        "    'eval_loss': float(best_eval_loss)\n",
        "}\n",
        "\n",
        "write_predictions(predictions, path_predictions)\n",
        "challenge_metrics = compute_metrics(golds=golds, predictions=predictions, task=TASK)\n",
        "scores.update(challenge_metrics)\n",
        "scores['best_metric'] = float(best_metric)\n",
        "scores['best_epoch_metric'] = float(best_epoch_metric)\n",
        "scores['best_epoch_eval_loss'] =  float(best_epoch_eval_loss)\n",
        "\n",
        "write_dict_to_json(scores, path_metrics)\n",
        "\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T19:20:18.390758Z",
          "iopub.status.idle": "2023-07-11T19:20:18.391292Z",
          "shell.execute_reply": "2023-07-11T19:20:18.391058Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.391035Z"
        },
        "id": "ITunC36XXLoN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if TASK == \"EMO\":\n",
        "  fig_name = \"confusion_matrix\"\n",
        "  plot_confusion_matrix(golds=golds,\n",
        "                        predictions=predictions,\n",
        "                        path= f\"{path_tosave}/{fig_name}.png\"\n",
        "                        )\n",
        "  print(\"\\n\")\n",
        "  fig_name = \"confusion_matrix_per_emotions\"\n",
        "  plot_confusion_matrix_per_emotions(gold_emotions = golds,\n",
        "                                     predicted_emotions = predictions,\n",
        "                                     path= f\"{path_tosave}/{fig_name}.png\"\n",
        "                                     )\n",
        "\n",
        "if TASK == \"EMP\":\n",
        "  fig_name = f\"empathy_true_vs_predicted\"\n",
        "  plot_true_vs_predicted(golds = golds[:,0],\n",
        "                        predictions = predictions[:,0],\n",
        "                        path= f\"{path_tosave}/{fig_name}.png\"\n",
        "                        )\n",
        "  print(\"\\n\")\n",
        "  fig_name = f\"distress_true_vs_predicted\"\n",
        "  plot_true_vs_predicted(golds = golds[:,1],\n",
        "                        predictions = predictions[:,1],\n",
        "                        path= f\"{path_tosave}/{fig_name}.png\"\n",
        "                        )\n",
        "  print(\"\\n\")\n",
        "  fig_name = f\"abs_diff_true_vs_predicted\"\n",
        "  plot_abs_diff_emp(golds = golds,\n",
        "                        predictions = predictions,\n",
        "                        path= f\"{path_tosave}/{fig_name}.png\"\n",
        "                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pkHv9w4tM1F"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1u9D1Z2R_Jc"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint_and_compute_metrics(checkpoint_path, test_set):\n",
        "\n",
        "  model = CustomSequenceClassification.from_pretrained(checkpoint_path,\n",
        "                                                     problem_type = problem_type,\n",
        "                                                     classifier_dropout = config.get('dropout'),\n",
        "                                                     model_class = config.get('model_class_string'),\n",
        "                                                     num_labels=config.get('num_labels'),\n",
        "                                                     dim_extra_features = config.get('dim_extra_features'),\n",
        "                                                     local_features_names = config.get('local_features_names'),\n",
        "                                                     n_last_cls = config.get('n_last_cls'),\n",
        "                                                     mean_last_cls = config.get('mean_last_cls'),\n",
        "                                                     concat_local_features = config.get('concat_local_features'),\n",
        "                                                     loss_weights = loss_weights_train,\n",
        "                                                     ignore_mismatched_sizes=True\n",
        "                                                    )\n",
        "  trainer = Trainer(model=model)\n",
        "  # Perform prediction using the loaded checkpoint\n",
        "  outs = trainer.predict(test_set)\n",
        "\n",
        "  if TASK == \"EMO\":\n",
        "    golds = label_encoder.decode(outs.label_ids)\n",
        "    predictions = predict_emotions(outs.predictions[0], golds)\n",
        "  if TASK == \"EMP\":\n",
        "    golds = outs.label_ids\n",
        "    predictions = outs.predictions[0]\n",
        "\n",
        "  path_predictions = f\"{path_tosave}/predictions_{TASK}_best_metric.tsv\"\n",
        "  path_metrics = f\"{path_tosave}/dev_metrics_{TASK}_best_metric.json\"\n",
        "\n",
        "  write_predictions(predictions, path_predictions)\n",
        "  challenge_metrics = compute_metrics(golds=golds, predictions=predictions, task=TASK)\n",
        "\n",
        "  write_dict_to_json(challenge_metrics, path_metrics)\n",
        "\n",
        "  print(challenge_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC88bo8dSSsr"
      },
      "outputs": [],
      "source": [
        "best_metric_path = f\"/content/{config.get('model_name')}/checkpoint-{best_steps}\"\n",
        "load_checkpoint_and_compute_metrics(best_metric_path, dev_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DuCaju6tSHB"
      },
      "source": [
        "## Save on Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WxgVCLCUSN8"
      },
      "outputs": [],
      "source": [
        "# move the best checkpoint in the folder with model id\n",
        "best_model_path = trainer.state.best_model_checkpoint\n",
        "\n",
        "!mv $best_model_path /content/$path_tosave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Q_AjZEVUSN8"
      },
      "outputs": [],
      "source": [
        "# move the checkpoint with best metric in the folder with model id\n",
        "!mv $best_metric_path /content/$path_tosave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-11T19:20:18.405534Z",
          "iopub.status.idle": "2023-07-11T19:20:18.406365Z",
          "shell.execute_reply": "2023-07-11T19:20:18.406135Z",
          "shell.execute_reply.started": "2023-07-11T19:20:18.406111Z"
        },
        "id": "b1KcxQQ0uUl6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# move the results to personal drive\n",
        "!mv /content/$path_tosave /content/drive/MyDrive/hlt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}