{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>empathy</th>\n",
       "      <th>distress</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>personality_agreeableness</th>\n",
       "      <th>personality_stability</th>\n",
       "      <th>iri_perspective_taking</th>\n",
       "      <th>iri_personal_distress</th>\n",
       "      <th>iri_fantasy</th>\n",
       "      <th>iri_empathatic_concern</th>\n",
       "      <th>speaker_number</th>\n",
       "      <th>split</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>It breaks my heart to see people living in tho...</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>6.625</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.429</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>Hope/Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>I wonder why there aren't more people trying t...</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>6.000</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.429</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.714</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>After reading the article, you can't help but ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.375</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>6.75</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.643</td>\n",
       "      <td>2.0715</td>\n",
       "      <td>4.143</td>\n",
       "      <td>4.643</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>213</td>\n",
       "      <td>It is so sad that someone who had such an amaz...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>6.625</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.143</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>213</td>\n",
       "      <td>From reading the article, it looks like the wo...</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.429</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>7</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>495</td>\n",
       "      <td>218</td>\n",
       "      <td>I feel that this will become a national proble...</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>6.750</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.429</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>994</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>496</td>\n",
       "      <td>103</td>\n",
       "      <td>The whole situation is sketchy. The wavering r...</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>6.375</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.143</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>995</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>498</td>\n",
       "      <td>103</td>\n",
       "      <td>The death of a former aide to Russian Presiden...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.286</td>\n",
       "      <td>1.286</td>\n",
       "      <td>3.857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>997</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>499</td>\n",
       "      <td>103</td>\n",
       "      <td>Everything about Russia really freaks me out. ...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.286</td>\n",
       "      <td>3.571</td>\n",
       "      <td>3.714</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>998</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>500</td>\n",
       "      <td>103</td>\n",
       "      <td>Whenever Russia and Putin are involved  I do n...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.875</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.429</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>999</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     conversation_id  article_id  \\\n",
       "0                  2          35   \n",
       "1                  3          35   \n",
       "2                  5          35   \n",
       "3                  6         213   \n",
       "4                  8         213   \n",
       "..               ...         ...   \n",
       "787              495         218   \n",
       "788              496         103   \n",
       "789              498         103   \n",
       "790              499         103   \n",
       "791              500         103   \n",
       "\n",
       "                                                 essay   empathy  distress  \\\n",
       "0    It breaks my heart to see people living in tho...  6.833333     6.625   \n",
       "1    I wonder why there aren't more people trying t...  5.833333     6.000   \n",
       "2    After reading the article, you can't help but ...  1.000000     1.375   \n",
       "3    It is so sad that someone who had such an amaz...  6.166667     6.625   \n",
       "4    From reading the article, it looks like the wo...  6.833333     1.000   \n",
       "..                                                 ...       ...       ...   \n",
       "787  I feel that this will become a national proble...  6.500000     6.750   \n",
       "788  The whole situation is sketchy. The wavering r...  3.166667     6.375   \n",
       "789  The death of a former aide to Russian Presiden...  6.000000     2.000   \n",
       "790  Everything about Russia really freaks me out. ...  6.000000     6.000   \n",
       "791  Whenever Russia and Putin are involved  I do n...  1.500000     4.875   \n",
       "\n",
       "     speaker_id gender education race age  ... personality_agreeableness  \\\n",
       "0            30      1         6    3  37  ...                       6.5   \n",
       "1            19      1         6    2  32  ...                       5.5   \n",
       "2            17      1         6    1  29  ...                      6.75   \n",
       "3            16      2         5    1  28  ...                       4.5   \n",
       "4            30      1         6    3  37  ...                       6.5   \n",
       "..          ...    ...       ...  ...  ..  ...                       ...   \n",
       "787          30      1         6    3  37  ...                       6.5   \n",
       "788          16      2         5    1  28  ...                       4.5   \n",
       "789          43      2         6    1  33  ...                       7.0   \n",
       "790          53      2         3    1  27  ...                       6.0   \n",
       "791          30      1         6    3  37  ...                       6.5   \n",
       "\n",
       "    personality_stability iri_perspective_taking iri_personal_distress  \\\n",
       "0                     6.0                  4.857                   2.0   \n",
       "1                     4.5                  3.429                 2.857   \n",
       "2                     7.0                  4.643                2.0715   \n",
       "3                     3.5                    5.0                 4.143   \n",
       "4                     6.0                  4.857                   2.0   \n",
       "..                    ...                    ...                   ...   \n",
       "787                   6.0                  4.857                   2.0   \n",
       "788                   3.5                    5.0                 4.143   \n",
       "789                   7.0                  4.286                 1.286   \n",
       "790                   6.0                    4.0                 2.286   \n",
       "791                   6.0                  4.857                   2.0   \n",
       "\n",
       "    iri_fantasy iri_empathatic_concern speaker_number  split essay_id  \\\n",
       "0         3.429                    5.0              1  train        1   \n",
       "1         2.857                  2.714              1  train        2   \n",
       "2         4.143                  4.643              1  train        4   \n",
       "3         4.857                    5.0              1  train        5   \n",
       "4         3.429                    5.0              1  train        7   \n",
       "..          ...                    ...            ...    ...      ...   \n",
       "787       3.429                    5.0              2  train      994   \n",
       "788       4.857                    5.0              2  train      995   \n",
       "789       3.857                    4.0              2  train      997   \n",
       "790       3.571                  3.714              2  train      998   \n",
       "791       3.429                    5.0              2  train      999   \n",
       "\n",
       "          emotion  \n",
       "0    Hope/Sadness  \n",
       "1           Anger  \n",
       "2         Sadness  \n",
       "3         Sadness  \n",
       "4         Neutral  \n",
       "..            ...  \n",
       "787       Neutral  \n",
       "788       Neutral  \n",
       "789       Neutral  \n",
       "790          Fear  \n",
       "791       Sadness  \n",
       "\n",
       "[792 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = pd.read_table('dataset\\WASSA23_essay_level_with_labels_train.tsv')\n",
    "display(train_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRACK 2: Regression (EMP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Range di valori 'empathy' e 'distress'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "empathy_value = train_dataset['empathy'].unique()\n",
    "display(max(empathy_value))\n",
    "display(min(empathy_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distress_value = train_dataset['distress'].unique()\n",
    "display(max(distress_value))\n",
    "display(min(distress_value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRACK 3: Classification (EMO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classi delle emozioni, ogni essay viene classificato in 1, 2 o 3 classi delle 8 disponibili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hope/Sadness', 'Anger', 'Sadness', 'Neutral', 'Disgust/Sadness',\n",
       "       'Anger/Disgust', 'Fear/Sadness', 'Joy', 'Hope', 'Joy/Neutral',\n",
       "       'Disgust', 'Neutral/Sadness', 'Neutral/Surprise', 'Anger/Neutral',\n",
       "       'Hope/Neutral', 'Surprise', 'Anger/Sadness', 'Fear', 'Anger/Joy',\n",
       "       'Disgust/Fear', 'Fear/Neutral', 'Fear/Hope', 'Joy/Sadness',\n",
       "       'Anger/Disgust/Sadness', 'Anger/Surprise', 'Disgust/Neutral',\n",
       "       'Anger/Fear', 'Sadness/Surprise', 'Disgust/Surprise', 'Anger/Hope'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotion_label = train_dataset['emotion'].unique()\n",
    "display(emotion_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anger', 'Disgust', 'Fear', 'Hope', 'Joy', 'Neutral', 'Sadness', 'Surprise'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotion = set()\n",
    "for label in emotion_label:\n",
    "    emotion.update(label.split(\"/\"))\n",
    "\n",
    "emozioni_divise = list(emotion)\n",
    "\n",
    "display(emotion)\n",
    "display(len(emotion))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRACK 4 e/o 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numero di speakers totali: 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 19, 17, 16, 49, 24, 43, 31, 40, 13, 37, 20, 44, 45, 33, 48, 25,\n",
       "       56, 57, 23,  5, 27, 55,  2,  7, 53, 35, 32, 18, 14, 46, 51, 22, 36,\n",
       "       15, 41,  3, 50, 38,  8, 26,  6, 34, 52,  9, 42,  0, 58, 10, 12, 29,\n",
       "       47, 11,  1,  4, 28, 39, 21, 54], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "speaker_id_value = train_dataset['speaker_id'].unique()\n",
    "display(speaker_id_value)\n",
    "display(len(speaker_id_value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numero di conversazioni: 396, ogniuna coinvolge 2 speakers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conversation_id_value = train_dataset['conversation_id'].unique()\n",
    "display(len(conversation_id_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 396], dtype='int64')\n",
      "Int64Index([1, 397], dtype='int64')\n",
      "Int64Index([2, 398], dtype='int64')\n",
      "Int64Index([3, 399], dtype='int64')\n",
      "Int64Index([4, 400], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "for value in conversation_id_value[:5]:\n",
    "    print(train_dataset[train_dataset['conversation_id'] == value].index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricavo indici delle righe relativi agli essay che ogni speaker ha letto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([241, 267, 311, 315, 321, 384, 389, 391, 398, 411, 437, 445, 454,\n",
      "            467, 638, 657, 661, 666, 672, 673, 681, 700, 703, 708, 713, 716,\n",
      "            729, 766],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "for speaker in speaker_id_value[:1]:\n",
    "    print(train_dataset[train_dataset['speaker_id'] == value].index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricavo indici delle righe relativi agli essay con cui ogni speaker ha interagito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[384, 513, 769, 260, 391, 136, 776, 777, 11, 266, 13, 395, 396, 400, 786, 148, 789, 535, 280, 153, 539, 667, 670, 31, 32, 417, 674, 425, 555, 683, 559, 175, 689, 303, 51, 564, 53, 566, 180, 697, 186, 315, 191, 453, 205, 718, 79, 591, 207, 596, 213, 469, 216, 733, 350, 736, 490, 619, 235, 238, 367, 624, 760, 494, 120, 378]\n"
     ]
    }
   ],
   "source": [
    "for speaker in speaker_id_value[:1]:\n",
    "    not_speaker_index = train_dataset[train_dataset['speaker_id'] != speaker].index\n",
    "    conversation_speaker = train_dataset[train_dataset['conversation_id'].isin(train_dataset[train_dataset['speaker_id'] == speaker]['conversation_id'])].index\n",
    "    print(list(set(not_speaker_index) & set(conversation_speaker)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data preprocessing on the features was done by following these steps:\n",
    "- **Remove punctuations**: use RegEx library to recognize punctuation and remove it from text.\n",
    "- **Remove digit**: use RegEx library to recognize digit and remove it from text.\n",
    "- **Remove stopwords**: use the stop words list provided by NLTK to recognize stop words and remove them from text.\n",
    "- **Lemmatize**: use NLTK Lemmatizer object to replace each text word with its lemma if it's found in WordNet.\n",
    "- **Stemming**: use NLTK Stemmer object to replace each text word with its word steam.\n",
    "- **Convert lowercase**: use lower() method to convert all words in the text in lowercase.\n",
    "- **Expand contractions**: use contractions library to replace each contracted text word with words from which it is formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\giuli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\giuli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\giuli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\giuli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re # python library to recoginze punctuation and digit\n",
    "import contractions # python library to recoginze contractions\n",
    "\n",
    "import pickle\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english') # load english stop words to recognize it in text\n",
    "lemmatizer = WordNetLemmatizer() # create Lemmatizer object\n",
    "stemmer = PorterStemmer() # create Stemmer object\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def remove_digit(text):\n",
    "    return re.sub('\\d+', '', text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in nltk.word_tokenize(text) if word not in stop_words])\n",
    "\n",
    "def lemmatize(text):\n",
    "    return ' '.join(lemmatizer.lemmatize(word) for word in text.split())\n",
    "\n",
    "def stemming(text):\n",
    "    return ' '.join(stemmer.stem(word) for word in text.split())\n",
    "\n",
    "def convert_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return ' '.join(contractions.fix(word) for word in text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_digit(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatize(text)\n",
    "    text = stemming(text)\n",
    "    text = convert_lowercase(text)\n",
    "    text = expand_contractions(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = train_dataset.loc[:, ['conversation_id', 'essay', 'empathy', 'distress', 'speaker_id', 'emotion']]\n",
    "# oppure: train_dataset = train_dataset.drop([])\n",
    "\n",
    "# text preprocessing\n",
    "tr_df['essay'] = tr_df['essay'].apply(text_preprocessing)\n",
    "\n",
    "# shuffle rows\n",
    "#tr_df = tr_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>empathy</th>\n",
       "      <th>distress</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>it break heart see peopl live condit i hope ai...</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>6.625</td>\n",
       "      <td>30</td>\n",
       "      <td>Hope/Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>i wonder are not peopl tri help peopl i unders...</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>6.000</td>\n",
       "      <td>19</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>after read articl cannot help feel realli sad ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.375</td>\n",
       "      <td>17</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>it sad someon amaz stori die freak accid hi li...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>6.625</td>\n",
       "      <td>16</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>from read articl look like world lost kindhear...</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>30</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>495</td>\n",
       "      <td>i feel becom nation problem soon i feel pipe b...</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>6.750</td>\n",
       "      <td>30</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>496</td>\n",
       "      <td>the whole situat sketchi the waver rule death ...</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>6.375</td>\n",
       "      <td>16</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>498</td>\n",
       "      <td>the death former aid russian presid vladimir p...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>43</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>499</td>\n",
       "      <td>everyth russia realli freak i think countri re...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>53</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>500</td>\n",
       "      <td>whenev russia putin involv i trust said the st...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.875</td>\n",
       "      <td>30</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     conversation_id                                              essay  \\\n",
       "0                  2  it break heart see peopl live condit i hope ai...   \n",
       "1                  3  i wonder are not peopl tri help peopl i unders...   \n",
       "2                  5  after read articl cannot help feel realli sad ...   \n",
       "3                  6  it sad someon amaz stori die freak accid hi li...   \n",
       "4                  8  from read articl look like world lost kindhear...   \n",
       "..               ...                                                ...   \n",
       "787              495  i feel becom nation problem soon i feel pipe b...   \n",
       "788              496  the whole situat sketchi the waver rule death ...   \n",
       "789              498  the death former aid russian presid vladimir p...   \n",
       "790              499  everyth russia realli freak i think countri re...   \n",
       "791              500  whenev russia putin involv i trust said the st...   \n",
       "\n",
       "      empathy  distress  speaker_id       emotion  \n",
       "0    6.833333     6.625          30  Hope/Sadness  \n",
       "1    5.833333     6.000          19         Anger  \n",
       "2    1.000000     1.375          17       Sadness  \n",
       "3    6.166667     6.625          16       Sadness  \n",
       "4    6.833333     1.000          30       Neutral  \n",
       "..        ...       ...         ...           ...  \n",
       "787  6.500000     6.750          30       Neutral  \n",
       "788  3.166667     6.375          16       Neutral  \n",
       "789  6.000000     2.000          43       Neutral  \n",
       "790  6.000000     6.000          53          Fear  \n",
       "791  1.500000     4.875          30       Sadness  \n",
       "\n",
       "[792 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It breaks my heart to see people living in those conditions. I hope that all the aid that was sent to the island makes it to the people who need it the most. I do not know what I would do it that was my family and I. I would hope that I would do my best, but I can see how depressing and hopeless you could feel having your whole life changed because of a storm and not knowing where your next meal is coming from.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'it break heart see peopl live condit i hope aid sent island make peopl need i know i would famili i i would hope i would best i see depress hopeless could feel whole life chang storm know next meal come'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_dataset['essay'][0])\n",
    "display(tr_df['essay'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
